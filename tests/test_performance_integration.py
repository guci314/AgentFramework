#!/usr/bin/env python3
"""
æ€§èƒ½ç›‘æ§é›†æˆæµ‹è¯•
æµ‹è¯•WorkflowStateä¸æ€§èƒ½ç›‘æ§ç³»ç»Ÿçš„é›†æˆ
"""

import sys
import os
import time
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from enhancedAgent_v2 import WorkflowState
from performance_monitor import PerformanceMonitor, get_performance_monitor

def test_performance_integration():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§é›†æˆ"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½ç›‘æ§é›†æˆæµ‹è¯•")
    
    # 1. åˆ›å»ºWorkflowStateå®ä¾‹
    print("\n1. åˆ›å»ºWorkflowStateå®ä¾‹...")
    workflow_state = WorkflowState()
    
    # 2. æ£€æŸ¥æ€§èƒ½ç›‘æ§æ˜¯å¦æ­£ç¡®é›†æˆ
    print("\n2. æ£€æŸ¥æ€§èƒ½ç›‘æ§é›†æˆçŠ¶æ€...")
    if hasattr(workflow_state, '_performance_monitor') and workflow_state._performance_monitor:
        print("âœ… æ€§èƒ½ç›‘æ§ç³»ç»Ÿå·²æˆåŠŸé›†æˆåˆ°WorkflowState")
        print(f"   ç›‘æ§å™¨ç±»å‹: {type(workflow_state._performance_monitor).__name__}")
    else:
        print("âŒ æ€§èƒ½ç›‘æ§ç³»ç»Ÿæœªé›†æˆæˆ–ä¸å¯ç”¨")
        return False
    
    # 3. æµ‹è¯•çŠ¶æ€æ“ä½œçš„æ€§èƒ½ç›‘æ§
    print("\n3. æµ‹è¯•çŠ¶æ€æ“ä½œæ€§èƒ½ç›‘æ§...")
    
    # è®¾ç½®çŠ¶æ€
    test_states = [
        "é¡¹ç›®åˆå§‹åŒ–é˜¶æ®µ",
        "æ•°æ®å¤„ç†ä¸­ï¼Œå·²å®Œæˆ30%",
        "é‡åˆ°ç½‘ç»œå»¶è¿Ÿï¼Œæ­£åœ¨é‡è¯•",
        "å¤„ç†å®Œæˆï¼Œå‡†å¤‡ç”ŸæˆæŠ¥å‘Š",
        "ä»»åŠ¡å®Œæˆï¼Œç³»ç»Ÿæ­£å¸¸è¿è¡Œ"
    ]
    
    for i, state in enumerate(test_states):
        print(f"   è®¾ç½®çŠ¶æ€ {i+1}: {state[:30]}...")
        workflow_state.set_global_state(state, source=f"test_source_{i+1}")
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    # 4. æµ‹è¯•å†å²æ“ä½œ
    print("\n4. æµ‹è¯•å†å²æ“ä½œ...")
    history = workflow_state.get_state_history()
    print(f"   å†å²è®°å½•æ•°é‡: {len(history)}")
    
    history_count = workflow_state.get_state_history_count()
    print(f"   å†å²è®¡æ•°: {history_count}")
    
    # 5. è·å–æ€§èƒ½ç»Ÿè®¡
    print("\n5. è·å–æ€§èƒ½ç»Ÿè®¡...")
    monitor = workflow_state._performance_monitor
    
    # è·å–åŸºæœ¬ç»Ÿè®¡
    stats = monitor.get_performance_report()
    print("   åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
    for category, metrics in stats.items():
        print(f"     {category}:")
        if isinstance(metrics, dict):
            for metric_name, data in metrics.items():
                print(f"       {metric_name}: {data}")
        else:
            print(f"       {metrics}")
    
    # 6. æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§
    print("\n6. æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§...")
    memory_info = workflow_state.get_memory_usage()
    print("   å†…å­˜ä½¿ç”¨ä¿¡æ¯:")
    for key, value in memory_info.items():
        if isinstance(value, (int, float)):
            print(f"     {key}: {value}")
        else:
            print(f"     {key}: {str(value)[:50]}...")
    
    # 7. æµ‹è¯•AIçŠ¶æ€æ›´æ–°å™¨çŠ¶æ€
    print("\n7. æµ‹è¯•AIçŠ¶æ€æ›´æ–°å™¨çŠ¶æ€...")
    ai_status = workflow_state.get_ai_updater_status()
    print("   AIæ›´æ–°å™¨çŠ¶æ€:")
    for key, value in ai_status.items():
        print(f"     {key}: {value}")
    
    # 8. æµ‹è¯•æ€§èƒ½ç›‘æ§çš„è®°å½•åŠŸèƒ½
    print("\n8. æµ‹è¯•æ€§èƒ½ç›‘æ§è®°å½•åŠŸèƒ½...")
    
    # æ‰‹åŠ¨è®°å½•ä¸€äº›æŒ‡æ ‡
    monitor.metric_collector.record_counter("test_counter", 5.0, {"test_tag": "integration_test"})
    monitor.metric_collector.record_gauge("test_gauge", 42.0, {"test_tag": "integration_test"})
    monitor.metric_collector.record_timer("test_timer", 123.0, {"operation": "test_timing"})
    
    # è·å–æ›´æ–°åçš„ç»Ÿè®¡
    updated_stats = monitor.get_performance_report()
    print("   æ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯:")
    for category, metrics in updated_stats.items():
        if "test" in category.lower():
            print(f"     {category}: {metrics}")
    
    # 9. æµ‹è¯•çŠ¶æ€æ‘˜è¦åŠŸèƒ½
    print("\n9. æµ‹è¯•çŠ¶æ€æ‘˜è¦åŠŸèƒ½...")
    summary = workflow_state.get_state_summary()
    print("   çŠ¶æ€æ‘˜è¦:")
    print(f"     {summary}")
    
    print("\nâœ… æ€§èƒ½ç›‘æ§é›†æˆæµ‹è¯•å®Œæˆï¼")
    return True

def test_performance_monitoring_kpis():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§KPIæ”¶é›†"""
    print("\nğŸ¯ æµ‹è¯•æ€§èƒ½ç›‘æ§KPIæ”¶é›†")
    
    # è·å–å…¨å±€æ€§èƒ½ç›‘æ§å™¨
    monitor = get_performance_monitor()
    
    # è®°å½•ä¸€äº›KPIæŒ‡æ ‡
    kpi_metrics = [
        ("workflow_execution", "steps_completed", 10),
        ("workflow_execution", "steps_failed", 2),
        ("state_management", "state_updates", 15),
        ("state_management", "history_size", 8),
        ("ai_operations", "llm_calls", 5),
        ("ai_operations", "cache_hits", 3),
        ("system_performance", "memory_usage_mb", 256),
        ("system_performance", "cpu_usage_percent", 45)
    ]
    
    print("   è®°å½•KPIæŒ‡æ ‡...")
    for category, operation, value in kpi_metrics:
        monitor.metric_collector.record_counter(f"{category}_{operation}", float(value), {"category": category})
        print(f"     âœ“ {category}.{operation}: {value}")
    
    # è®°å½•ä¸€äº›æ—¶é—´æŒ‡æ ‡
    timing_metrics = [
        ("ai_state_update", 1234.0, {"model": "deepseek", "tokens": "150"}),
        ("state_persistence", 45.0, {"operation": "save"}),
        ("history_compression", 678.0, {"entries": "50"}),
        ("workflow_step_execution", 2345.0, {"step_type": "python_execution"})
    ]
    
    print("   è®°å½•æ—¶é—´æŒ‡æ ‡...")
    for operation, duration, tags in timing_metrics:
        monitor.metric_collector.record_timer(operation, duration, tags)
        print(f"     âœ“ {operation}: {duration}ms")
    
    # è·å–å®Œæ•´ç»Ÿè®¡
    print("\n   å®Œæ•´KPIç»Ÿè®¡:")
    stats = monitor.get_performance_report()
    
    for category, metrics in stats.items():
        print(f"     ğŸ“Š {category}:")
        if isinstance(metrics, dict):
            for metric_name, data in metrics.items():
                print(f"       {metric_name}: {data}")
        else:
            print(f"       {metrics}")
    
    print("\nâœ… KPIæ”¶é›†æµ‹è¯•å®Œæˆï¼")
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” æ€§èƒ½ç›‘æ§å’ŒKPIæ”¶é›†é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•åŸºç¡€é›†æˆ
        success1 = test_performance_integration()
        
        # æµ‹è¯•KPIæ”¶é›†
        success2 = test_performance_monitoring_kpis()
        
        if success1 and success2:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ€§èƒ½ç›‘æ§ç³»ç»Ÿå·²å®Œå…¨é›†æˆã€‚")
            print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
            print("  âœ… WorkflowStateæ€§èƒ½ç›‘æ§é›†æˆ")
            print("  âœ… çŠ¶æ€æ“ä½œæ€§èƒ½è·Ÿè¸ª")
            print("  âœ… å†…å­˜ä½¿ç”¨ç›‘æ§")
            print("  âœ… AIçŠ¶æ€æ›´æ–°å™¨çŠ¶æ€ç›‘æ§")
            print("  âœ… KPIæŒ‡æ ‡æ”¶é›†")
            print("  âœ… æ—¶é—´æŒ‡æ ‡è®°å½•")
            print("  âœ… ç»Ÿè®¡æ•°æ®èšåˆ")
            
            print("\nğŸš€ å­ä»»åŠ¡5.4 (æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†) å·²å®Œæˆï¼")
            return True
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é›†æˆé—®é¢˜ã€‚")
            return False
            
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main() 