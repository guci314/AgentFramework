#!/usr/bin/env python3
"""
AIçŠ¶æ€æ›´æ–°å™¨ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘æµ‹è¯•
===================================

æµ‹è¯•æ–°å¢çš„ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘åŠŸèƒ½ï¼š
1. LRUç¼“å­˜ç³»ç»Ÿæµ‹è¯•
2. ä¸Šä¸‹æ–‡å“ˆå¸Œç”Ÿæˆæµ‹è¯•
3. AIè°ƒç”¨æ¡ä»¶æ£€æŸ¥æµ‹è¯•
4. ç»¼åˆç¼“å­˜å’Œæ¡ä»¶é€»è¾‘é›†æˆæµ‹è¯•
5. æ€§èƒ½å½±å“è¯„ä¼°

è¿™äº›æµ‹è¯•éªŒè¯ä¼˜åŒ–åŠŸèƒ½çš„æ­£ç¡®æ€§å’Œæ€§èƒ½æå‡æ•ˆæœã€‚
"""

import time
import logging
from datetime import datetime
from enhancedAgent_v2 import (
    WorkflowState, 
    AIStateUpdaterService, 
    LRUCache, 
    ContextHasher, 
    AICallConditionChecker,
    AICallCacheEntry
)
from unittest.mock import Mock, MagicMock

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MockLLM:
    """Mock LLMç”¨äºæµ‹è¯•"""
    def __init__(self):
        self.call_count = 0
        self.responses = ["æµ‹è¯•çŠ¶æ€æ›´æ–°ï¼šå½“å‰ä»»åŠ¡å·²å®Œæˆï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸"]
        
    def invoke(self, messages):
        self.call_count += 1
        response = Mock()
        response.content = self.responses[0] if self.responses else "é»˜è®¤å“åº”"
        logger.info(f"Mock LLMè°ƒç”¨ #{self.call_count}")
        return response

def test_lru_cache():
    """æµ‹è¯•LRUç¼“å­˜åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•LRUç¼“å­˜åŠŸèƒ½...")
    
    cache = LRUCache(max_size=3)
    
    # æµ‹è¯•åŸºæœ¬æ“ä½œ
    entry1 = AICallCacheEntry("å“åº”1", datetime.now(), "hash1", 0.9, 1)
    entry2 = AICallCacheEntry("å“åº”2", datetime.now(), "hash2", 0.8, 1)
    entry3 = AICallCacheEntry("å“åº”3", datetime.now(), "hash3", 0.7, 1)
    entry4 = AICallCacheEntry("å“åº”4", datetime.now(), "hash4", 0.6, 1)
    
    # æ·»åŠ ç¼“å­˜é¡¹
    cache.put("key1", entry1)
    cache.put("key2", entry2)
    cache.put("key3", entry3)
    
    # æµ‹è¯•ç¼“å­˜å‘½ä¸­
    cached = cache.get("key1")
    assert cached is not None, "ç¼“å­˜é¡¹åº”è¯¥å­˜åœ¨"
    assert cached.response == "å“åº”1", "ç¼“å­˜å“åº”ä¸åŒ¹é…"
    assert cached.usage_count == 2, "ä½¿ç”¨æ¬¡æ•°åº”è¯¥å¢åŠ "
    
    # æµ‹è¯•LRUæ·˜æ±°
    cache.put("key4", entry4)  # åº”è¯¥æ·˜æ±°key2
    assert cache.get("key2") is None, "key2åº”è¯¥è¢«æ·˜æ±°"
    assert cache.get("key1") is not None, "key1åº”è¯¥è¿˜åœ¨ï¼ˆæœ€è¿‘ä½¿ç”¨è¿‡ï¼‰"
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    stats = cache.get_stats()
    assert stats['cache_size'] == 3, "ç¼“å­˜å¤§å°ä¸æ­£ç¡®"
    assert stats['hits'] > 0, "åº”è¯¥æœ‰ç¼“å­˜å‘½ä¸­"
    
    print("âœ… LRUç¼“å­˜æµ‹è¯•é€šè¿‡")
    return True

def test_context_hasher():
    """æµ‹è¯•ä¸Šä¸‹æ–‡å“ˆå¸Œç”Ÿæˆ"""
    print("ğŸ§ª æµ‹è¯•ä¸Šä¸‹æ–‡å“ˆå¸Œç”Ÿæˆ...")
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = WorkflowState()
    state.set_global_state("æµ‹è¯•çŠ¶æ€", source="test")
    
    # æµ‹è¯•ä¸Šä¸‹æ–‡
    context1 = {
        'step_info': {'action': 'test_action', 'step_id': 'step1'},
        'execution_result': 'æ‰§è¡ŒæˆåŠŸ',
        'step_status': 'completed'
    }
    
    context2 = {
        'step_info': {'action': 'test_action', 'step_id': 'step1'},
        'execution_result': 'æ‰§è¡ŒæˆåŠŸ',
        'step_status': 'completed'
    }
    
    context3 = {
        'step_info': {'action': 'different_action', 'step_id': 'step1'},
        'execution_result': 'æ‰§è¡ŒæˆåŠŸ',
        'step_status': 'completed'
    }
    
    # æµ‹è¯•ç›¸åŒä¸Šä¸‹æ–‡ç”Ÿæˆç›¸åŒå“ˆå¸Œ
    hash1 = ContextHasher.hash_context(state, context1)
    hash2 = ContextHasher.hash_context(state, context2)
    assert hash1 == hash2, "ç›¸åŒä¸Šä¸‹æ–‡åº”è¯¥ç”Ÿæˆç›¸åŒå“ˆå¸Œ"
    
    # æµ‹è¯•ä¸åŒä¸Šä¸‹æ–‡ç”Ÿæˆä¸åŒå“ˆå¸Œ
    hash3 = ContextHasher.hash_context(state, context3)
    assert hash1 != hash3, "ä¸åŒä¸Šä¸‹æ–‡åº”è¯¥ç”Ÿæˆä¸åŒå“ˆå¸Œ"
    
    # æµ‹è¯•åŒ…å«æ—¶é—´æˆ³çš„å“ˆå¸Œ
    hash4 = ContextHasher.hash_context(state, context1, include_timestamp=True)
    time.sleep(0.1)
    hash5 = ContextHasher.hash_context(state, context1, include_timestamp=True)
    assert hash4 != hash5, "åŒ…å«æ—¶é—´æˆ³çš„å“ˆå¸Œåº”è¯¥ä¸åŒ"
    
    print("âœ… ä¸Šä¸‹æ–‡å“ˆå¸Œæµ‹è¯•é€šè¿‡")
    return True

def test_condition_checker():
    """æµ‹è¯•AIè°ƒç”¨æ¡ä»¶æ£€æŸ¥å™¨"""
    print("ğŸ§ª æµ‹è¯•AIè°ƒç”¨æ¡ä»¶æ£€æŸ¥å™¨...")
    
    checker = AICallConditionChecker()
    state = WorkflowState()
    
    # æµ‹è¯•åˆå§‹åŒ–åœºæ™¯
    context_init = {}
    should_call, reason = checker.should_make_ai_call(state, context_init)
    print(f"åˆå§‹åŒ–æµ‹è¯• - should_call: {should_call}, reason: '{reason}'")
    assert should_call, "åˆå§‹åŒ–æ—¶åº”è¯¥è°ƒç”¨AI"
    assert "åˆå§‹åŒ–" in reason or "å·¥ä½œæµåˆå§‹åŒ–" in reason, f"åŸå› åº”è¯¥åŒ…å«åˆå§‹åŒ–ï¼Œå®é™…åŸå› : '{reason}'"
    
    # è®¾ç½®ä¸€äº›çŠ¶æ€ï¼Œç¡®ä¿æœ‰å†å²è®°å½•
    state.set_global_state("åˆå§‹çŠ¶æ€", source="test")
    state.set_global_state("æµ‹è¯•çŠ¶æ€", source="test")
    
    # æµ‹è¯•é”™è¯¯æ¡ä»¶
    context_error = {
        'error_info': 'æµ‹è¯•é”™è¯¯',
        'step_status': 'failed'
    }
    should_call, reason = checker.should_make_ai_call(state, context_error)
    print(f"é”™è¯¯æµ‹è¯• - should_call: {should_call}, reason: '{reason}'")
    assert should_call, "æœ‰é”™è¯¯æ—¶åº”è¯¥è°ƒç”¨AI"
    assert "é”™è¯¯" in reason or "AIåˆ†æ" in reason, f"åŸå› åº”è¯¥åŒ…å«é”™è¯¯ç›¸å…³ä¿¡æ¯ï¼Œå®é™…åŸå› : '{reason}'"
    
    # æµ‹è¯•çŠ¶æ€è½¬æ¢
    context_transition = {
        'step_status': 'completed',
        'execution_result': 'ä»»åŠ¡å®Œæˆ'
    }
    should_call, reason = checker.should_make_ai_call(state, context_transition)
    assert should_call, "çŠ¶æ€è½¬æ¢æ—¶åº”è¯¥è°ƒç”¨AI"
    
    # æµ‹è¯•ä¸é‡è¦å˜åŒ–
    context_minor = {
        'step_status': 'running',
        'execution_result': 'ok'
    }
    should_call, reason = checker.should_make_ai_call(state, context_minor)
    # å¯èƒ½è°ƒç”¨ä¹Ÿå¯èƒ½ä¸è°ƒç”¨ï¼Œå–å†³äºå…·ä½“é€»è¾‘
    
    # æµ‹è¯•é…ç½®æ›´æ–°
    original_config = checker.get_configuration()
    checker.set_significance_threshold(0.5)
    checker.set_time_threshold(600)
    
    new_config = checker.get_configuration()
    assert new_config['significance_threshold'] == 0.5, "é˜ˆå€¼æ›´æ–°å¤±è´¥"
    assert new_config['time_threshold_seconds'] == 600, "æ—¶é—´é˜ˆå€¼æ›´æ–°å¤±è´¥"
    
    print("âœ… æ¡ä»¶æ£€æŸ¥å™¨æµ‹è¯•é€šè¿‡")
    return True

def test_ai_updater_integration():
    """æµ‹è¯•AIçŠ¶æ€æ›´æ–°å™¨ä¸ç¼“å­˜ã€æ¡ä»¶é€»è¾‘çš„é›†æˆ"""
    print("ğŸ§ª æµ‹è¯•AIçŠ¶æ€æ›´æ–°å™¨é›†æˆ...")
    
    # åˆ›å»ºMock LLM
    mock_llm = MockLLM()
    
    # åˆ›å»ºå¯ç”¨ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘çš„AIæ›´æ–°å™¨
    updater = AIStateUpdaterService(
        llm=mock_llm,
        enable_caching=True,
        cache_size=5,
        enable_conditional_logic=True
    )
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = WorkflowState()
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ - åº”è¯¥è°ƒç”¨LLMï¼ˆåˆå§‹åŒ–ï¼‰
    context1 = {
        'step_info': {'action': 'init', 'step_id': 'step1'},
        'execution_result': 'åˆå§‹åŒ–å®Œæˆ',
        'step_status': 'completed'
    }
    
    result1 = updater.update_state(state, context1)
    assert result1 is not None, "ç¬¬ä¸€æ¬¡æ›´æ–°åº”è¯¥æˆåŠŸ"
    first_call_count = mock_llm.call_count
    
    # ç›¸åŒä¸Šä¸‹æ–‡çš„ç¬¬äºŒæ¬¡è°ƒç”¨ - åº”è¯¥ä½¿ç”¨ç¼“å­˜
    result2 = updater.update_state(state, context1)
    assert result2 == result1, "ç¼“å­˜ç»“æœåº”è¯¥ç›¸åŒ"
    assert mock_llm.call_count == first_call_count, "åº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼Œä¸å¢åŠ LLMè°ƒç”¨"
    
    # æ£€æŸ¥ç¼“å­˜ç»Ÿè®¡
    cache_stats = updater.get_cache_statistics()
    assert cache_stats['enabled'], "ç¼“å­˜åº”è¯¥å¯ç”¨"
    assert cache_stats['hits'] >= 1, "åº”è¯¥æœ‰ç¼“å­˜å‘½ä¸­"
    
    # ä¸åŒä¸Šä¸‹æ–‡çš„è°ƒç”¨ - åº”è¯¥è°ƒç”¨LLM
    context2 = {
        'step_info': {'action': 'process', 'step_id': 'step2'},
        'execution_result': 'å¤„ç†å®Œæˆ',
        'step_status': 'completed'
    }
    
    result3 = updater.update_state(state, context2)
    assert result3 is not None, "æ–°ä¸Šä¸‹æ–‡æ›´æ–°åº”è¯¥æˆåŠŸ"
    assert mock_llm.call_count > first_call_count, "æ–°ä¸Šä¸‹æ–‡åº”è¯¥è°ƒç”¨LLM"
    
    # æµ‹è¯•æ¡ä»¶é€»è¾‘é…ç½®
    condition_config = updater.get_condition_checker_config()
    assert condition_config['enabled'], "æ¡ä»¶é€»è¾‘åº”è¯¥å¯ç”¨"
    
    # æµ‹è¯•æ€§èƒ½ç»Ÿè®¡
    perf_stats = updater.get_performance_statistics()
    assert 'caching' in perf_stats, "åº”è¯¥åŒ…å«ç¼“å­˜ç»Ÿè®¡"
    assert 'conditional_logic' in perf_stats, "åº”è¯¥åŒ…å«æ¡ä»¶é€»è¾‘ç»Ÿè®¡"
    
    print("âœ… AIçŠ¶æ€æ›´æ–°å™¨é›†æˆæµ‹è¯•é€šè¿‡")
    return True

def test_performance_impact():
    """æµ‹è¯•æ€§èƒ½å½±å“"""
    print("ğŸ§ª æµ‹è¯•æ€§èƒ½å½±å“...")
    
    # åˆ›å»ºä¸¤ä¸ªæ›´æ–°å™¨ï¼šä¸€ä¸ªå¯ç”¨ä¼˜åŒ–ï¼Œä¸€ä¸ªä¸å¯ç”¨
    mock_llm1 = MockLLM()
    mock_llm2 = MockLLM()
    
    updater_optimized = AIStateUpdaterService(
        llm=mock_llm1,
        enable_caching=True,
        enable_conditional_logic=True
    )
    
    updater_basic = AIStateUpdaterService(
        llm=mock_llm2,
        enable_caching=False,
        enable_conditional_logic=False
    )
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    state1 = WorkflowState()
    state2 = WorkflowState()
    
    contexts = [
        {'step_info': {'action': f'action_{i}', 'step_id': f'step_{i}'}, 
         'execution_result': f'ç»“æœ_{i}', 'step_status': 'completed'}
        for i in range(10)
    ]
    
    # æ·»åŠ ä¸€äº›é‡å¤çš„ä¸Šä¸‹æ–‡æ¥æµ‹è¯•ç¼“å­˜æ•ˆæœ
    contexts.extend(contexts[:5])
    
    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    start_time = time.time()
    for context in contexts:
        updater_optimized.update_state(state1, context)
    optimized_time = time.time() - start_time
    optimized_calls = mock_llm1.call_count
    
    # æµ‹è¯•åŸºç¡€ç‰ˆæœ¬
    start_time = time.time()
    for context in contexts:
        updater_basic.update_state(state2, context)
    basic_time = time.time() - start_time
    basic_calls = mock_llm2.call_count
    
    print(f"ğŸ“Š æ€§èƒ½å¯¹æ¯”:")
    print(f"   ä¼˜åŒ–ç‰ˆæœ¬: {optimized_time:.3f}s, LLMè°ƒç”¨: {optimized_calls}æ¬¡")
    print(f"   åŸºç¡€ç‰ˆæœ¬: {basic_time:.3f}s, LLMè°ƒç”¨: {basic_calls}æ¬¡")
    print(f"   ç¼“å­˜èŠ‚çœçš„LLMè°ƒç”¨: {basic_calls - optimized_calls}æ¬¡")
    
    # éªŒè¯ç¼“å­˜ç¡®å®å‡å°‘äº†LLMè°ƒç”¨
    assert optimized_calls < basic_calls, "ä¼˜åŒ–ç‰ˆæœ¬åº”è¯¥å‡å°‘LLMè°ƒç”¨æ¬¡æ•°"
    
    # è·å–ç¼“å­˜ç»Ÿè®¡
    cache_stats = updater_optimized.get_cache_statistics()
    print(f"   ç¼“å­˜å‘½ä¸­ç‡: {cache_stats.get('hit_rate_percent', 0):.1f}%")
    
    print("âœ… æ€§èƒ½å½±å“æµ‹è¯•é€šè¿‡")
    return True

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘åŠŸèƒ½æµ‹è¯•...\n")
    
    tests = [
        test_lru_cache,
        test_context_hasher,
        test_condition_checker,
        test_ai_updater_integration,
        test_performance_impact
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            print()  # ç©ºè¡Œåˆ†éš”
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {test_func.__name__} - {e}")
            print()
    
    print(f"ğŸ“‹ æµ‹è¯•æ€»ç»“: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘æµ‹è¯•å‡é€šè¿‡ï¼")
        print("\nâœ¨ ä¼˜åŒ–åŠŸèƒ½éªŒè¯æˆåŠŸï¼š")
        print("   - LRUç¼“å­˜ç³»ç»Ÿæ­£å¸¸å·¥ä½œ")
        print("   - ä¸Šä¸‹æ–‡å“ˆå¸Œç”Ÿæˆæ­£ç¡®")
        print("   - æ¡ä»¶é€»è¾‘æ£€æŸ¥æœ‰æ•ˆ")
        print("   - AIæ›´æ–°å™¨é›†æˆå®Œå–„")
        print("   - æ€§èƒ½ä¼˜åŒ–æ•ˆæœæ˜æ˜¾")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
    
    return passed == total

if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1) 