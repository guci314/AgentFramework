"""
MultiStepAgent_v3 - é™æ€å·¥ä½œæµæ™ºèƒ½ä½“
===================================

åŸºäºé™æ€å·¥ä½œæµæ¶æ„çš„å¤šæ­¥éª¤æ™ºèƒ½ä½“ï¼Œé‡‡ç”¨é¢„å®šä¹‰çš„å£°æ˜å¼æ§åˆ¶æµã€‚
"""

import os
import sys
import json
import logging
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
from datetime import datetime as dt

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ç°æœ‰æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agent_base import Result, reduce_memory_decorator_compress
from pythonTask import Agent
from langchain_core.language_models import BaseChatModel
from result_evaluator import TestResultEvaluator, MockTestResultEvaluator

from .workflow_definitions import WorkflowDefinition, WorkflowStep, WorkflowLoader
from .static_workflow_engine import StaticWorkflowEngine, WorkflowExecutionResult
from .control_flow_evaluator import ControlFlowEvaluator

logger = logging.getLogger(__name__)


class RegisteredAgent:
    """å­˜å‚¨å·²æ³¨å†Œçš„æ™ºèƒ½ä½“ä¿¡æ¯"""
    def __init__(self, name: str, instance: Agent, description: str):
        self.name = name
        self.instance = instance
        self.description = description


class MultiStepAgent_v3(Agent):
    """
    é™æ€å·¥ä½œæµå¤šæ­¥éª¤æ™ºèƒ½ä½“
    
    é‡‡ç”¨å£°æ˜å¼æ§åˆ¶æµæ¶æ„ï¼Œé€šè¿‡é¢„å®šä¹‰çš„å·¥ä½œæµé…ç½®æ–‡ä»¶
    å®ç°ç¡®å®šæ€§çš„é«˜æ€§èƒ½æ‰§è¡Œã€‚
    """
    
    def __init__(
        self,
        llm: BaseChatModel,
        registered_agents: Optional[List[RegisteredAgent]] = None,
        max_retries: int = 3,
        thinker_system_message: Optional[str] = None,
        thinker_chat_system_message: Optional[str] = None,
        max_parallel_workers: int = 4,
        workflow_base_path: str = None,
        planning_prompt_template: Optional[str] = None,
        deepseek_api_key: Optional[str] = None,
        use_mock_evaluator: bool = False
    ):
        """
        åˆå§‹åŒ–é™æ€å·¥ä½œæµæ™ºèƒ½ä½“
        
        Args:
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹
            registered_agents: å·²æ³¨å†Œçš„æ™ºèƒ½ä½“åˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            thinker_system_message: æ€è€ƒè€…ç³»ç»Ÿæ¶ˆæ¯
            thinker_chat_system_message: æ€è€ƒè€…èŠå¤©ç³»ç»Ÿæ¶ˆæ¯
            max_parallel_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
            workflow_base_path: å·¥ä½œæµé…ç½®æ–‡ä»¶åŸºç¡€è·¯å¾„
            planning_prompt_template: è‡ªå®šä¹‰è§„åˆ’æç¤ºæ¨¡æ¿
            deepseek_api_key: DeepSeek APIå¯†é’¥ï¼Œç”¨äºæ™ºèƒ½æµ‹è¯•ç»“æœåˆ¤æ–­
            use_mock_evaluator: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿè¯„ä¼°å™¨ï¼ˆå¼€å‘/æµ‹è¯•ç”¨ï¼‰
        """
        
        # ä½¿ç”¨é»˜è®¤çš„ç³»ç»Ÿæ¶ˆæ¯
        if thinker_system_message is None:
            thinker_system_message = """
ä½ æ˜¯ä¸€ä¸ªé™æ€å·¥ä½œæµæ‰§è¡Œæ™ºèƒ½ä½“ï¼Œè´Ÿè´£æŒ‰ç…§é¢„å®šä¹‰çš„å·¥ä½œæµé…ç½®æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚

æ ¸å¿ƒèŒè´£ï¼š
1. ä¸¥æ ¼æŒ‰ç…§å·¥ä½œæµå®šä¹‰æ‰§è¡Œæ­¥éª¤
2. è°ƒç”¨ç›¸åº”çš„æ™ºèƒ½ä½“æ‰§è¡Œå…·ä½“ä»»åŠ¡
3. å¤„ç†æ­¥éª¤é—´çš„æ•°æ®ä¼ é€’å’ŒçŠ¶æ€ç®¡ç†
4. æ‰§è¡Œé¢„å®šä¹‰çš„æ§åˆ¶æµé€»è¾‘ï¼ˆæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œï¼‰

æ‰§è¡ŒåŸåˆ™ï¼š
- é«˜æ•ˆï¼šæ— è¿è¡Œæ—¶LLMå†³ç­–ï¼ŒæŒ‰é¢„å®šä¹‰è·¯å¾„æ‰§è¡Œ
- ç¡®å®šï¼šæ‰€æœ‰æ§åˆ¶æµè·¯å¾„åœ¨è®¾è®¡æ—¶ç¡®å®š
- å¯é ï¼šå®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- å¯è¿½è¸ªï¼šè¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—å’ŒçŠ¶æ€è®°å½•
"""
        
        super().__init__(
            llm=llm,
            stateful=True,
            thinker_system_message=thinker_system_message,
            thinker_chat_system_message=thinker_chat_system_message,
            max_retries=max_retries
        )
        
        # åˆå§‹åŒ–æ™ºèƒ½ç»“æœè¯„ä¼°å™¨
        if use_mock_evaluator or not deepseek_api_key:
            self.result_evaluator = MockTestResultEvaluator()
            logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæµ‹è¯•ç»“æœè¯„ä¼°å™¨")
        else:
            self.result_evaluator = TestResultEvaluator(api_key=deepseek_api_key)
            logger.info("ä½¿ç”¨DeepSeekæ™ºèƒ½æµ‹è¯•ç»“æœè¯„ä¼°å™¨")
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶ï¼ˆä¼ é€’AIè¯„ä¼°å™¨ç»™å·¥ä½œæµå¼•æ“ï¼‰
        self.registered_agents = registered_agents if registered_agents is not None else []
        self.max_retries = max_retries
        self.workflow_engine = StaticWorkflowEngine(max_parallel_workers, ai_evaluator=self.result_evaluator)
        self.workflow_loader = WorkflowLoader()
        
        # è®¾ç½®å·¥ä½œæµé…ç½®åŸºç¡€è·¯å¾„
        if workflow_base_path is None:
            self.workflow_base_path = Path(__file__).parent / "workflow_examples"
        else:
            self.workflow_base_path = Path(workflow_base_path)
        
        # æ³¨å†Œæ™ºèƒ½ä½“åˆ°StatefulExecutorå˜é‡ç©ºé—´
        for spec in self.registered_agents:
            self.device.set_variable(spec.name, spec.instance)
        
        # è®¾ç½®å·¥ä½œæµå¼•æ“çš„æ­¥éª¤æ‰§è¡Œå™¨
        self.workflow_engine.set_step_executor(self._execute_single_step)
        
        # è®¾ç½®å¼•æ“å›è°ƒ
        self.workflow_engine.on_step_start = self._on_step_start
        self.workflow_engine.on_step_complete = self._on_step_complete
        self.workflow_engine.on_step_failed = self._on_step_failed
        self.workflow_engine.on_workflow_complete = self._on_workflow_complete
        
        # è®¾ç½®è§„åˆ’æç¤ºæ¨¡æ¿
        self.planning_prompt_template = planning_prompt_template or self._get_default_planning_template()
        
        logger.debug(f"MultiStepAgent_v3 åˆå§‹åŒ–å®Œæˆï¼Œæ³¨å†Œäº† {len(self.registered_agents)} ä¸ªæ™ºèƒ½ä½“")
    
    def register_agent(self, name: str, instance: Agent, description: str = None) -> None:
        """
        æ³¨å†Œæ™ºèƒ½ä½“
        
        Args:
            name: æ™ºèƒ½ä½“åç§°
            instance: æ™ºèƒ½ä½“å®ä¾‹
            description: æ™ºèƒ½ä½“æè¿°
        """
        if description is None:
            description = getattr(instance, 'api_specification', f"{name}æ™ºèƒ½ä½“ï¼Œé€šç”¨ä»»åŠ¡æ‰§è¡Œè€…")
        
        spec = RegisteredAgent(name=name, instance=instance, description=description)
        self.registered_agents.append(spec)
        self.device.set_variable(name, instance)
        
        logger.debug(f"å·²æ³¨å†Œæ™ºèƒ½ä½“: {name}")
    
    def execute_workflow_from_file(self, 
                                 workflow_file: Union[str, Path],
                                 initial_variables: Dict[str, Any] = None) -> WorkflowExecutionResult:
        """
        ä»æ–‡ä»¶åŠ è½½å¹¶æ‰§è¡Œå·¥ä½œæµ
        
        Args:
            workflow_file: å·¥ä½œæµé…ç½®æ–‡ä»¶è·¯å¾„
            initial_variables: åˆå§‹å˜é‡
            
        Returns:
            å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if not Path(workflow_file).is_absolute():
            workflow_file = self.workflow_base_path / workflow_file
        
        try:
            # åŠ è½½å·¥ä½œæµå®šä¹‰
            workflow_definition = self.workflow_loader.load_from_file(str(workflow_file))
            
            # æ‰§è¡Œå·¥ä½œæµ
            return self.execute_workflow(workflow_definition, initial_variables)
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµæ–‡ä»¶å¤±è´¥ {workflow_file}: {e}")
            raise
    
    def execute_workflow(self, 
                        workflow_definition: WorkflowDefinition,
                        initial_variables: Dict[str, Any] = None) -> WorkflowExecutionResult:
        """
        æ‰§è¡Œå·¥ä½œæµå®šä¹‰
        
        Args:
            workflow_definition: å·¥ä½œæµå®šä¹‰
            initial_variables: åˆå§‹å˜é‡
            
        Returns:
            å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œé™æ€å·¥ä½œæµ: {workflow_definition.workflow_metadata.name}")
            
            # éªŒè¯æ™ºèƒ½ä½“å¯ç”¨æ€§
            self._validate_agents_availability(workflow_definition)
            
            # è®¾ç½®å½“å‰å·¥ä½œæµå®šä¹‰ä¾›æ‰§è¡Œå†å²ä½¿ç”¨
            self.workflow_definition = workflow_definition
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = self.workflow_engine.execute_workflow(workflow_definition, initial_variables)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            if result.success:
                logger.info(f"å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ: {workflow_definition.workflow_metadata.name}")
                logger.info(f"å®Œæˆæ­¥éª¤: {result.completed_steps}/{result.total_steps}")
                logger.info(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
            else:
                logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {workflow_definition.workflow_metadata.name}")
                logger.error(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
            
            return result
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {e}")
            raise
    
    def create_workflow_from_dict(self, workflow_dict: Dict[str, Any]) -> WorkflowDefinition:
        """
        ä»å­—å…¸åˆ›å»ºå·¥ä½œæµå®šä¹‰
        
        Args:
            workflow_dict: å·¥ä½œæµé…ç½®å­—å…¸
            
        Returns:
            å·¥ä½œæµå®šä¹‰å¯¹è±¡
        """
        return self.workflow_loader.load_from_dict(workflow_dict)
    
    def save_workflow_to_file(self, 
                             workflow_definition: WorkflowDefinition,
                             file_path: Union[str, Path]) -> None:
        """
        ä¿å­˜å·¥ä½œæµå®šä¹‰åˆ°æ–‡ä»¶
        
        Args:
            workflow_definition: å·¥ä½œæµå®šä¹‰
            file_path: ä¿å­˜è·¯å¾„
        """
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if not Path(file_path).is_absolute():
            file_path = self.workflow_base_path / file_path
        
        self.workflow_loader.save_to_file(workflow_definition, str(file_path))
    
    def list_available_workflows(self) -> List[str]:
        """
        åˆ—å‡ºå¯ç”¨çš„å·¥ä½œæµé…ç½®æ–‡ä»¶
        
        Returns:
            å·¥ä½œæµæ–‡ä»¶åˆ—è¡¨
        """
        
        if not self.workflow_base_path.exists():
            return []
        
        workflow_files = []
        for file_path in self.workflow_base_path.glob("*.json"):
            workflow_files.append(file_path.name)
        for file_path in self.workflow_base_path.glob("*.yml"):
            workflow_files.append(file_path.name)
        for file_path in self.workflow_base_path.glob("*.yaml"):
            workflow_files.append(file_path.name)
        
        return sorted(workflow_files)
    
    def get_workflow_info(self, workflow_file: Union[str, Path]) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµåŸºæœ¬ä¿¡æ¯
        
        Args:
            workflow_file: å·¥ä½œæµæ–‡ä»¶è·¯å¾„
            
        Returns:
            å·¥ä½œæµä¿¡æ¯å­—å…¸
        """
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if not Path(workflow_file).is_absolute():
            workflow_file = self.workflow_base_path / workflow_file
        
        try:
            workflow_definition = self.workflow_loader.load_from_file(str(workflow_file))
            
            return {
                'name': workflow_definition.workflow_metadata.name,
                'version': workflow_definition.workflow_metadata.version,
                'description': workflow_definition.workflow_metadata.description,
                'author': workflow_definition.workflow_metadata.author,
                'total_steps': len(workflow_definition.steps),
                'step_names': [step.name for step in workflow_definition.steps],
                'required_agents': list(set(step.agent_name for step in workflow_definition.steps)),
                'global_variables': list(workflow_definition.global_variables.keys()),
                'control_rules_count': len(workflow_definition.control_rules)
            }
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµä¿¡æ¯å¤±è´¥ {workflow_file}: {e}")
            raise
    
    def _validate_agents_availability(self, workflow_definition: WorkflowDefinition) -> None:
        """éªŒè¯æ‰€éœ€æ™ºèƒ½ä½“æ˜¯å¦å·²æ³¨å†Œ"""
        
        registered_agent_names = {spec.name for spec in self.registered_agents}
        required_agent_names = {step.agent_name for step in workflow_definition.steps}
        
        missing_agents = required_agent_names - registered_agent_names
        if missing_agents:
            raise ValueError(f"ç¼ºå°‘æ‰€éœ€çš„æ™ºèƒ½ä½“: {', '.join(missing_agents)}")
    
    def _execute_single_step(self, step: WorkflowStep) -> Result:
        """
        æ‰§è¡Œå•ä¸ªå·¥ä½œæµæ­¥éª¤
        
        Args:
            step: å·¥ä½œæµæ­¥éª¤å®šä¹‰
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        
        agent_name = step.agent_name
        instruction = step.instruction
        instruction_type = step.instruction_type
        
        try:
            # æŸ¥æ‰¾æŒ‡å®šçš„æ™ºèƒ½ä½“
            target_agent = None
            for spec in self.registered_agents:
                if spec.name == agent_name:
                    target_agent = spec.instance
                    break
            
            if target_agent is None:
                raise ValueError(f"æ‰¾ä¸åˆ°åä¸º '{agent_name}' çš„æ™ºèƒ½ä½“")
            
            # æ„å»ºåŒ…å«æ‰§è¡Œå†å²çš„æŒ‡ä»¤
            enhanced_instruction = self._build_enhanced_instruction(step)
            
            # æ ¹æ®æŒ‡ä»¤ç±»å‹æ‰§è¡Œ
            if instruction_type == "information":
                # ä¿¡æ¯æ€§ä»»åŠ¡ï¼Œä½¿ç”¨chat_sync
                result = target_agent.chat_sync(enhanced_instruction)
            else:
                # æ‰§è¡Œæ€§ä»»åŠ¡ï¼Œä½¿ç”¨execute_sync
                result = target_agent.execute_sync(enhanced_instruction)
            
            return result
            
        except Exception as e:
            error_msg = f"æ­¥éª¤æ‰§è¡Œå¤±è´¥ {step.id}: {e}"
            logger.error(error_msg)
            return Result(False, instruction, "", error_msg)
    
    def evaluate_condition_with_ai(self, condition: str, last_result: Result) -> bool:
        """
        ä½¿ç”¨AIæ™ºèƒ½è¯„ä¼°æ¡ä»¶è¡¨è¾¾å¼
        
        Args:
            condition: æ¡ä»¶è¡¨è¾¾å¼
            last_result: ä¸Šä¸€æ­¥çš„æ‰§è¡Œç»“æœ
            
        Returns:
            bool: æ¡ä»¶æ˜¯å¦æ»¡è¶³
        """
        
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯AIæ™ºèƒ½è¯„ä¼°æ¡ä»¶
            if "ai_evaluate_test_result" in condition:
                logger.info(f"ä½¿ç”¨AIè¯„ä¼°æµ‹è¯•ç»“æœ: {condition}")
                
                # ä½¿ç”¨æ™ºèƒ½è¯„ä¼°å™¨åˆ¤æ–­æµ‹è¯•ç»“æœ
                evaluation = self.result_evaluator.evaluate_test_result(
                    result_code=getattr(last_result, 'code', None),
                    result_stdout=getattr(last_result, 'stdout', None),
                    result_stderr=getattr(last_result, 'stderr', None),
                    result_return_value=getattr(last_result, 'return_value', None)
                )
                
                result = evaluation["passed"]
                logger.info(f"AIè¯„ä¼°ç»“æœ: {'é€šè¿‡' if result else 'å¤±è´¥'} (ç½®ä¿¡åº¦: {evaluation['confidence']:.2f})")
                logger.debug(f"è¯„ä¼°ç†ç”±: {evaluation['reason']}")
                
                return result
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¼ ç»Ÿçš„successæ¡ä»¶
            elif "last_result.success" in condition:
                # ä¼ ç»Ÿæ¡ä»¶è¯„ä¼°
                if condition == "last_result.success == True":
                    return getattr(last_result, 'success', False)
                elif condition == "last_result.success == False":
                    return not getattr(last_result, 'success', False)
            
            # å…¶ä»–è‡ªå®šä¹‰æ¡ä»¶å¯ä»¥åœ¨è¿™é‡Œæ‰©å±•
            else:
                logger.warning(f"æœªè¯†åˆ«çš„æ¡ä»¶ç±»å‹: {condition}")
                # é»˜è®¤è¿”å›successçŠ¶æ€
                return getattr(last_result, 'success', False)
                
        except Exception as e:
            logger.error(f"æ¡ä»¶è¯„ä¼°å¤±è´¥: {e}")
            # å‡ºé”™æ—¶è¿”å›ä¿å®ˆç»“æœ
            return False
    
    def _on_step_start(self, step: WorkflowStep) -> None:
        """æ­¥éª¤å¼€å§‹å›è°ƒ"""
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œæ­¥éª¤: {step.name} ({step.id})")
        if step.expected_output:
            print(f"   é¢„æœŸè¾“å‡º: {step.expected_output}")
    
    def _on_step_complete(self, step: WorkflowStep, result: Any) -> None:
        """æ­¥éª¤å®Œæˆå›è°ƒ"""
        success_indicator = "âœ…" if (result and getattr(result, 'success', False)) else "âŒ"
        print(f"{success_indicator} æ­¥éª¤å®Œæˆ: {step.name}")
        
        # æ˜¾ç¤ºç®€è¦ç»“æœä¿¡æ¯
        if result and hasattr(result, 'stdout') and result.stdout:
            output_preview = result.stdout[:200] + "..." if len(result.stdout) > 200 else result.stdout
            print(f"   è¾“å‡º: {output_preview}")
    
    def _on_step_failed(self, step: WorkflowStep, error: Exception) -> None:
        """æ­¥éª¤å¤±è´¥å›è°ƒ"""
        print(f"âŒ æ­¥éª¤å¤±è´¥: {step.name}")
        print(f"   é”™è¯¯: {error}")
        
        # å¦‚æœæœ‰é‡è¯•ï¼Œæ˜¾ç¤ºé‡è¯•ä¿¡æ¯
        if step.retry_count < step.max_retries:
            print(f"   å°†è¿›è¡Œç¬¬ {step.retry_count + 1} æ¬¡é‡è¯•...")
    
    def _on_workflow_complete(self, result: WorkflowExecutionResult) -> None:
        """å·¥ä½œæµå®Œæˆå›è°ƒ"""
        if result.success:
            print(f"\nğŸ‰ å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!")
        else:
            print(f"\nğŸ’¥ å·¥ä½œæµæ‰§è¡Œå¤±è´¥!")
        
        print(f"æ€»æ­¥éª¤: {result.total_steps}")
        print(f"å®Œæˆæ­¥éª¤: {result.completed_steps}")
        print(f"å¤±è´¥æ­¥éª¤: {result.failed_steps}")
        print(f"è·³è¿‡æ­¥éª¤: {result.skipped_steps}")
        print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
    
    #TODO: è¿”å›å€¼åº”è¯¥æ˜¯Resultç±»å‹
    @reduce_memory_decorator_compress
    def execute_multi_step(self, main_instruction: str, interactive: bool = False) -> str:
        """
        å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡Œä¸»å…¥å£æ–¹æ³•ï¼ˆæ ‡å‡†æ¥å£å…¼å®¹ï¼‰
        
        åŸºäºä¸»æŒ‡ä»¤è°ƒç”¨LLMç”Ÿæˆé™æ€å·¥ä½œæµé…ç½®ï¼Œç„¶åæ‰§è¡Œã€‚
        
        Args:
            main_instruction: ä¸»ä»»åŠ¡æŒ‡ä»¤
            interactive: æ˜¯å¦äº¤äº’æ¨¡å¼ï¼ˆé™æ€å·¥ä½œæµä¸­æš‚ä¸æ”¯æŒï¼‰
            
        Returns:
            æ‰§è¡Œæ‘˜è¦å­—ç¬¦ä¸²
        """
        
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œå¤šæ­¥éª¤ä»»åŠ¡: {main_instruction}")
            
            # æ­¥éª¤1: è°ƒç”¨LLMç”Ÿæˆå·¥ä½œæµè§„åˆ’
            logger.info("ç”Ÿæˆå·¥ä½œæµè§„åˆ’...")
            workflow_definition = self._generate_workflow_plan(main_instruction)
            
            # æ­¥éª¤2: ä»æŒ‡ä»¤ä¸­æå–åˆå§‹å˜é‡
            initial_variables = self._extract_variables_from_instruction(main_instruction)
            
            # æ­¥éª¤3: æ‰§è¡ŒåŠ¨æ€ç”Ÿæˆçš„å·¥ä½œæµ
            logger.info(f"æ‰§è¡Œç”Ÿæˆçš„å·¥ä½œæµï¼ŒåŒ…å« {len(workflow_definition.steps)} ä¸ªæ­¥éª¤")
            result = self.execute_workflow(workflow_definition, initial_variables)
            
            # æ­¥éª¤4: ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
            return self._generate_dynamic_execution_summary(main_instruction, workflow_definition, result)
            
        except Exception as e:
            error_summary = f"""
## å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡Œå¤±è´¥

**ä¸»æŒ‡ä»¤**: {main_instruction}
**é”™è¯¯**: {str(e)}

### å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ
1. æ£€æŸ¥æŒ‡ä»¤æ˜¯å¦æ¸…æ™°æ˜ç¡®
2. ç¡®è®¤æ‰€éœ€æ™ºèƒ½ä½“æ˜¯å¦å·²æ³¨å†Œ
3. æ£€æŸ¥LLMç”Ÿæˆçš„å·¥ä½œæµæ˜¯å¦æœ‰æ•ˆ

### å·²æ³¨å†Œæ™ºèƒ½ä½“
{', '.join([spec.name for spec in self.registered_agents])}

### å¯ç”¨å·¥ä½œæµæ¨¡æ¿
{', '.join(self.list_available_workflows())}
"""
            logger.error(f"å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            return error_summary
    
    
    def _match_workflow_for_instruction(self, instruction: str) -> str:
        """
        æ ¹æ®æŒ‡ä»¤æ™ºèƒ½åŒ¹é…æœ€åˆé€‚çš„å·¥ä½œæµæ–‡ä»¶
        
        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤
            
        Returns:
            å·¥ä½œæµæ–‡ä»¶å
        """
        
        instruction_lower = instruction.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ç­–ç•¥
        if any(keyword in instruction_lower for keyword in ['è®¡ç®—å™¨', 'calculator', 'åŠ æ³•', 'å‡æ³•', 'ä¹˜æ³•', 'é™¤æ³•']):
            return 'calculator_workflow.json'
        elif any(keyword in instruction_lower for keyword in ['æ•°æ®å¤„ç†', 'data processing', 'æ•°æ®åˆ†æ', 'data analysis']):
            return 'data_processing.json'
        elif any(keyword in instruction_lower for keyword in ['ä»£ç ', 'code', 'æµ‹è¯•', 'test', 'ç¼–ç¨‹', 'programming']):
            return 'code_test_workflow.json'
        else:
            # é»˜è®¤ä½¿ç”¨è®¡ç®—å™¨å·¥ä½œæµï¼ˆä½œä¸ºç¤ºä¾‹ï¼‰
            available_workflows = self.list_available_workflows()
            if available_workflows:
                return available_workflows[0]
            else:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å·¥ä½œæµé…ç½®æ–‡ä»¶")
    
    def _extract_variables_from_instruction(self, instruction: str) -> Dict[str, Any]:
        """
        ä»æŒ‡ä»¤ä¸­æå–å¯èƒ½çš„åˆå§‹å˜é‡
        
        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤
            
        Returns:
            æå–çš„å˜é‡å­—å…¸
        """
        
        variables = {
            'user_instruction': instruction,
            'execution_time': dt.now().isoformat()
        }
        
        # å¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å˜é‡æå–é€»è¾‘
        # ä¾‹å¦‚è§£ææŒ‡ä»¤ä¸­çš„å‚æ•°ã€æ–‡ä»¶åç­‰
        
        return variables
    
    def _get_default_planning_template(self) -> str:
        """è·å–é»˜è®¤çš„è§„åˆ’æç¤ºæ¨¡æ¿"""
        return """
# ä»»åŠ¡èƒŒæ™¯
ä½ æ˜¯ä¸€ä¸ªé™æ€å·¥ä½œæµç”Ÿæˆå™¨ï¼Œè´Ÿè´£å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬æ¢ä¸ºç»“æ„åŒ–çš„é™æ€å·¥ä½œæµé…ç½®ã€‚
ä½ éœ€è¦åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œå°†å…¶åˆ†è§£ä¸ºå¯ä»¥é™æ€æ‰§è¡Œçš„æ­¥éª¤åºåˆ—ï¼Œå¹¶ä¸ºæ¯ä¸ªæ­¥éª¤è®¾è®¡åˆé€‚çš„æ§åˆ¶æµã€‚

# å¯ç”¨æ™ºèƒ½ä½“åˆ—è¡¨
{available_agents_str}

# ä¸»ä»»åŠ¡æŒ‡ä»¤
{main_instruction}

# å·¥ä½œæµè®¾è®¡åŸåˆ™
1. **é™æ€æ€§**: æ‰€æœ‰æ§åˆ¶æµå†³ç­–åœ¨è®¾è®¡æ—¶ç¡®å®šï¼Œä¸ä¾èµ–è¿è¡Œæ—¶LLMåˆ¤æ–­
2. **ç¡®å®šæ€§**: ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒçš„æ‰§è¡Œè·¯å¾„
3. **é«˜æ•ˆæ€§**: é¿å…ä¸å¿…è¦çš„LLMè°ƒç”¨ï¼Œä¸“æ³¨äºä»»åŠ¡æ‰§è¡Œ
4. **å®Œæ•´æ€§**: åŒ…å«é”™è¯¯å¤„ç†ã€é‡è¯•å’ŒéªŒè¯æœºåˆ¶

# æ­¥éª¤åˆ†è§£è¦æ±‚
è¯·å°†ä¸»ä»»åŠ¡åˆ†è§£ä¸ºæœ‰åºçš„æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«:
1. id: æ­¥éª¤å”¯ä¸€æ ‡è¯†ç¬¦ (å¦‚ "step1", "step2", "validate_result" ç­‰)
2. name: ç®€çŸ­çš„æ­¥éª¤åç§°
3. instruction: è¯¦ç»†çš„æ‰§è¡ŒæŒ‡ä»¤ï¼Œéœ€è¦æ¸…æ™°æ˜ç¡®
4. agent_name: æ‰§è¡Œè¯¥æ­¥éª¤çš„æ™ºèƒ½ä½“åç§°ï¼Œå¿…é¡»ä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©: {available_agent_names}
5. instruction_type: æŒ‡ä»¤ç±»å‹ ("execution" æ‰§è¡Œä»£ç ä»»åŠ¡ / "information" ä¿¡æ¯æŸ¥è¯¢ä»»åŠ¡)
6. expected_output: é¢„æœŸè¾“å‡ºæè¿°
7. timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¯é€‰
8. max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º2
9. control_flow: æ§åˆ¶æµé…ç½®ï¼ˆå¯é€‰ï¼Œè§ä¸‹æ–¹è¯´æ˜ï¼‰

# æ§åˆ¶æµç±»å‹è¯´æ˜
- sequential: é¡ºåºæ‰§è¡Œï¼ˆé»˜è®¤ï¼‰
- conditional: æ¡ä»¶åˆ†æ”¯ï¼ŒåŸºäºä¸Šä¸€æ­¥ç»“æœå†³å®šä¸‹ä¸€æ­¥
- loop: å¾ªç¯æ‰§è¡Œï¼Œç”¨äºé‡å¤æ‰§è¡ŒæŸäº›æ­¥éª¤ç›´åˆ°æ»¡è¶³æ¡ä»¶
- parallel: å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ­¥éª¤
- terminal: ç»ˆæ­¢èŠ‚ç‚¹

# é‡è¦ï¼šå¾ªç¯æ§åˆ¶ä¸æ­¥éª¤é‡è¯•çš„åŒºåˆ«
- **æ­¥éª¤é‡è¯•**ï¼šå•ä¸ªæ­¥éª¤å¤±è´¥æ—¶çš„è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œç”± `max_retries` æ§åˆ¶
- **å·¥ä½œæµå¾ªç¯**ï¼šå¤šä¸ªæ­¥éª¤ä¹‹é—´çš„å¾ªç¯æµç¨‹ï¼Œç”± `loop_condition` æ§åˆ¶
- ä¸è¦å°†è¿™ä¸¤ä¸ªæ¦‚å¿µæ··åˆä½¿ç”¨ï¼

# æ§åˆ¶æµé…ç½®ç¤ºä¾‹

## conditionalç±»å‹ - æ¡ä»¶åˆ†æ”¯
æ”¯æŒä¸¤ç§é…ç½®æ–¹å¼ï¼š

### æ–¹å¼1ï¼šAIå¸ƒå°”å­—æ®µï¼ˆæ¨èï¼‰
```json
"control_flow": {{
  "type": "conditional",
  "ai_evaluate_test_result": true,
  "ai_confidence_threshold": 0.8,
  "ai_fallback_condition": "last_result.success == True",
  "success_next": "next_step_id",
  "failure_next": "error_handling_step"
}}
```

### æ–¹å¼2ï¼šä¼ ç»Ÿæ¡ä»¶è¡¨è¾¾å¼
```json
"control_flow": {{
  "type": "conditional", 
  "condition": "ai_evaluate_test_result == True",
  "success_next": "next_step_id",
  "failure_next": "error_handling_step"
}}
```

# AIè¯„ä¼°é…ç½®è¯´æ˜
- `ai_evaluate_test_result`: true/falseï¼Œæ˜¯å¦å¯ç”¨AIæ™ºèƒ½è¯„ä¼°æµ‹è¯•ç»“æœ
- `ai_confidence_threshold`: 0.0-1.0ï¼ŒAIè¯„ä¼°ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼å°†ä½¿ç”¨fallbackæ¡ä»¶
- `ai_fallback_condition`: å½“AIè¯„ä¼°å¤±è´¥æˆ–ç½®ä¿¡åº¦ä¸å¤Ÿæ—¶çš„å›é€€æ¡ä»¶
- å­—ç¬¦ä¸²æ¡ä»¶ `"ai_evaluate_test_result == True"`: å…¼å®¹æ—§ç‰ˆæœ¬çš„å­—ç¬¦ä¸²æ–¹å¼
- ä¼ ç»Ÿæ¡ä»¶ `"last_result.success == True"`: ä»…åˆ¤æ–­æ­¥éª¤æ˜¯å¦æˆåŠŸæ‰§è¡Œ

# æ¡ä»¶é…ç½®å»ºè®®
1. å¯¹äºæµ‹è¯•ã€éªŒè¯ã€æ„å»ºç­‰æ­¥éª¤ï¼Œä¼˜å…ˆä½¿ç”¨AIå¸ƒå°”å­—æ®µæ–¹å¼
2. ç®€å•åœºæ™¯ç”¨å¸ƒå°”å­—æ®µï¼Œå¤æ‚åœºæ™¯å¯ç»„åˆæ¡ä»¶è¡¨è¾¾å¼
3. å§‹ç»ˆè®¾ç½®fallbackæ¡ä»¶ç¡®ä¿å¯é æ€§

## loopç±»å‹ - å¾ªç¯æ§åˆ¶
```json
"control_flow": {{
  "type": "loop",
  "loop_condition": null,
  "loop_target": "step3", 
  "max_iterations": 3,
  "exit_on_max": "error_handling"
}}
```

# å¾ªç¯æ§åˆ¶æœ€ä½³å®è·µ
- **æ¨èæ–¹å¼**ï¼šä½¿ç”¨ `max_iterations` è®¾ç½®å¾ªç¯æ¬¡æ•°ä¸Šé™ï¼Œ`loop_condition` è®¾ä¸º null
- **è®¾ç½®å‡ºå£**ï¼šå¿…é¡»è®¾ç½® `exit_on_max` æŒ‡å®šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°åçš„è·³è½¬æ­¥éª¤
- **é¿å…å¤æ‚æ¡ä»¶**ï¼šä¸è¦ä½¿ç”¨å¤æ‚çš„å·¥ä½œæµçŠ¶æ€å˜é‡ï¼ˆå¦‚ `workflow_state.fix_attempts`ï¼‰
- **ä¿æŒç®€å•**ï¼šä¼˜å…ˆä½¿ç”¨å¼•æ“å†…ç½®çš„å¾ªç¯æ§åˆ¶æœºåˆ¶
- åŒºåˆ†æ­¥éª¤é‡è¯•ï¼ˆ`max_retries`ï¼‰å’Œå·¥ä½œæµå¾ªç¯ï¼ˆ`max_iterations`ï¼‰

# è¾“å‡ºæ ¼å¼
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºå®Œæ•´çš„å·¥ä½œæµé…ç½®:
```json
{{
  "workflow_metadata": {{
    "name": "dynamic_workflow_task",
    "version": "1.0", 
    "description": "åŸºäºç”¨æˆ·æŒ‡ä»¤åŠ¨æ€ç”Ÿæˆçš„å·¥ä½œæµ",
    "author": "MultiStepAgent_v3"
  }},
  "global_variables": {{
    "max_retries": 3,
    "timeout": 300
  }},
  "steps": [
    {{
      "id": "step1",
      "name": "æ­¥éª¤åç§°",
      "agent_name": "{first_agent_name}",
      "instruction": "è¯¦ç»†çš„æ‰§è¡ŒæŒ‡ä»¤...",
      "instruction_type": "execution",
      "expected_output": "é¢„æœŸè¾“å‡º",
      "timeout": 120,
      "max_retries": 2,
      "control_flow": {{
        "type": "sequential",
        "success_next": "step2",
        "failure_next": "error_handling"
      }}
    }}
  ],
  "control_rules": [
    {{
      "trigger": "execution_time > 600",
      "action": "terminate",
      "target": "error_handling",
      "priority": 1
    }}
  ],
  "error_handling": {{
    "default_strategy": "retry_with_analysis"
  }}
}}
```

# é‡è¦æç¤º
- æ¯ä¸ªæ­¥éª¤éƒ½è¦æŒ‡å®šåˆé€‚çš„æ™ºèƒ½ä½“
- ç¡®ä¿æ­¥éª¤ä¹‹é—´çš„æ•°æ®æµåŠ¨æ¸…æ™°
- ä¸ºå¯èƒ½å¤±è´¥çš„æ­¥éª¤è®¾è®¡é‡è¯•å’Œé”™è¯¯å¤„ç†
- æ¡ä»¶è¡¨è¾¾å¼ä½¿ç”¨ `last_result.success` åˆ¤æ–­ä¸Šä¸€æ­¥æ˜¯å¦æˆåŠŸ
- æ­¥éª¤æŒ‡ä»¤è¦è¯¦ç»†å…·ä½“ï¼Œä¾¿äºæ™ºèƒ½ä½“ç†è§£å’Œæ‰§è¡Œ
"""

    def _generate_workflow_plan(self, main_instruction: str) -> WorkflowDefinition:
        """
        è°ƒç”¨LLMç”Ÿæˆå·¥ä½œæµè§„åˆ’
        
        Args:
            main_instruction: ä¸»ä»»åŠ¡æŒ‡ä»¤
            
        Returns:
            å·¥ä½œæµå®šä¹‰å¯¹è±¡
        """
        
        # å‡†å¤‡æ™ºèƒ½ä½“ä¿¡æ¯
        available_agents_str = "\\n".join([
            f"- {spec.name}: {spec.description}" 
            for spec in self.registered_agents
        ])
        
        available_agent_names = [spec.name for spec in self.registered_agents]
        first_agent_name = available_agent_names[0] if available_agent_names else "æ™ºèƒ½ä½“åç§°"
        
        # æ ¼å¼åŒ–è§„åˆ’æç¤º
        planning_prompt = self.planning_prompt_template.format(
            available_agents_str=available_agents_str,
            main_instruction=main_instruction,
            available_agent_names=', '.join(available_agent_names),
            first_agent_name=first_agent_name
        )
        
        logger.debug(f"ç”Ÿæˆè§„åˆ’æç¤ºï¼Œé•¿åº¦: {len(planning_prompt)} å­—ç¬¦")
        
        try:
            # ä½¿ç”¨JSONæ ¼å¼çº¦æŸ
            response_format = {"type": "json_object"}
            
            # è°ƒç”¨LLMç”Ÿæˆè§„åˆ’
            result = self.chat_sync(planning_prompt, response_format=response_format)
            
            if result.success:
                plan_result = result.return_value if result.return_value else result.stdout
            else:
                logger.warning(f"chat_syncè¿”å›å¤±è´¥: {result.stderr}")
                # å›é€€åˆ°æ— æ ¼å¼çº¦æŸæ–¹å¼
                result = self.chat_sync(planning_prompt)
                plan_result = result.return_value if result.return_value else result.stdout
            
            # è§£æJSONå“åº”
            workflow_data = self._parse_llm_workflow_response(plan_result)
            
            # æ ¡éªŒå·¥ä½œæµåˆæ³•æ€§
            validation_result = self._validate_workflow_legality(workflow_data)
            
            if not validation_result["is_valid"]:
                logger.warning(f"å·¥ä½œæµæ ¡éªŒå¤±è´¥: {validation_result['errors']}")
                # å°è¯•ä¿®å¤æˆ–é‡æ–°ç”Ÿæˆ
                workflow_data = self._fix_workflow_issues(workflow_data, validation_result["errors"])
            
            # éªŒè¯å’Œè½¬æ¢ä¸ºWorkflowDefinition
            workflow_definition = self._validate_and_convert_workflow(workflow_data, main_instruction)
            
            logger.info(f"æˆåŠŸç”ŸæˆåŒ…å« {len(workflow_definition.steps)} ä¸ªæ­¥éª¤çš„å·¥ä½œæµ")
            return workflow_definition
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµè§„åˆ’ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°é¢„è®¾æ¨¡æ¿
            return self._create_fallback_workflow(main_instruction)
    
    def _parse_llm_workflow_response(self, response: str) -> Dict[str, Any]:
        """
        è§£æLLMè¿”å›çš„å·¥ä½œæµJSONå“åº”
        
        Args:
            response: LLMå“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„å·¥ä½œæµæ•°æ®å­—å…¸
        """
        
        try:
            # å°è¯•ä»autogenæå–ä»£ç å—
            try:
                from autogen.code_utils import extract_code
                extracted_codes = extract_code(response)
                if extracted_codes:
                    workflow_data = json.loads(extracted_codes[0][1])
                    return workflow_data
            except ImportError:
                logger.debug("autogenä¸å¯ç”¨ï¼Œä½¿ç”¨æ‰‹åŠ¨è§£æ")
            
            # æ‰‹åŠ¨æå–JSONä»£ç å—
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                if end > start:
                    json_str = response[start:end].strip()
                    return json.loads(json_str)
            
            # ç›´æ¥è§£ææ•´ä¸ªå“åº”
            return json.loads(response)
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}, å“åº”å†…å®¹: {response[:500]}...")
            raise ValueError(f"æ— æ³•è§£æLLMè¿”å›çš„å·¥ä½œæµJSON: {e}")
    
    def _validate_and_convert_workflow(self, workflow_data: Dict[str, Any], main_instruction: str) -> WorkflowDefinition:
        """
        éªŒè¯å¹¶è½¬æ¢å·¥ä½œæµæ•°æ®ä¸ºWorkflowDefinitionå¯¹è±¡
        
        Args:
            workflow_data: å·¥ä½œæµæ•°æ®å­—å…¸
            main_instruction: åŸå§‹ä¸»æŒ‡ä»¤
            
        Returns:
            éªŒè¯åçš„å·¥ä½œæµå®šä¹‰å¯¹è±¡
        """
        
        # ç¡®ä¿åŒ…å«å¿…è¦å­—æ®µ
        if "steps" not in workflow_data:
            raise ValueError("å·¥ä½œæµæ•°æ®ç¼ºå°‘stepså­—æ®µ")
        
        # è®¾ç½®é»˜è®¤å…ƒæ•°æ®
        if "workflow_metadata" not in workflow_data:
            workflow_data["workflow_metadata"] = {
                "name": "dynamic_generated_workflow",
                "version": "1.0",
                "description": f"åŸºäºæŒ‡ä»¤åŠ¨æ€ç”Ÿæˆ: {main_instruction[:100]}...",
                "author": "MultiStepAgent_v3"
            }
        
        # è®¾ç½®é»˜è®¤å…¨å±€å˜é‡
        if "global_variables" not in workflow_data:
            workflow_data["global_variables"] = {
                "max_retries": 3,
                "timeout": 300
            }
        
        # éªŒè¯æ™ºèƒ½ä½“åç§°
        available_agent_names = {spec.name for spec in self.registered_agents}
        for step in workflow_data["steps"]:
            if step.get("agent_name") not in available_agent_names:
                logger.warning(f"æ­¥éª¤ {step.get('id')} ä½¿ç”¨äº†æœªæ³¨å†Œçš„æ™ºèƒ½ä½“: {step.get('agent_name')}")
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ™ºèƒ½ä½“ä½œä¸ºæ›¿ä»£
                if available_agent_names:
                    step["agent_name"] = next(iter(available_agent_names))
        
        # è‡ªåŠ¨ä¿®å¤æ­¥éª¤å¼•ç”¨é—®é¢˜
        self._fix_workflow_references(workflow_data)
        
        # ä½¿ç”¨WorkflowLoaderåˆ›å»ºWorkflowDefinition
        return self.workflow_loader.load_from_dict(workflow_data)
    
    def _create_fallback_workflow(self, main_instruction: str) -> WorkflowDefinition:
        """
        åˆ›å»ºå›é€€å·¥ä½œæµï¼ˆå½“LLMç”Ÿæˆå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            main_instruction: ä¸»ä»»åŠ¡æŒ‡ä»¤
            
        Returns:
            ç®€å•çš„å›é€€å·¥ä½œæµå®šä¹‰
        """
        
        first_agent_name = self.registered_agents[0].name if self.registered_agents else "default_agent"
        
        fallback_workflow_data = {
            "workflow_metadata": {
                "name": "fallback_workflow",
                "version": "1.0", 
                "description": f"å›é€€å·¥ä½œæµ: {main_instruction}",
                "author": "MultiStepAgent_v3"
            },
            "global_variables": {
                "max_retries": 3,
                "timeout": 300
            },
            "steps": [
                {
                    "id": "execute_task",
                    "name": "æ‰§è¡Œä¸»ä»»åŠ¡",
                    "agent_name": first_agent_name,
                    "instruction": main_instruction,
                    "instruction_type": "execution",
                    "expected_output": "ä»»åŠ¡æ‰§è¡Œç»“æœ",
                    "timeout": 300,
                    "max_retries": 2,
                    "control_flow": {
                        "type": "terminal"
                    }
                }
            ],
            "control_rules": [],
            "error_handling": {
                "default_strategy": "retry_with_analysis"
            }
        }
        
        logger.info("ä½¿ç”¨å›é€€å·¥ä½œæµï¼Œå°†æ•´ä¸ªä»»åŠ¡åˆ†é…ç»™å•ä¸ªæ™ºèƒ½ä½“æ‰§è¡Œ")
        return self.workflow_loader.load_from_dict(fallback_workflow_data)
    
    def _generate_dynamic_execution_summary(self, 
                                          main_instruction: str,
                                          workflow_definition: WorkflowDefinition, 
                                          result: WorkflowExecutionResult) -> str:
        """
        ç”ŸæˆåŠ¨æ€å·¥ä½œæµæ‰§è¡Œæ‘˜è¦
        
        Args:
            main_instruction: åŸå§‹ä¸»æŒ‡ä»¤
            workflow_definition: å·¥ä½œæµå®šä¹‰
            result: æ‰§è¡Œç»“æœ
            
        Returns:
            æ‰§è¡Œæ‘˜è¦å­—ç¬¦ä¸²
        """
        
        summary = f"""
## å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡Œæ‘˜è¦

**åŸå§‹æŒ‡ä»¤**: {main_instruction}
**ç”Ÿæˆå·¥ä½œæµ**: {result.workflow_name}
**æ‰§è¡ŒçŠ¶æ€**: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}
**æ€»æ­¥éª¤æ•°**: {result.total_steps}
**å®Œæˆæ­¥éª¤**: {result.completed_steps}
**å¤±è´¥æ­¥éª¤**: {result.failed_steps}
**è·³è¿‡æ­¥éª¤**: {result.skipped_steps}
**æ‰§è¡Œæ—¶é—´**: {result.execution_time:.2f}ç§’

### ç”Ÿæˆçš„å·¥ä½œæµæ­¥éª¤
"""
        
        for i, step in enumerate(workflow_definition.steps, 1):
            summary += f"{i}. **{step.name}** ({step.id}) - æ‰§è¡Œè€…: {step.agent_name}\\n"
            summary += f"   æŒ‡ä»¤ç±»å‹: {step.instruction_type}\\n"
            if step.expected_output:
                summary += f"   é¢„æœŸè¾“å‡º: {step.expected_output}\\n"
            summary += f"\\n"
        
        summary += "### æ‰§è¡Œè¯¦æƒ…\\n"
        
        for step_id, step_info in result.step_results.items():
            status_icon = {
                'completed': 'âœ…',
                'failed': 'âŒ', 
                'skipped': 'â­ï¸',
                'pending': 'â¸ï¸',
                'running': 'ğŸ”„'
            }.get(step_info['status'], 'â“')
            
            summary += f"- {status_icon} **{step_info['name']}** ({step_id}): {step_info['status']}\\n"
            
            if step_info['error_message']:
                summary += f"  - é”™è¯¯: {step_info['error_message']}\\n"
            
            if step_info['retry_count'] > 0:
                summary += f"  - é‡è¯•æ¬¡æ•°: {step_info['retry_count']}\\n"
        
        if not result.success and result.error_message:
            summary += f"\\n**é”™è¯¯ä¿¡æ¯**: {result.error_message}\\n"
        
        return summary
    
    def _fix_workflow_references(self, workflow_data: Dict[str, Any]) -> None:
        """
        è‡ªåŠ¨ä¿®å¤å·¥ä½œæµä¸­çš„æ­¥éª¤å¼•ç”¨é—®é¢˜
        
        Args:
            workflow_data: å·¥ä½œæµæ•°æ®å­—å…¸ï¼ˆä¼šè¢«å°±åœ°ä¿®æ”¹ï¼‰
        """
        
        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„æ­¥éª¤ID
        steps = workflow_data.get("steps", [])
        valid_step_ids = {step.get("id") for step in steps if step.get("id") is not None}
        
        # ç¡®ä¿valid_step_idsä¸ä¸ºç©ºï¼Œé¿å…åç»­NoneTypeé”™è¯¯
        if not valid_step_ids:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ­¥éª¤IDï¼Œè·³è¿‡å¼•ç”¨ä¿®å¤")
            return
        
        # ä¿®å¤æ­¥éª¤ä¸­çš„æ§åˆ¶æµå¼•ç”¨
        for i, step in enumerate(steps):
            step_id = step.get("id")
            control_flow = step.get("control_flow", {})
            
            # å¦‚æœæ²¡æœ‰æ§åˆ¶æµï¼Œä¸”ä¸æ˜¯æœ€åä¸€æ­¥ï¼Œåˆ™è®¾ç½®ä¸ºsequentialæŒ‡å‘ä¸‹ä¸€æ­¥
            if not control_flow and i < len(steps) - 1:
                next_step_id = steps[i + 1].get("id")
                step["control_flow"] = {
                    "type": "sequential",
                    "success_next": next_step_id,
                    "failure_next": None
                }
                logger.debug(f"ä¸ºæ­¥éª¤ {step_id} æ·»åŠ é»˜è®¤sequentialæ§åˆ¶æµï¼ŒæŒ‡å‘ {next_step_id}")
                continue
            elif not control_flow and i == len(steps) - 1:
                # æœ€åä¸€æ­¥è®¾ç½®ä¸ºterminal
                step["control_flow"] = {"type": "terminal"}
                logger.debug(f"ä¸ºæœ€åæ­¥éª¤ {step_id} è®¾ç½®terminalæ§åˆ¶æµ")
                continue
            
            # ä¿®å¤success_nextå¼•ç”¨
            if "success_next" in control_flow:
                if control_flow["success_next"] and control_flow["success_next"] not in valid_step_ids:
                    logger.warning(f"ä¿®å¤æ­¥éª¤ {step_id} çš„æ— æ•ˆsuccess_nextå¼•ç”¨: {control_flow['success_next']}")
                    # å°è¯•æŒ‡å‘ä¸‹ä¸€ä¸ªé¡ºåºæ­¥éª¤
                    if i < len(steps) - 1:
                        control_flow["success_next"] = steps[i + 1].get("id")
                    else:
                        control_flow["success_next"] = None
            
            # ä¿®å¤failure_nextå¼•ç”¨
            if "failure_next" in control_flow:
                if control_flow["failure_next"] and control_flow["failure_next"] not in valid_step_ids:
                    logger.warning(f"ä¿®å¤æ­¥éª¤ {step_id} çš„æ— æ•ˆfailure_nextå¼•ç”¨: {control_flow['failure_next']}")
                    # å¯¹äºå¤±è´¥æƒ…å†µï¼Œè®¾ç½®ä¸ºNoneï¼ˆå°†ä¾èµ–é»˜è®¤è¡Œä¸ºï¼‰
                    control_flow["failure_next"] = None
            
            # ä¿®å¤loop_targetå¼•ç”¨
            if "loop_target" in control_flow:
                if control_flow["loop_target"] and control_flow["loop_target"] not in valid_step_ids:
                    logger.warning(f"ä¿®å¤æ­¥éª¤ {step_id} çš„æ— æ•ˆloop_targetå¼•ç”¨: {control_flow['loop_target']}")
                    control_flow["loop_target"] = step_id  # æŒ‡å‘è‡ªå·±
            
            # ä¿®å¤exit_on_maxå¼•ç”¨
            if "exit_on_max" in control_flow:
                if control_flow["exit_on_max"] and control_flow["exit_on_max"] not in valid_step_ids:
                    logger.warning(f"ä¿®å¤æ­¥éª¤ {step_id} çš„æ— æ•ˆexit_on_maxå¼•ç”¨: {control_flow['exit_on_max']}")
                    # å¯¹äºexit_on_maxï¼Œåº”è¯¥æŒ‡å‘ç»ˆæ­¢æ­¥éª¤è€Œä¸æ˜¯è®¾ä¸ºNone
                    terminal_step_id = self._find_or_create_terminal_step(steps, valid_step_ids)
                    control_flow["exit_on_max"] = terminal_step_id
                    logger.info(f"å°†æ­¥éª¤ {step_id} çš„ exit_on_max è®¾ç½®ä¸ºç»ˆæ­¢æ­¥éª¤: {terminal_step_id}")
            
            # ä¿®å¤parallel_stepså¼•ç”¨
            if "parallel_steps" in control_flow:
                parallel_steps = control_flow.get("parallel_steps", [])
                if isinstance(parallel_steps, list) and parallel_steps:
                    valid_parallel_steps = []
                    for parallel_step_id in parallel_steps:
                        # ç¡®ä¿parallel_step_idä¸ä¸ºNoneä¸”åœ¨valid_step_idsä¸­
                        if parallel_step_id is not None and parallel_step_id in valid_step_ids:
                            valid_parallel_steps.append(parallel_step_id)
                        else:
                            logger.warning(f"ç§»é™¤æ­¥éª¤ {step_id} ä¸­çš„æ— æ•ˆparallel_stepså¼•ç”¨: {parallel_step_id}")
                    
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„å¹¶è¡Œæ­¥éª¤ï¼Œå°†ç±»å‹æ”¹ä¸ºsequential
                    if not valid_parallel_steps:
                        logger.warning(f"æ­¥éª¤ {step_id} æ²¡æœ‰æœ‰æ•ˆçš„å¹¶è¡Œæ­¥éª¤ï¼Œæ”¹ä¸ºsequentialç±»å‹")
                        control_flow["type"] = "sequential"
                        if i < len(steps) - 1:
                            control_flow["success_next"] = steps[i + 1].get("id")
                        control_flow.pop("parallel_steps", None)
                    else:
                        control_flow["parallel_steps"] = valid_parallel_steps
            
            # ç¡®ä¿æ§åˆ¶æµç±»å‹æ­£ç¡®
            if "type" not in control_flow:
                if i < len(steps) - 1:
                    control_flow["type"] = "sequential"
                else:
                    control_flow["type"] = "terminal"
                logger.debug(f"ä¸ºæ­¥éª¤ {step_id} è®¾ç½®é»˜è®¤æ§åˆ¶æµç±»å‹: {control_flow['type']}")
        
        # ä¿®å¤æ§åˆ¶è§„åˆ™ä¸­çš„ç›®æ ‡å¼•ç”¨
        control_rules = workflow_data.get("control_rules", [])
        valid_rules = []
        for rule in control_rules:
            if "target" in rule:
                if rule["target"] not in valid_step_ids:
                    logger.warning(f"ç§»é™¤æ§åˆ¶è§„åˆ™ä¸­çš„æ— æ•ˆtargetå¼•ç”¨: {rule['target']}")
                else:
                    valid_rules.append(rule)
            else:
                valid_rules.append(rule)
        
        workflow_data["control_rules"] = valid_rules
        logger.debug("å·¥ä½œæµå¼•ç”¨ä¿®å¤å®Œæˆ")
    
    def _build_enhanced_instruction(self, current_step: WorkflowStep) -> str:
        """
        æ„å»ºåŒ…å«æ‰§è¡Œå†å²çš„å¢å¼ºæŒ‡ä»¤
        
        Args:
            current_step: å½“å‰è¦æ‰§è¡Œçš„æ­¥éª¤
            
        Returns:
            åŒ…å«å†å²ä¸Šä¸‹æ–‡çš„å¢å¼ºæŒ‡ä»¤
        """
        
        # è·å–å·²å®Œæˆæ­¥éª¤çš„å†å²
        execution_history = self._get_execution_history(current_step)
        
        # æ„å»ºåŸºæœ¬æŒ‡ä»¤ä¿¡æ¯
        enhanced_instruction = f"""# å·¥ä½œæµæ­¥éª¤æ‰§è¡Œ

## å½“å‰æ­¥éª¤ä¿¡æ¯
- æ­¥éª¤ID: {current_step.id}
- æ­¥éª¤åç§°: {current_step.name}
- æ‰§è¡Œè€…: {current_step.agent_name}
- æŒ‡ä»¤ç±»å‹: {current_step.instruction_type}
- é¢„æœŸè¾“å‡º: {current_step.expected_output}
"""
        
        # æ·»åŠ æ‰§è¡Œå†å²
        if execution_history:
            enhanced_instruction += f"""
## æ‰§è¡Œå†å²ä¸Šä¸‹æ–‡
ä»¥ä¸‹æ˜¯ä¹‹å‰å·²å®Œæˆçš„æ­¥éª¤åŠå…¶ç»“æœï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯æ‰§è¡Œå½“å‰ä»»åŠ¡ï¼š

{execution_history}
"""
        
        # æ·»åŠ å½“å‰æ‰§è¡ŒæŒ‡ä»¤
        enhanced_instruction += f"""
## å½“å‰ä»»åŠ¡æŒ‡ä»¤
{current_step.instruction}

## é‡è¦æç¤º
- è¯·åŸºäºä¸Šè¿°æ‰§è¡Œå†å²çš„ç»“æœæ¥æ‰§è¡Œå½“å‰ä»»åŠ¡
- é¿å…é‡å¤ä¹‹å‰å·²å®Œæˆçš„å·¥ä½œ
- ç¡®ä¿ä¸å‰é¢æ­¥éª¤çš„è¾“å‡ºä¿æŒä¸€è‡´æ€§
- å¦‚æœæ˜¯ä»£ç ç›¸å…³ä»»åŠ¡ï¼Œè¯·ç¡®ä¿ä»£ç çš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§
- å¦‚æœéœ€è¦å¼•ç”¨å‰é¢æ­¥éª¤çš„ç»“æœï¼Œè¯·æ˜ç¡®è¯´æ˜æ¥æº
"""
        
        return enhanced_instruction
    
    def _get_execution_history(self, current_step: WorkflowStep) -> str:
        """
        è·å–å½“å‰æ­¥éª¤ä¹‹å‰çš„æ‰§è¡Œå†å²
        
        Args:
            current_step: å½“å‰æ­¥éª¤
            
        Returns:
            æ ¼å¼åŒ–çš„æ‰§è¡Œå†å²å­—ç¬¦ä¸²
        """
        
        if not self.workflow_definition:
            return ""
        
        history_parts = []
        current_step_index = None
        
        # æ‰¾åˆ°å½“å‰æ­¥éª¤çš„ç´¢å¼•
        for i, step in enumerate(self.workflow_definition.steps):
            if step.id == current_step.id:
                current_step_index = i
                break
        
        if current_step_index is None:
            return ""
        
        # æ”¶é›†å·²å®Œæˆçš„æ­¥éª¤å†å²
        for i in range(current_step_index):
            step = self.workflow_definition.steps[i]
            
            # åªåŒ…å«å·²å®Œæˆçš„æ­¥éª¤
            if hasattr(step, 'status') and step.status and step.status.value == 'completed':
                history_part = f"""
### æ­¥éª¤ {i+1}: {step.name} ({step.id})
- **æ‰§è¡Œè€…**: {step.agent_name}
- **æŒ‡ä»¤ç±»å‹**: {step.instruction_type}
- **åŸå§‹æŒ‡ä»¤**: {step.instruction[:200]}{'...' if len(step.instruction) > 200 else ''}
"""
                
                # æ·»åŠ æ‰§è¡Œç»“æœ
                if hasattr(step, 'result') and step.result:
                    result = step.result
                    if hasattr(result, 'success') and result.success:
                        history_part += f"- **æ‰§è¡ŒçŠ¶æ€**: âœ… æˆåŠŸ\n"
                        
                        # æ·»åŠ ä»£ç ç»“æœ
                        if hasattr(result, 'code') and result.code:
                            code_preview = result.code[:500] + "..." if len(result.code) > 500 else result.code
                            history_part += f"- **ç”Ÿæˆä»£ç **:\n```python\n{code_preview}\n```\n"
                        
                        # æ·»åŠ è¾“å‡ºç»“æœ
                        if hasattr(result, 'stdout') and result.stdout:
                            output_preview = result.stdout[:300] + "..." if len(result.stdout) > 300 else result.stdout
                            history_part += f"- **è¾“å‡ºç»“æœ**: {output_preview}\n"
                        
                        if hasattr(result, 'return_value') and result.return_value:
                            return_preview = str(result.return_value)[:200] + "..." if len(str(result.return_value)) > 200 else str(result.return_value)
                            history_part += f"- **è¿”å›å€¼**: {return_preview}\n"
                    else:
                        history_part += f"- **æ‰§è¡ŒçŠ¶æ€**: âŒ å¤±è´¥\n"
                        if hasattr(result, 'stderr') and result.stderr:
                            error_preview = result.stderr[:200] + "..." if len(result.stderr) > 200 else result.stderr
                            history_part += f"- **é”™è¯¯ä¿¡æ¯**: {error_preview}\n"
                else:
                    history_part += f"- **æ‰§è¡ŒçŠ¶æ€**: â¸ï¸ å¾…å¤„ç†\n"
                
                history_parts.append(history_part)
        
        if not history_parts:
            return "æš‚æ— æ‰§è¡Œå†å²ï¼ˆè¿™æ˜¯ç¬¬ä¸€ä¸ªæ­¥éª¤ï¼‰"
        
        return "\n".join(history_parts)
    
    def _validate_workflow_legality(self, workflow_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¡éªŒå·¥ä½œæµçš„åˆæ³•æ€§
        
        Args:
            workflow_data: å·¥ä½œæµæ•°æ®å­—å…¸
            
        Returns:
            æ ¡éªŒç»“æœå­—å…¸ {"is_valid": bool, "errors": List[str]}
        """
        
        errors = []
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if "steps" not in workflow_data:
            errors.append("ç¼ºå°‘å¿…è¦å­—æ®µ: steps")
            return {"is_valid": False, "errors": errors}
        
        steps = workflow_data["steps"]
        if not steps:
            errors.append("å·¥ä½œæµè‡³å°‘éœ€è¦åŒ…å«ä¸€ä¸ªæ­¥éª¤")
            return {"is_valid": False, "errors": errors}
        
        # æ”¶é›†æ‰€æœ‰æ­¥éª¤ID
        step_ids = set()
        for step in steps:
            if "id" not in step:
                errors.append(f"æ­¥éª¤ç¼ºå°‘idå­—æ®µ: {step}")
                continue
            step_ids.add(step["id"])
        
        # ç¡®ä¿step_idsä¸ä¸ºç©ºï¼Œé¿å…åç»­NoneTypeé”™è¯¯
        if not step_ids:
            errors.append("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ­¥éª¤ID")
            return {"is_valid": False, "errors": errors}
        
        # æ£€æŸ¥æ™ºèƒ½ä½“åç§°
        available_agent_names = {spec.name for spec in self.registered_agents}
        for step in steps:
            agent_name = step.get("agent_name")
            if agent_name and agent_name not in available_agent_names:
                errors.append(f"æ­¥éª¤ {step.get('id')} ä½¿ç”¨äº†æœªæ³¨å†Œçš„æ™ºèƒ½ä½“: {agent_name}")
        
        # æ£€æŸ¥æ§åˆ¶æµå¼•ç”¨
        for step in steps:
            step_id = step.get("id")
            control_flow = step.get("control_flow", {})
            
            # æ£€æŸ¥success_nextå¼•ç”¨
            success_next = control_flow.get("success_next")
            if success_next and success_next not in step_ids:
                errors.append(f"æ­¥éª¤ {step_id} çš„ success_next å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ­¥éª¤: {success_next}")
            
            # æ£€æŸ¥failure_nextå¼•ç”¨
            failure_next = control_flow.get("failure_next")
            if failure_next and failure_next not in step_ids:
                errors.append(f"æ­¥éª¤ {step_id} çš„ failure_next å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ­¥éª¤: {failure_next}")
            
            # æ£€æŸ¥loop_targetå¼•ç”¨
            loop_target = control_flow.get("loop_target")
            if loop_target and loop_target not in step_ids:
                errors.append(f"æ­¥éª¤ {step_id} çš„ loop_target å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ­¥éª¤: {loop_target}")
            
            # æ£€æŸ¥exit_on_maxå¼•ç”¨
            exit_on_max = control_flow.get("exit_on_max")
            if exit_on_max and exit_on_max not in step_ids:
                errors.append(f"æ­¥éª¤ {step_id} çš„ exit_on_max å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ­¥éª¤: {exit_on_max}")
            
            # æ£€æŸ¥parallel_stepså¼•ç”¨
            parallel_steps = control_flow.get("parallel_steps", [])
            for parallel_step_id in parallel_steps:
                if parallel_step_id not in step_ids:
                    errors.append(f"æ­¥éª¤ {step_id} çš„ parallel_steps å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ­¥éª¤: {parallel_step_id}")
        
        # æ£€æŸ¥æ§åˆ¶è§„åˆ™å¼•ç”¨
        control_rules = workflow_data.get("control_rules", [])
        for rule in control_rules:
            target = rule.get("target")
            if target and target not in step_ids:
                errors.append(f"æ§åˆ¶è§„åˆ™çš„ target å¼•ç”¨äº†ä¸å­˜åœ¨çš„æ­¥éª¤: {target}")
        
        # æ£€æŸ¥å¾ªç¯é€»è¾‘å†²çª
        self._check_loop_logic_conflicts(steps, errors)
        
        # æ£€æŸ¥å¾ªç¯å¼•ç”¨ï¼ˆç®€å•æ£€æŸ¥ï¼‰
        self._check_circular_references(steps, errors)
        
        is_valid = len(errors) == 0
        return {"is_valid": is_valid, "errors": errors}
    
    def _check_loop_logic_conflicts(self, steps: List[Dict], errors: List[str]) -> None:
        """æ£€æŸ¥å¾ªç¯é€»è¾‘å†²çª"""
        
        for step in steps:
            step_id = step.get("id")
            control_flow = step.get("control_flow", {})
            
            # åªæ£€æŸ¥ç±»å‹ä¸ºloopçš„æ­¥éª¤
            if control_flow.get("type") != "loop":
                continue
            
            loop_condition = control_flow.get("loop_condition", "")
            max_retries = step.get("max_retries", 0)
            max_iterations = control_flow.get("max_iterations", 0)
            
            # ç¡®ä¿loop_conditionä¸ä¸ºNoneï¼Œé¿å…NoneTypeé”™è¯¯
            if loop_condition is None:
                loop_condition = ""
            
            # æ£€æŸ¥æ˜¯å¦æ··ç”¨äº†æ­¥éª¤é‡è¯•å’Œå·¥ä½œæµå¾ªç¯æ¦‚å¿µ
            if loop_condition and "retry_count" in loop_condition and "max_retries" in loop_condition:
                errors.append(f"æ­¥éª¤ {step_id} çš„å¾ªç¯æ¡ä»¶é”™è¯¯ä½¿ç”¨äº†æ­¥éª¤é‡è¯•æœºåˆ¶ 'retry_count < max_retries'ï¼Œåº”ä½¿ç”¨å·¥ä½œæµçŠ¶æ€å˜é‡")
            
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶è®¾ç½®äº†max_retrieså’Œmax_iterationsä¸”å€¼ä¸ä¸€è‡´
            if max_retries > 0 and max_iterations > 0 and max_retries != max_iterations:
                errors.append(f"æ­¥éª¤ {step_id} åŒæ—¶è®¾ç½®äº† max_retries({max_retries}) å’Œ max_iterations({max_iterations})ï¼Œè¿™å¯èƒ½å¯¼è‡´é€»è¾‘å†²çª")
            
            # æ£€æŸ¥å¾ªç¯æ¡ä»¶æ˜¯å¦ä¸ºç©º
            if not loop_condition:
                errors.append(f"æ­¥éª¤ {step_id} çš„å¾ªç¯ç±»å‹ç¼ºå°‘ loop_condition")
            
            # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å¾ªç¯ç›®æ ‡
            if not control_flow.get("loop_target"):
                errors.append(f"æ­¥éª¤ {step_id} çš„å¾ªç¯ç±»å‹ç¼ºå°‘ loop_target")
            
            # æ£€æŸ¥å¾ªç¯æ¡ä»¶æ ¼å¼
            if loop_condition and not any(keyword in loop_condition for keyword in ['workflow_state', 'iteration_count', '<', '>', '==']):
                errors.append(f"æ­¥éª¤ {step_id} çš„å¾ªç¯æ¡ä»¶æ ¼å¼å¯èƒ½æœ‰è¯¯: {loop_condition}")

    def _check_circular_references(self, steps: List[Dict], errors: List[str]) -> None:
        """æ£€æŸ¥å¾ªç¯å¼•ç”¨ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
        
        # æ„å»ºæ­¥éª¤ä¾èµ–å›¾
        dependencies = {}
        for step in steps:
            step_id = step.get("id")
            if not step_id:
                continue
                
            deps = set()
            control_flow = step.get("control_flow", {})
            
            # æ·»åŠ success_nextä¾èµ–
            if control_flow.get("success_next"):
                deps.add(control_flow["success_next"])
            
            # æ·»åŠ failure_nextä¾èµ–
            if control_flow.get("failure_next"):
                deps.add(control_flow["failure_next"])
            
            # loop_targetä¸ç®—å¾ªç¯å¼•ç”¨ï¼ˆè¿™æ˜¯é¢„æœŸçš„å¾ªç¯ï¼‰
            
            dependencies[step_id] = deps
        
        # ç®€å•çš„å¾ªç¯æ£€æµ‹ï¼ˆå¯ä»¥æ”¹è¿›ä¸ºæ›´å¤æ‚çš„ç®—æ³•ï¼‰
        for step_id, deps in dependencies.items():
            if step_id in deps:
                errors.append(f"æ­¥éª¤ {step_id} å­˜åœ¨è‡ªå¼•ç”¨")
    
    def _fix_workflow_issues(self, workflow_data: Dict[str, Any], errors: List[str]) -> Dict[str, Any]:
        """
        ä¿®å¤å·¥ä½œæµé—®é¢˜
        
        Args:
            workflow_data: æœ‰é—®é¢˜çš„å·¥ä½œæµæ•°æ®
            errors: æ ¡éªŒé”™è¯¯åˆ—è¡¨
            
        Returns:
            ä¿®å¤åçš„å·¥ä½œæµæ•°æ®
        """
        
        logger.info(f"å¼€å§‹ä¿®å¤å·¥ä½œæµé—®é¢˜ï¼Œå…± {len(errors)} ä¸ªé”™è¯¯")
        
        # ä½¿ç”¨ç°æœ‰çš„ä¿®å¤æœºåˆ¶
        self._fix_workflow_references(workflow_data)
        
        # é’ˆå¯¹ç‰¹å®šé”™è¯¯ç±»å‹è¿›è¡Œä¿®å¤
        for error in errors:
            if "æœªæ³¨å†Œçš„æ™ºèƒ½ä½“" in error:
                self._fix_agent_references(workflow_data)
            elif "ç¼ºå°‘å¿…è¦å­—æ®µ" in error:
                self._add_missing_fields(workflow_data)
            elif "å¾ªç¯æ¡ä»¶é”™è¯¯ä½¿ç”¨äº†æ­¥éª¤é‡è¯•æœºåˆ¶" in error or "å¾ªç¯é€»è¾‘å†²çª" in error:
                self._fix_loop_configuration(workflow_data)
        
        logger.info(f"å·¥ä½œæµé—®é¢˜ä¿®å¤å®Œæˆ")
        return workflow_data
    
    def _fix_agent_references(self, workflow_data: Dict[str, Any]) -> None:
        """ä¿®å¤æ™ºèƒ½ä½“å¼•ç”¨é—®é¢˜"""
        
        if not self.registered_agents:
            return
        
        default_agent = self.registered_agents[0].name
        
        for step in workflow_data.get("steps", []):
            agent_name = step.get("agent_name")
            if not agent_name or agent_name not in {spec.name for spec in self.registered_agents}:
                step["agent_name"] = default_agent
                logger.debug(f"ä¿®å¤æ­¥éª¤ {step.get('id')} çš„æ™ºèƒ½ä½“å¼•ç”¨ä¸º: {default_agent}")
    
    def _add_missing_fields(self, workflow_data: Dict[str, Any]) -> None:
        """æ·»åŠ ç¼ºå¤±çš„å¿…è¦å­—æ®µ"""
        
        if "workflow_metadata" not in workflow_data:
            workflow_data["workflow_metadata"] = {
                "name": "auto_generated_workflow",
                "version": "1.0",
                "description": "è‡ªåŠ¨ç”Ÿæˆçš„å·¥ä½œæµ",
                "author": "MultiStepAgent_v3"
            }
        
        if "global_variables" not in workflow_data:
            workflow_data["global_variables"] = {
                "max_retries": 3,
                "timeout": 300
            }
        
        if "steps" not in workflow_data:
            workflow_data["steps"] = []
        
        # ç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½æœ‰å¿…è¦å­—æ®µ
        for i, step in enumerate(workflow_data["steps"]):
            if "id" not in step:
                step["id"] = f"step_{i+1}"
            if "name" not in step:
                step["name"] = f"æ­¥éª¤ {i+1}"
            if "agent_name" not in step and self.registered_agents:
                step["agent_name"] = self.registered_agents[0].name
            if "instruction_type" not in step:
                step["instruction_type"] = "execution"
    
    def _fix_loop_configuration(self, workflow_data: Dict[str, Any]) -> None:
        """ä¿®å¤å¾ªç¯é…ç½®é—®é¢˜"""
        
        steps = workflow_data.get("steps", [])
        
        for step in steps:
            step_id = step.get("id")
            control_flow = step.get("control_flow", {})
            
            # åªä¿®å¤å¾ªç¯ç±»å‹çš„æ­¥éª¤
            if control_flow.get("type") != "loop":
                continue
            
            loop_condition = control_flow.get("loop_condition", "")
            
            # ä¿®å¤é”™è¯¯çš„å¾ªç¯æ¡ä»¶ï¼ˆæ­¥éª¤é‡è¯•æœºåˆ¶ï¼‰
            if "retry_count" in loop_condition and "max_retries" in loop_condition:
                logger.warning(f"ä¿®å¤æ­¥éª¤ {step_id} çš„é”™è¯¯å¾ªç¯æ¡ä»¶: {loop_condition}")
                # æ›¿æ¢ä¸ºæ­£ç¡®çš„å·¥ä½œæµçŠ¶æ€å˜é‡
                control_flow["loop_condition"] = "workflow_state.fix_attempts < 3"
                control_flow["max_iterations"] = 3
                # æ¸…é™¤å¯èƒ½å†²çªçš„æ­¥éª¤çº§é‡è¯•è®¾ç½®
                if step.get("max_retries", 0) > 0:
                    step["max_retries"] = 0
                    logger.debug(f"æ¸…é™¤æ­¥éª¤ {step_id} çš„ max_retries ä»¥é¿å…ä¸å¾ªç¯é€»è¾‘å†²çª")
            
            # ç¡®ä¿å¾ªç¯æ­¥éª¤æœ‰å¿…è¦çš„å­—æ®µ
            if not control_flow.get("loop_condition"):
                control_flow["loop_condition"] = "workflow_state.iteration_count < 3"
                logger.debug(f"ä¸ºæ­¥éª¤ {step_id} æ·»åŠ é»˜è®¤å¾ªç¯æ¡ä»¶")
            
            if not control_flow.get("loop_target"):
                # å°è¯•æ‰¾åˆ°å‰ä¸€ä¸ªæ­¥éª¤ä½œä¸ºå¾ªç¯ç›®æ ‡
                step_ids = [s.get("id") for s in steps]
                try:
                    current_index = step_ids.index(step_id)
                    if current_index > 0:
                        control_flow["loop_target"] = step_ids[current_index - 1]
                    else:
                        control_flow["loop_target"] = step_id  # æŒ‡å‘è‡ªå·±
                    logger.debug(f"ä¸ºæ­¥éª¤ {step_id} è®¾ç½®å¾ªç¯ç›®æ ‡: {control_flow['loop_target']}")
                except ValueError:
                    control_flow["loop_target"] = step_id
            
            if not control_flow.get("max_iterations"):
                control_flow["max_iterations"] = 3
                logger.debug(f"ä¸ºæ­¥éª¤ {step_id} è®¾ç½®é»˜è®¤æœ€å¤§è¿­ä»£æ¬¡æ•°: 3")
            
            # å¦‚æœåŒæ—¶è®¾ç½®äº†max_retrieså’Œmax_iterationsä¸”ä¸ä¸€è‡´ï¼Œç»Ÿä¸€ä¸ºmax_iterations
            max_retries = step.get("max_retries", 0)
            max_iterations = control_flow.get("max_iterations", 0)
            if max_retries > 0 and max_iterations > 0 and max_retries != max_iterations:
                logger.warning(f"æ­¥éª¤ {step_id} çš„ max_retries({max_retries}) ä¸ max_iterations({max_iterations}) ä¸ä¸€è‡´ï¼Œç»Ÿä¸€ä¸º max_iterations")
                step["max_retries"] = 0  # æ¸…é™¤æ­¥éª¤çº§é‡è¯•ï¼Œä½¿ç”¨å¾ªç¯è¿­ä»£
            
            logger.info(f"ä¿®å¤æ­¥éª¤ {step_id} çš„å¾ªç¯é…ç½®å®Œæˆ")
    
    def _find_or_create_terminal_step(self, steps: List[Dict], valid_step_ids: set) -> str:
        """
        æŸ¥æ‰¾æˆ–åˆ›å»ºç»ˆæ­¢æ­¥éª¤
        
        Args:
            steps: æ­¥éª¤åˆ—è¡¨
            valid_step_ids: æœ‰æ•ˆçš„æ­¥éª¤IDé›†åˆ
            
        Returns:
            ç»ˆæ­¢æ­¥éª¤çš„ID
        """
        
        # é¦–å…ˆæŸ¥æ‰¾ç°æœ‰çš„ç»ˆæ­¢æ­¥éª¤
        for step in steps:
            control_flow = step.get("control_flow", {})
            if control_flow.get("type") == "terminal":
                step_id = step.get("id")
                if step_id in valid_step_ids:
                    logger.debug(f"æ‰¾åˆ°ç°æœ‰çš„ç»ˆæ­¢æ­¥éª¤: {step_id}")
                    return step_id
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»ˆæ­¢æ­¥éª¤ï¼ŒæŸ¥æ‰¾æœ€åä¸€ä¸ªæ­¥éª¤å¹¶å°†å…¶è®¾ä¸ºç»ˆæ­¢æ­¥éª¤
        if steps:
            last_step = steps[-1]
            last_step_id = last_step.get("id")
            
            if last_step_id and last_step_id in valid_step_ids:
                # å°†æœ€åä¸€ä¸ªæ­¥éª¤çš„æ§åˆ¶æµè®¾ç½®ä¸ºterminal
                if "control_flow" not in last_step:
                    last_step["control_flow"] = {}
                last_step["control_flow"]["type"] = "terminal"
                
                logger.info(f"å°†æœ€åä¸€ä¸ªæ­¥éª¤è®¾ç½®ä¸ºç»ˆæ­¢æ­¥éª¤: {last_step_id}")
                return last_step_id
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰åˆé€‚çš„æ­¥éª¤ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ç»ˆæ­¢æ­¥éª¤
        terminal_step_id = "workflow_end"
        
        # ç¡®ä¿æ–°æ­¥éª¤IDä¸ä¸ç°æœ‰IDå†²çª
        counter = 1
        while terminal_step_id in valid_step_ids:
            terminal_step_id = f"workflow_end_{counter}"
            counter += 1
        
        # åˆ›å»ºç»ˆæ­¢æ­¥éª¤
        terminal_step = {
            "id": terminal_step_id,
            "name": "å·¥ä½œæµç»“æŸ",
            "agent_name": self.registered_agents[0].name if self.registered_agents else "default_agent",
            "instruction": "å·¥ä½œæµæ‰§è¡Œç»“æŸï¼Œæ•´ç†å’Œæ±‡æ€»æ‰§è¡Œç»“æœ",
            "instruction_type": "information",
            "expected_output": "å·¥ä½œæµæ‰§è¡Œæ‘˜è¦",
            "timeout": 60,
            "max_retries": 1,
            "control_flow": {
                "type": "terminal"
            }
        }
        
        # å°†æ–°æ­¥éª¤æ·»åŠ åˆ°æ­¥éª¤åˆ—è¡¨
        steps.append(terminal_step)
        valid_step_ids.add(terminal_step_id)
        
        logger.info(f"åˆ›å»ºæ–°çš„ç»ˆæ­¢æ­¥éª¤: {terminal_step_id}")
        return terminal_step_id