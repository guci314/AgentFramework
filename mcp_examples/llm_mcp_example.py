#!/usr/bin/env python3
"""
è¯­è¨€æ¨¡å‹è°ƒç”¨ MCP çš„å®Œæ•´ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•å°†è¯­è¨€æ¨¡å‹ä¸ MCP æœåŠ¡å™¨é›†æˆ
"""

import asyncio
import json
import subprocess
import sys
from typing import Dict, List, Any, Optional
import anthropic
import openai
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

class MCPClient:
    """MCP å®¢æˆ·ç«¯å°è£…"""
    
    def __init__(self, server_command: List[str]):
        self.server_command = server_command
        self.session: Optional[ClientSession] = None
        self.available_tools = []
        self.available_resources = []
        self.available_prompts = []
    
    async def connect(self):
        """è¿æ¥åˆ° MCP æœåŠ¡å™¨"""
        print(f"è¿æ¥åˆ° MCP æœåŠ¡å™¨: {' '.join(self.server_command)}")
        
        server_params = StdioServerParameters(
            command=self.server_command[0],
            args=self.server_command[1:] if len(self.server_command) > 1 else []
        )
        
        self.session = await stdio_client(server_params)
        
        # åˆå§‹åŒ–è¿æ¥
        await self.session.initialize()
        
        # è·å–å¯ç”¨å·¥å…·ã€èµ„æºå’Œæç¤º
        await self.refresh_capabilities()
        
        print(f"âœ… æˆåŠŸè¿æ¥åˆ° MCP æœåŠ¡å™¨")
        print(f"ğŸ“‹ å¯ç”¨å·¥å…·: {len(self.available_tools)}")
        print(f"ğŸ“ å¯ç”¨èµ„æº: {len(self.available_resources)}")  
        print(f"ğŸ“ å¯ç”¨æç¤º: {len(self.available_prompts)}")
    
    async def refresh_capabilities(self):
        """åˆ·æ–°æœåŠ¡å™¨èƒ½åŠ›"""
        if not self.session:
            raise RuntimeError("æœªè¿æ¥åˆ°æœåŠ¡å™¨")
        
        # è·å–å·¥å…·åˆ—è¡¨
        tools_result = await self.session.list_tools()
        self.available_tools = tools_result.tools
        
        # è·å–èµ„æºåˆ—è¡¨
        try:
            resources_result = await self.session.list_resources()
            self.available_resources = resources_result.resources
        except:
            self.available_resources = []
        
        # è·å–æç¤ºåˆ—è¡¨
        try:
            prompts_result = await self.session.list_prompts()
            self.available_prompts = prompts_result.prompts
        except:
            self.available_prompts = []
    
    async def call_tool(self, name: str, arguments: Dict[str, Any]) -> str:
        """è°ƒç”¨ MCP å·¥å…·"""
        if not self.session:
            raise RuntimeError("æœªè¿æ¥åˆ°æœåŠ¡å™¨")
        
        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {name}")
        print(f"ğŸ“ å‚æ•°: {json.dumps(arguments, ensure_ascii=False, indent=2)}")
        
        result = await self.session.call_tool(name, arguments)
        
        # æå–æ–‡æœ¬å†…å®¹
        content_parts = []
        for content in result.content:
            if hasattr(content, 'text'):
                content_parts.append(content.text)
            else:
                content_parts.append(str(content))
        
        response = "\n".join(content_parts)
        print(f"âœ… å·¥å…·å“åº”: {response}")
        return response
    
    async def read_resource(self, uri: str) -> str:
        """è¯»å– MCP èµ„æº"""
        if not self.session:
            raise RuntimeError("æœªè¿æ¥åˆ°æœåŠ¡å™¨")
        
        print(f"ğŸ“ è¯»å–èµ„æº: {uri}")
        result = await self.session.read_resource(uri)
        
        content = ""
        for item in result.contents:
            if hasattr(item, 'text'):
                content += item.text
            else:
                content += str(item)
        
        print(f"âœ… èµ„æºå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        return content
    
    async def get_prompt(self, name: str, arguments: Dict[str, str]) -> str:
        """è·å–æç¤ºæ¨¡æ¿"""
        if not self.session:
            raise RuntimeError("æœªè¿æ¥åˆ°æœåŠ¡å™¨")
        
        print(f"ğŸ“ è·å–æç¤º: {name}")
        result = await self.session.get_prompt(name, arguments)
        
        # æå–æç¤ºå†…å®¹
        prompt_parts = []
        for message in result.messages:
            if hasattr(message.content, 'text'):
                prompt_parts.append(message.content.text)
            else:
                prompt_parts.append(str(message.content))
        
        prompt = "\n".join(prompt_parts)
        print(f"âœ… æç¤ºæ¨¡æ¿é•¿åº¦: {len(prompt)} å­—ç¬¦")
        return prompt
    
    def get_tools_for_llm(self) -> List[Dict[str, Any]]:
        """è·å–é€‚ç”¨äºè¯­è¨€æ¨¡å‹çš„å·¥å…·å®šä¹‰"""
        tools = []
        for tool in self.available_tools:
            tools.append({
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.inputSchema
            })
        return tools
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.session:
            await self.session.close()
            print("ğŸ”Œ å·²æ–­å¼€ MCP è¿æ¥")

class LLMWithMCP:
    """é›†æˆäº† MCP çš„è¯­è¨€æ¨¡å‹"""
    
    def __init__(self, mcp_client: MCPClient, llm_type: str = "anthropic"):
        self.mcp_client = mcp_client
        self.llm_type = llm_type
        
        # åˆå§‹åŒ–è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯
        if llm_type == "anthropic":
            self.anthropic_client = anthropic.Anthropic(
                api_key="your-anthropic-api-key"  # æ›¿æ¢ä¸ºå®é™…APIå¯†é’¥
            )
        elif llm_type == "openai":
            self.openai_client = openai.OpenAI(
                api_key="your-openai-api-key"  # æ›¿æ¢ä¸ºå®é™…APIå¯†é’¥
            )
    
    async def chat_with_tools(self, user_message: str, system_prompt: str = None) -> str:
        """ä¸è¯­è¨€æ¨¡å‹å¯¹è¯ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨"""
        
        # æ„å»ºç³»ç»Ÿæç¤º
        if system_prompt is None:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å¤šç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚

å¯ç”¨çš„ MCP å·¥å…·ï¼š
"""
            for tool in self.mcp_client.available_tools:
                system_prompt += f"- {tool.name}: {tool.description}\n"
            
            system_prompt += "\nè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚"
        
        # è·å–å·¥å…·å®šä¹‰
        tools = self.mcp_client.get_tools_for_llm()
        
        print(f"ğŸ¤– å‘é€æ¶ˆæ¯ç»™ {self.llm_type.upper()}")
        print(f"ğŸ’¬ ç”¨æˆ·æ¶ˆæ¯: {user_message}")
        
        if self.llm_type == "anthropic":
            return await self._chat_anthropic(user_message, system_prompt, tools)
        elif self.llm_type == "openai":
            return await self._chat_openai(user_message, system_prompt, tools)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€æ¨¡å‹ç±»å‹: {self.llm_type}")
    
    async def _chat_anthropic(self, user_message: str, system_prompt: str, tools: List[Dict]) -> str:
        """ä½¿ç”¨ Anthropic Claude è¿›è¡Œå¯¹è¯"""
        # è½¬æ¢å·¥å…·æ ¼å¼ä¸º Claude æ ¼å¼
        claude_tools = []
        for tool in tools:
            claude_tools.append({
                "name": tool["name"],
                "description": tool["description"],
                "input_schema": tool["input_schema"]
            })
        
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1000,
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}],
                tools=claude_tools
            )
            
            # å¤„ç†å“åº”
            response_text = ""
            
            for content in response.content:
                if content.type == "text":
                    response_text += content.text
                elif content.type == "tool_use":
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_name = content.name
                    tool_input = content.input
                    
                    print(f"ğŸ”§ Claude è¯·æ±‚è°ƒç”¨å·¥å…·: {tool_name}")
                    
                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await self.mcp_client.call_tool(tool_name, tool_input)
                    
                    # å°†ç»“æœæ·»åŠ åˆ°å“åº”ä¸­
                    response_text += f"\n\n[å·¥å…·è°ƒç”¨ç»“æœ]\n{tool_result}"
            
            return response_text
            
        except Exception as e:
            return f"Claude è°ƒç”¨å‡ºé”™: {str(e)}"
    
    async def _chat_openai(self, user_message: str, system_prompt: str, tools: List[Dict]) -> str:
        """ä½¿ç”¨ OpenAI GPT è¿›è¡Œå¯¹è¯"""
        # è½¬æ¢å·¥å…·æ ¼å¼ä¸º OpenAI æ ¼å¼
        openai_tools = []
        for tool in tools:
            openai_tools.append({
                "type": "function",
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": tool["input_schema"]
                }
            })
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                tools=openai_tools,
                tool_choice="auto"
            )
            
            message = response.choices[0].message
            response_text = message.content or ""
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if message.tool_calls:
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)
                    
                    print(f"ğŸ”§ GPT è¯·æ±‚è°ƒç”¨å·¥å…·: {tool_name}")
                    
                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await self.mcp_client.call_tool(tool_name, tool_args)
                    
                    # å°†ç»“æœæ·»åŠ åˆ°å“åº”ä¸­
                    response_text += f"\n\n[å·¥å…·è°ƒç”¨ç»“æœ]\n{tool_result}"
            
            return response_text
            
        except Exception as e:
            return f"OpenAI è°ƒç”¨å‡ºé”™: {str(e)}"

async def demo_llm_mcp_integration():
    """æ¼”ç¤ºè¯­è¨€æ¨¡å‹ä¸ MCP çš„é›†æˆ"""
    
    print("=" * 60)
    print("ğŸš€ è¯­è¨€æ¨¡å‹ + MCP é›†æˆæ¼”ç¤º")
    print("=" * 60)
    
    # 1. å¯åŠ¨ MCP å®¢æˆ·ç«¯
    mcp_client = MCPClient(["python", "mcp_example/server.py"])
    
    try:
        await mcp_client.connect()
        
        # 2. åˆ›å»ºé›†æˆäº† MCP çš„è¯­è¨€æ¨¡å‹
        # æ³¨æ„ï¼šéœ€è¦æä¾›çœŸå®çš„ API å¯†é’¥
        llm = LLMWithMCP(mcp_client, llm_type="anthropic")  # æˆ– "openai"
        
        # 3. æ¼”ç¤ºå¯¹è¯åœºæ™¯
        test_scenarios = [
            "å¸®æˆ‘è®¡ç®— 15 + 27 ç­‰äºå¤šå°‘",
            "è¯·å°†ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“ä¸­ï¼Œé”®åä¸º 'calculation_result'",
            "ç°åœ¨å‘Šè¯‰æˆ‘æ•°æ®åº“ä¸­æœ‰ä»€ä¹ˆæ•°æ®",
            "å¸®æˆ‘åˆ†æä¸€ä¸‹æ–‡æœ¬ 'Hello MCP World' çš„å­—ç¬¦æ•°å’Œå•è¯æ•°",
            "è·å–å½“å‰æ—¶é—´"
        ]
        
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\nğŸ“‹ åœºæ™¯ {i}: {scenario}")
            print("-" * 40)
            
            try:
                # æ¨¡æ‹Ÿè°ƒç”¨ï¼ˆå› ä¸ºéœ€è¦çœŸå®çš„ API å¯†é’¥ï¼‰
                print("ğŸ¤– [æ¨¡æ‹Ÿ] è¯­è¨€æ¨¡å‹åˆ†æè¯·æ±‚...")
                
                # ç›´æ¥è°ƒç”¨ MCP å·¥å…·æ¼”ç¤º
                if "è®¡ç®—" in scenario:
                    result = await mcp_client.call_tool("add", {"a": 15, "b": 27})
                elif "å­˜å‚¨" in scenario:
                    result = await mcp_client.call_tool("add", {"a": 42, "b": 0})  # å‡è®¾ç»“æœæ˜¯42
                    print(f"ğŸ’¾ å­˜å‚¨ç»“æœ: calculation_result = {42}")
                elif "æ•°æ®åº“" in scenario:
                    # æ¼”ç¤ºè¯»å–èµ„æº
                    print("ğŸ“ è¯»å–æ•°æ®å­˜å‚¨èµ„æº...")
                elif "åˆ†ææ–‡æœ¬" in scenario:
                    print("ğŸ“ åˆ†ææ–‡æœ¬å†…å®¹...")
                elif "æ—¶é—´" in scenario:
                    print("â° è·å–å½“å‰æ—¶é—´...")
                
                print(f"âœ… åœºæ™¯å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ åœºæ™¯æ‰§è¡Œå‡ºé”™: {str(e)}")
            
            # ç­‰å¾…ä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çœ‹æ¸…è¾“å‡º
            await asyncio.sleep(1)
        
        # 4. æ¼”ç¤ºèµ„æºè®¿é—®
        print(f"\nğŸ“ æ¼”ç¤ºèµ„æºè®¿é—®")
        print("-" * 40)
        
        for resource in mcp_client.available_resources:
            print(f"ğŸ“„ èµ„æº: {resource.name} ({resource.uri})")
        
        # 5. æ¼”ç¤ºæç¤ºæ¨¡æ¿
        print(f"\nğŸ“ æ¼”ç¤ºæç¤ºæ¨¡æ¿")
        print("-" * 40)
        
        for prompt in mcp_client.available_prompts:
            print(f"ğŸ“‹ æ¨¡æ¿: {prompt.name} - {prompt.description}")
    
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        await mcp_client.close()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")

def create_simple_mcp_demo():
    """åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„ MCP æ¼”ç¤ºï¼ˆä¸éœ€è¦çœŸå®çš„è¯­è¨€æ¨¡å‹ APIï¼‰"""
    
    demo_code = '''
# ç®€åŒ–çš„ MCP è°ƒç”¨æ¼”ç¤º
import asyncio
import json

async def simple_mcp_demo():
    """ç®€å•çš„ MCP å·¥å…·è°ƒç”¨æ¼”ç¤º"""
    
    # æ¨¡æ‹Ÿ MCP å·¥å…·è°ƒç”¨
    tools_results = {
        "calculator": {
            "operation": "add",
            "a": 15,
            "b": 27,
            "result": "è®¡ç®—ç»“æœ: 15 + 27 = 42"
        },
        "text_analysis": {
            "text": "Hello MCP World",
            "result": "å­—ç¬¦æ•°: 15, å•è¯æ•°: 3"
        },
        "data_storage": {
            "action": "set",
            "key": "demo_key", 
            "value": "demo_value",
            "result": "å·²å­˜å‚¨: demo_key = demo_value"
        }
    }
    
    print("ğŸ”§ MCP å·¥å…·è°ƒç”¨æ¼”ç¤º:")
    for tool, data in tools_results.items():
        print(f"\\nå·¥å…·: {tool}")
        print(f"å‚æ•°: {json.dumps(data, ensure_ascii=False, indent=2)}")
        print(f"ç»“æœ: {data['result']}")

# è¿è¡Œæ¼”ç¤º
asyncio.run(simple_mcp_demo())
'''
    
    print("ğŸ“ ç®€åŒ–ç‰ˆ MCP æ¼”ç¤ºä»£ç :")
    print("-" * 40)
    print(demo_code)

if __name__ == "__main__":
    print("é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
    print("1. å®Œæ•´æ¼”ç¤º (éœ€è¦ MCP æœåŠ¡å™¨)")
    print("2. ç®€åŒ–æ¼”ç¤º (çº¯ä»£ç )")
    
    choice = input("è¯·é€‰æ‹© (1/2): ").strip()
    
    if choice == "1":
        # è¿è¡Œå®Œæ•´æ¼”ç¤º
        asyncio.run(demo_llm_mcp_integration())
    elif choice == "2":
        # æ˜¾ç¤ºç®€åŒ–æ¼”ç¤º
        create_simple_mcp_demo()
    else:
        print("æ— æ•ˆé€‰æ‹©") 