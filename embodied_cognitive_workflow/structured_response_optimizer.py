#!/usr/bin/env python3
"""
ç»“æ„åŒ–å“åº”ä¼˜åŒ–å™¨
ä½¿ç”¨ response_format å’Œ JSON schema ç¡®ä¿ç¨³å®šçš„ JSON è¾“å‡º

è¿™ä¸ªæ¨¡å—æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ OpenAI çš„ response_format å‚æ•°
å’Œå®Œæ•´çš„ JSON schema æ¥è·å¾—ç¨³å®šå¯é çš„ JSON å“åº”ã€‚
"""

import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
from datetime import datetime
import logging

# JSON Schema å®šä¹‰
STRATEGY_OPTIMIZATION_SCHEMA = {
    "type": "object",
    "properties": {
        "analysis": {
            "type": "string",
            "description": "å¯¹å½“å‰ç­–ç•¥çš„åˆ†æç»“æœ"
        },
        "strategies": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "å»ºè®®çš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨",
            "minItems": 1,
            "maxItems": 5
        },
        "priority": {
            "type": "string",
            "enum": ["high", "medium", "low"],
            "description": "å®æ–½ä¼˜å…ˆçº§"
        },
        "confidence": {
            "type": "number",
            "minimum": 0.0,
            "maximum": 1.0,
            "description": "å»ºè®®çš„ç½®ä¿¡åº¦åˆ†æ•°"
        }
    },
    "required": ["analysis", "strategies", "priority", "confidence"],
    "additionalProperties": False
}

STRATEGY_REGULATION_SCHEMA = {
    "type": "object",
    "properties": {
        "assessment": {
            "type": "string",
            "description": "å¯¹å½“å‰ç­–ç•¥çš„è¯„ä¼°"
        },
        "adjustment_needed": {
            "type": "boolean",
            "description": "æ˜¯å¦éœ€è¦è°ƒæ•´ç­–ç•¥"
        },
        "recommended_strategy": {
            "type": "string",
            "description": "æ¨èçš„ç­–ç•¥"
        },
        "confidence": {
            "type": "number",
            "minimum": 0.0,
            "maximum": 1.0,
            "description": "è¯„ä¼°çš„ç½®ä¿¡åº¦"
        },
        "reasoning": {
            "type": "string",
            "description": "è¯„ä¼°çš„ç†ç”±"
        }
    },
    "required": ["assessment", "adjustment_needed", "recommended_strategy", "confidence"],
    "additionalProperties": False
}

REFLECTION_SCHEMA = {
    "type": "object",
    "properties": {
        "lessons": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "ä»ç»éªŒä¸­å­¦åˆ°çš„ç»éªŒæ•™è®­",
            "minItems": 1,
            "maxItems": 5
        },
        "suggestions": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "æ”¹è¿›å»ºè®®",
            "minItems": 1,
            "maxItems": 5
        },
        "quality": {
            "type": "number",
            "minimum": 0.0,
            "maximum": 1.0,
            "description": "åæ€è´¨é‡è¯„åˆ†"
        },
        "insights": {
            "type": "string",
            "description": "å…³é”®æ´å¯Ÿ"
        }
    },
    "required": ["lessons", "suggestions", "quality"],
    "additionalProperties": False
}

META_LEARNING_SCHEMA = {
    "type": "object",
    "properties": {
        "success_patterns": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "æˆåŠŸæ¨¡å¼åˆ—è¡¨",
            "minItems": 1
        },
        "failure_causes": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "å¤±è´¥åŸå› åˆ—è¡¨",
            "minItems": 1
        },
        "insights": {
            "type": "string",
            "description": "å­¦ä¹ æ´å¯Ÿ"
        },
        "recommendations": {
            "type": "array",
            "items": {
                "type": "string"
            },
            "description": "åŸºäºå­¦ä¹ çš„å»ºè®®",
            "minItems": 1
        }
    },
    "required": ["success_patterns", "failure_causes", "insights"],
    "additionalProperties": False
}


class StructuredResponseOptimizer:
    """ç»“æ„åŒ–å“åº”ä¼˜åŒ–å™¨"""
    
    def __init__(self, llm, logger: Optional[logging.Logger] = None):
        self.llm = llm
        self.logger = logger or logging.getLogger(__name__)
    
    def _safe_json_dumps(self, data: Any) -> str:
        """å®‰å…¨åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ï¼Œå¤„ç†datetimeç­‰ç‰¹æ®Šå¯¹è±¡"""
        def json_serializer(obj):
            if isinstance(obj, datetime):
                return obj.isoformat()
            raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
        
        try:
            result = json.dumps(data, ensure_ascii=False, indent=2, default=json_serializer)
            # é™åˆ¶è¾“å‡ºé•¿åº¦ä»¥é¿å…æç¤ºè¿‡é•¿
            if len(result) > 1000:
                self.logger.debug(f"JSONåºåˆ—åŒ–ç»“æœè¿‡é•¿({len(result)}å­—ç¬¦)ï¼Œè¿›è¡Œæˆªæ–­")
                return json.dumps(str(data)[:500] + "...(æˆªæ–­)", ensure_ascii=False)
            return result
        except Exception as e:
            self.logger.warning(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}, ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
            return str(data)[:300]  # é™åˆ¶é•¿åº¦
    
    def _call_llm_with_schema(self, prompt: str, schema: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ JSON schema è°ƒç”¨ LLM"""
        try:
            # å°è¯•ä½¿ç”¨ OpenAI çš„ response_format
            if hasattr(self.llm, 'client') and hasattr(self.llm.client, 'chat'):
                try:
                    # ç›´æ¥ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯çš„ JSON mode
                    response = self.llm.client.chat.completions.create(
                        model=self.llm.model_name or "gpt-3.5-turbo",
                        messages=[{"role": "user", "content": prompt + "\n\nå¿…é¡»è¿”å›JSONæ ¼å¼ã€‚"}],
                        response_format={"type": "json_object"},
                        temperature=0.3
                    )
                    return json.loads(response.choices[0].message.content)
                except Exception as api_error:
                    self.logger.warning(f"OpenAI APIç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {api_error}")
            
            # é™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•ï¼Œä½†ä½¿ç”¨æ›´å¼ºçš„JSONæç¤º
            self.logger.info("ä½¿ç”¨å¢å¼ºå‹JSONæç¤ºæ¨¡å¼")
            
            # æ·»åŠ æ›´å¼ºçš„JSONæ ¼å¼è¦æ±‚
            enhanced_prompt = f"""{prompt}

é‡è¦ï¼šä½ å¿…é¡»åªè¿”å›çº¯ JSON æ ¼å¼ï¼Œä¸èƒ½æœ‰ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚
ç¤ºä¾‹æ ¼å¼ï¼š
{json.dumps(self._get_example_for_schema(schema), ensure_ascii=False, indent=2)}

è¯·ç°åœ¨è¿”å›ä½ çš„JSONå“åº”ï¼š"""
            
            response = self.llm.invoke(enhanced_prompt)
            content = response.content.strip()
            
            # å°è¯•æå–JSON
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            return json.loads(content.strip())
                
        except Exception as e:
            self.logger.error(f"ç»“æ„åŒ–å“åº”è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _get_example_for_schema(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®JSON schemaç”Ÿæˆç¤ºä¾‹"""
        example = {}
        properties = schema.get('properties', {})
        
        for field, field_schema in properties.items():
            field_type = field_schema.get('type')
            if field_type == 'string':
                if 'enum' in field_schema:
                    example[field] = field_schema['enum'][0]
                else:
                    example[field] = "ç¤ºä¾‹æ–‡æœ¬"
            elif field_type == 'number':
                example[field] = 0.8
            elif field_type == 'boolean':
                example[field] = False
            elif field_type == 'array':
                example[field] = ["ç¤ºä¾‹é¡¹ç›®1", "ç¤ºä¾‹é¡¹ç›®2"]
            else:
                example[field] = "ç¤ºä¾‹å€¼"
        
        return example
    
    def optimize_strategy_structured(self, 
                                   current_performance: Dict[str, float],
                                   context: Dict[str, Any],
                                   goals: List[str]) -> Dict[str, Any]:
        """ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºä¼˜åŒ–ç­–ç•¥"""
        try:
            prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ä¼˜åŒ–è®¤çŸ¥ç­–ç•¥ï¼š

å½“å‰æ€§èƒ½æŒ‡æ ‡ï¼š
{self._safe_json_dumps(current_performance)}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{self._safe_json_dumps(context)}

ç›®æ ‡ï¼š
{self._safe_json_dumps(goals)}

è¯·åˆ†æå½“å‰ç­–ç•¥å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚ä½ çš„å“åº”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONæ ¼å¼ï¼š

- analysis: å¯¹å½“å‰ç­–ç•¥çš„è¯¦ç»†åˆ†æ
- strategies: 1-5ä¸ªå…·ä½“çš„ä¼˜åŒ–ç­–ç•¥å»ºè®®
- priority: å®æ–½ä¼˜å…ˆçº§ï¼ˆhigh/medium/lowï¼‰
- confidence: 0.0-1.0çš„ç½®ä¿¡åº¦åˆ†æ•°

è¯·ç¡®ä¿æä¾›å®ç”¨ã€å¯æ‰§è¡Œçš„å»ºè®®ã€‚"""

            return self._call_llm_with_schema(prompt, STRATEGY_OPTIMIZATION_SCHEMA)
            
        except Exception as e:
            self.logger.error(f"ç»“æ„åŒ–ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            # è¿”å›ç¬¦åˆ schema çš„é»˜è®¤å“åº”
            return {
                "analysis": "ç”±äºç³»ç»Ÿé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥åˆ†æ",
                "strategies": ["ä¿æŒå½“å‰ç­–ç•¥", "ç›‘æ§æ€§èƒ½æŒ‡æ ‡"],
                "priority": "medium",
                "confidence": 0.5
            }
    
    def regulate_strategy_structured(self, 
                                   current_context: Dict[str, Any], 
                                   target_goals: List[str]) -> Dict[str, Any]:
        """ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè°ƒèŠ‚ç­–ç•¥"""
        try:
            prompt = f"""è¯„ä¼°å½“å‰è®¤çŸ¥ç­–ç•¥å¹¶ç¡®å®šæ˜¯å¦éœ€è¦è°ƒæ•´ï¼š

å½“å‰ä¸Šä¸‹æ–‡ï¼š
{self._safe_json_dumps(current_context)}

ç›®æ ‡ï¼š
{self._safe_json_dumps(target_goals)}

è¯·è¯„ä¼°å½“å‰ç­–ç•¥çš„é€‚ç”¨æ€§ã€‚ä½ çš„å“åº”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONæ ¼å¼ï¼š

- assessment: å¯¹å½“å‰ç­–ç•¥çš„è¯„ä¼°
- adjustment_needed: æ˜¯å¦éœ€è¦è°ƒæ•´ï¼ˆtrue/falseï¼‰
- recommended_strategy: æ¨èçš„ç­–ç•¥
- confidence: 0.0-1.0çš„ç½®ä¿¡åº¦åˆ†æ•°
- reasoning: è¯„ä¼°çš„ç†ç”±ï¼ˆå¯é€‰ï¼‰

è¯·åŸºäºå½“å‰ä¸Šä¸‹æ–‡å’Œç›®æ ‡è¿›è¡Œå®¢è§‚è¯„ä¼°ã€‚"""

            return self._call_llm_with_schema(prompt, STRATEGY_REGULATION_SCHEMA)
            
        except Exception as e:
            self.logger.error(f"ç»“æ„åŒ–ç­–ç•¥è°ƒèŠ‚å¤±è´¥: {e}")
            # è¿”å›ç¬¦åˆ schema çš„é»˜è®¤å“åº”
            return {
                "assessment": "ç”±äºç³»ç»Ÿé”™è¯¯ï¼Œç­–ç•¥è¯„ä¼°ä¸å¯ç”¨",
                "adjustment_needed": False,
                "recommended_strategy": "ç»§ç»­ä½¿ç”¨å½“å‰ç­–ç•¥",
                "confidence": 0.5,
                "reasoning": "ç³»ç»Ÿé”™è¯¯å¯¼è‡´æ— æ³•å®Œæˆè¯„ä¼°"
            }
    
    def reflect_structured(self, 
                          experience: Dict[str, Any], 
                          outcome: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè¿›è¡Œåæ€"""
        try:
            prompt = f"""åŸºäºä»¥ä¸‹ç»éªŒå’Œç»“æœè¿›è¡Œåæ€ï¼š

ç»éªŒï¼š
{self._safe_json_dumps(experience)}

ç»“æœï¼š
{self._safe_json_dumps(outcome)}

è¯·ä»è¿™æ¬¡ç»éªŒä¸­æå–å­¦ä¹ å†…å®¹ã€‚ä½ çš„å“åº”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONæ ¼å¼ï¼š

- lessons: 1-5ä¸ªä»ç»éªŒä¸­å­¦åˆ°çš„æ•™è®­
- suggestions: 1-5ä¸ªæ”¹è¿›å»ºè®®
- quality: 0.0-1.0çš„åæ€è´¨é‡è¯„åˆ†
- insights: å…³é”®æ´å¯Ÿï¼ˆå¯é€‰ï¼‰

è¯·æä¾›å…·ä½“ã€å¯æ“ä½œçš„å­¦ä¹ å†…å®¹ã€‚"""

            return self._call_llm_with_schema(prompt, REFLECTION_SCHEMA)
            
        except Exception as e:
            self.logger.error(f"ç»“æ„åŒ–åæ€å¤±è´¥: {e}")
            # è¿”å›ç¬¦åˆ schema çš„é»˜è®¤å“åº”
            return {
                "lessons": ["ç»éªŒç§¯ç´¯å¾ˆé‡è¦", "éœ€è¦æŒç»­æ”¹è¿›"],
                "suggestions": ["åŠ å¼ºç›‘æ§", "ä¼˜åŒ–æµç¨‹"],
                "quality": 0.6,
                "insights": "ç”±äºç³»ç»Ÿé”™è¯¯ï¼Œåæ€ä¸å®Œæ•´"
            }
    
    def meta_learn_structured(self, 
                            success_cases: List[Dict[str, Any]], 
                            failure_cases: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè¿›è¡Œå…ƒå­¦ä¹ """
        try:
            prompt = f"""åŸºäºæˆåŠŸå’Œå¤±è´¥æ¡ˆä¾‹è¿›è¡Œå…ƒå­¦ä¹ åˆ†æï¼š

æˆåŠŸæ¡ˆä¾‹ï¼š
{self._safe_json_dumps(success_cases)}

å¤±è´¥æ¡ˆä¾‹ï¼š
{self._safe_json_dumps(failure_cases)}

è¯·æå–å­¦ä¹ æ¨¡å¼å’Œæ´å¯Ÿã€‚ä½ çš„å“åº”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONæ ¼å¼ï¼š

- success_patterns: æˆåŠŸæ¨¡å¼åˆ—è¡¨
- failure_causes: å¤±è´¥åŸå› åˆ—è¡¨  
- insights: å­¦ä¹ æ´å¯Ÿ
- recommendations: åŸºäºå­¦ä¹ çš„å»ºè®®ï¼ˆå¯é€‰ï¼‰

è¯·æä¾›æ·±å…¥çš„åˆ†æå’Œå¯æ“ä½œçš„å»ºè®®ã€‚"""

            return self._call_llm_with_schema(prompt, META_LEARNING_SCHEMA)
            
        except Exception as e:
            self.logger.error(f"ç»“æ„åŒ–å…ƒå­¦ä¹ å¤±è´¥: {e}")
            # è¿”å›ç¬¦åˆ schema çš„é»˜è®¤å“åº”
            return {
                "success_patterns": ["ç³»ç»ŸåŒ–æ–¹æ³•", "æŒç»­ç›‘æ§"],
                "failure_causes": ["å‡†å¤‡ä¸è¶³", "æ²Ÿé€šä¸ç•…"],
                "insights": "ç”±äºç³»ç»Ÿé”™è¯¯ï¼Œå…ƒå­¦ä¹ åˆ†æä¸å®Œæ•´",
                "recommendations": ["å»ºç«‹æ›´å¥½çš„ç›‘æ§", "æ”¹è¿›æ²Ÿé€šæœºåˆ¶"]
            }


def test_structured_responses():
    """æµ‹è¯•ç»“æ„åŒ–å“åº”"""
    import os
    from langchain_openai import ChatOpenAI
    
    # åˆå§‹åŒ– LLM
    if os.getenv('DEEPSEEK_API_KEY'):
        llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=os.getenv('DEEPSEEK_API_KEY'),
            openai_api_base="https://api.deepseek.com",
            max_tokens=1000,
            temperature=0.3
        )
    elif os.getenv('OPENAI_API_KEY'):
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            max_tokens=1000,
            temperature=0.3
        )
    else:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = StructuredResponseOptimizer(llm)
    
    print("ğŸ§ª æµ‹è¯•ç»“æ„åŒ–å“åº”...")
    
    # æµ‹è¯•ç­–ç•¥ä¼˜åŒ–
    try:
        result = optimizer.optimize_strategy_structured(
            current_performance={"efficiency": 0.8, "accuracy": 0.9},
            context={"task": "è®¤çŸ¥ç›‘ç£", "complexity": "é«˜"},
            goals=["æé«˜æ•ˆç‡", "ä¿æŒå‡†ç¡®æ€§"]
        )
        print("âœ… ç»“æ„åŒ–ç­–ç•¥ä¼˜åŒ–æˆåŠŸ")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(f"âŒ ç»“æ„åŒ–ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")


if __name__ == "__main__":
    test_structured_responses()