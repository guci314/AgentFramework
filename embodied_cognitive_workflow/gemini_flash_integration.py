"""
Gemini Flash 2.5 é›†æˆæ¨¡å—

æœ¬æ¨¡å—å·²å‡çº§ä¸ºä½¿ç”¨ pythonTask ä¸­å®šä¹‰çš„ Gemini Flash 2.5 æ¨¡å‹ã€‚
æä¾›æ™ºèƒ½æ–­ç‚¹æ¡ä»¶è¯„ä¼°å’Œå¼‚æ­¥bugæ£€æµ‹åŠŸèƒ½ã€‚

å‡çº§è¯´æ˜ï¼š
- ä» Google generativeai åº“è¿ç§»åˆ°åŸºäº ChatOpenAI çš„å®ç°
- ä½¿ç”¨ pythonTask ä¸­é¢„é…ç½®çš„ get_model("gemini_2_5_flash") æ¨¡å‹
- ä¿æŒåŸæœ‰ API æ¥å£ä¸å˜ï¼Œç¡®ä¿å‘åå…¼å®¹æ€§
- æ”¯æŒä¸­å›½å¤§é™†ç”¨æˆ·çš„ç½‘ç»œç¯å¢ƒé…ç½®

è¦æ±‚ï¼š
- è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡
- ç¡®ä¿ pythonTask æ¨¡å—å¯æ­£å¸¸å¯¼å…¥
- ç½‘ç»œèƒ½å¤Ÿè®¿é—® Google APIï¼ˆæˆ–é…ç½®ä»£ç†ï¼‰
"""

import os
import asyncio
import json
import logging
import sys
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from datetime import datetime

# å¯¼å…¥ pythonTask ä¸­çš„ Gemini Flash 2.5 æ¨¡å‹
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from llm_lazy import get_model
    llm_gemini_2_5_flash_google = get_model("gemini_2_5_flash")
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œè®¾ç½®ä¸º None
    llm_gemini_2_5_flash_google = None


@dataclass
class GeminiConfig:
    """Gemini Flash 2.5 é…ç½®"""
    api_key: str
    model_name: str = "models/gemini-2.5-flash"
    temperature: float = 0.1
    max_output_tokens: int = 1000
    timeout: float = 10.0


class GeminiFlashClient:
    """Gemini Flash 2.5 å®¢æˆ·ç«¯ï¼ˆåŸºäº pythonTask æ¨¡å‹ï¼‰"""
    
    def __init__(self, config: Optional[GeminiConfig] = None):
        """
        åˆå§‹åŒ– Gemini Flash 2.5 å®¢æˆ·ç«¯
        
        Args:
            config: Geminié…ç½®ï¼ˆå¯é€‰ï¼Œå°†ä½¿ç”¨ pythonTask ä¸­çš„é»˜è®¤é…ç½®ï¼‰
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸå¯¼å…¥äº† pythonTask æ¨¡å‹
        if get_model("gemini_2_5_flash") is None:
            raise ImportError("æ— æ³•å¯¼å…¥ pythonTask ä¸­çš„ Gemini Flash 2.5 æ¨¡å‹")
        
        # ä½¿ç”¨ pythonTask ä¸­é¢„é…ç½®çš„æ¨¡å‹
        self.model = get_model("gemini_2_5_flash")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not os.getenv('GEMINI_API_KEY'):
            self.logger.warning("æœªè®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡ï¼ŒGemini Flash 2.5 å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        
        self.logger.info(f"Gemini Flash 2.5 å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼šåŸºäº pythonTask æ¨¡å‹")
    
    def generate_content(self, prompt: str, **kwargs) -> str:
        """
        ç”Ÿæˆå†…å®¹
        
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            str: ç”Ÿæˆçš„å†…å®¹
        """
        try:
            # ä½¿ç”¨ ChatOpenAI æ¥å£
            response = self.model.invoke(prompt)
            return response.content
            
        except Exception as e:
            self.logger.error(f"Gemini Flash 2.5 å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    async def generate_content_async(self, prompt: str, **kwargs) -> str:
        """
        å¼‚æ­¥ç”Ÿæˆå†…å®¹
        
        Args:
            prompt: è¾“å…¥æç¤º
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            str: ç”Ÿæˆçš„å†…å®¹
        """
        try:
            # ä½¿ç”¨ ChatOpenAI çš„å¼‚æ­¥æ¥å£
            response = await self.model.ainvoke(prompt)
            return response.content
            
        except Exception as e:
            self.logger.error(f"Gemini Flash 2.5 å¼‚æ­¥å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def evaluate_breakpoint_condition(self, condition: str, context: Dict[str, Any]) -> bool:
        """
        è¯„ä¼°æ–­ç‚¹æ¡ä»¶
        
        Args:
            condition: æ–­ç‚¹æ¡ä»¶ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            context: å½“å‰ä¸Šä¸‹æ–‡
            
        Returns:
            bool: æ¡ä»¶æ˜¯å¦æ»¡è¶³
        """
        try:
            prompt = f"""
            è¯·è¯„ä¼°ä»¥ä¸‹æ–­ç‚¹æ¡ä»¶æ˜¯å¦åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­æ»¡è¶³ã€‚
            
            æ–­ç‚¹æ¡ä»¶: {condition}
            
            å½“å‰ä¸Šä¸‹æ–‡:
            {json.dumps(context, ensure_ascii=False, indent=2)}
            
            è¯„ä¼°è§„åˆ™:
            1. ä»”ç»†åˆ†ææ–­ç‚¹æ¡ä»¶çš„è¯­ä¹‰
            2. æ£€æŸ¥ä¸Šä¸‹æ–‡ä¸­æ˜¯å¦å­˜åœ¨æ»¡è¶³æ¡ä»¶çš„æ•°æ®
            3. åªæœ‰å½“æ¡ä»¶å®Œå…¨åŒ¹é…æ—¶æ‰è¿”å›true
            
            è¯·åªè¿”å› 'true' æˆ– 'false'ï¼Œä¸è¦å…¶ä»–ä»»ä½•æ–‡å­—ã€‚
            """
            
            response = self.generate_content(prompt)
            result = response.strip().lower()
            
            # ç¡®ä¿è¿”å›å€¼åªæ˜¯trueæˆ–false
            if result in ['true', 'false']:
                return result == 'true'
            else:
                self.logger.warning(f"æ„å¤–çš„æ–­ç‚¹è¯„ä¼°ç»“æœ: {result}")
                return False
                
        except Exception as e:
            self.logger.error(f"æ–­ç‚¹æ¡ä»¶è¯„ä¼°å¤±è´¥: {e}")
            return False
    
    def analyze_bug_potential(self, step_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†ææ½œåœ¨çš„bug
        
        Args:
            step_data: è®¤çŸ¥æ­¥éª¤æ•°æ®
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            prompt = f"""
åˆ†æä»¥ä¸‹è®¤çŸ¥æ­¥éª¤æ˜¯å¦å­˜åœ¨è½¯ä»¶ç¼ºé™·ã€‚

æ­¥éª¤æ•°æ®: {json.dumps(step_data, ensure_ascii=False)}

åˆ†æè¦ç‚¹:
- æ£€æŸ¥é”™è¯¯å’Œå¼‚å¸¸
- è¯„ä¼°æ‰§è¡Œæ—¶é—´(>3ç§’ä¸ºå¼‚å¸¸)
- æ£€æŸ¥æ•°æ®åˆç†æ€§

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—:

{{
  "has_bug": false,
  "severity": "low",
  "bug_type": "unknown", 
  "description": "æ­£å¸¸æ‰§è¡Œ",
  "evidence": "æ— å¼‚å¸¸",
  "fix_suggestion": "æ— éœ€ä¿®å¤"
}}
            """
            
            response = self.generate_content(prompt)
            
            # æ™ºèƒ½è§£æJSONå“åº”
            analysis = self._parse_json_response(response)
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['has_bug', 'severity', 'description']
            if all(field in analysis for field in required_fields):
                return analysis
            else:
                self.logger.warning("Bugåˆ†æç»“æœç¼ºå°‘å¿…éœ€å­—æ®µ")
                return self._create_default_analysis()
                
        except Exception as e:
            self.logger.error(f"Bugæ½œåŠ›åˆ†æå¤±è´¥: {e}")
            return self._create_default_analysis()
    
    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """
        æ™ºèƒ½è§£æJSONå“åº”ï¼Œå¤„ç†åŒ…å«markdownä»£ç å—çš„æƒ…å†µ
        
        Args:
            response: åŸå§‹å“åº”
            
        Returns:
            Dict[str, Any]: è§£æåçš„JSONå¯¹è±¡ï¼Œå¤±è´¥æ—¶è¿”å›é»˜è®¤åˆ†æ
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šå°è¯•ç›´æ¥è§£æ
            cleaned_response = response.strip()
            return json.loads(cleaned_response)
            
        except json.JSONDecodeError:
            try:
                # ç¬¬äºŒæ­¥ï¼šç§»é™¤markdownä»£ç å—æ ‡è®°
                import re
                
                # ç§»é™¤ ```json å’Œ ``` æ ‡è®°
                pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
                match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
                
                if match:
                    json_content = match.group(1).strip()
                    self.logger.debug(f"æå–åˆ°çš„JSONå†…å®¹: {json_content}")
                    return json.loads(json_content)
                
                # ç¬¬ä¸‰æ­¥ï¼šå¯»æ‰¾ä»»ä½•JSONå¯¹è±¡
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    json_content = json_match.group().strip()
                    self.logger.debug(f"é€šè¿‡æ­£åˆ™æå–çš„JSON: {json_content}")
                    return json.loads(json_content)
                    
            except json.JSONDecodeError as e:
                self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
                self.logger.debug(f"åŸå§‹å“åº”: {response}")
            
        except Exception as e:
            self.logger.error(f"å“åº”è§£æå¼‚å¸¸: {e}")
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ
        self.logger.warning("æ— æ³•è§£æå“åº”ï¼Œè¿”å›é»˜è®¤åˆ†æç»“æœ")
        return self._create_default_analysis()
    
    def _create_default_analysis(self) -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤åˆ†æç»“æœ"""
        return {
            "has_bug": False,
            "severity": "low",
            "bug_type": "unknown",
            "description": "åˆ†æå¤±è´¥",
            "evidence": "æ— æ³•å®Œæˆåˆ†æ",
            "fix_suggestion": "éœ€è¦äººå·¥æ£€æŸ¥"
        }
    
    async def analyze_bug_potential_async(self, step_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¼‚æ­¥åˆ†ææ½œåœ¨çš„bug
        
        Args:
            step_data: è®¤çŸ¥æ­¥éª¤æ•°æ®
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            prompt = f"""
            è¯·å¿«é€Ÿåˆ†æä»¥ä¸‹è®¤çŸ¥æ­¥éª¤æ˜¯å¦å­˜åœ¨ç¼ºé™·:
            
            {json.dumps(step_data, ensure_ascii=False)}
            
            è¿”å›JSONæ ¼å¼: {{"has_bug": bool, "severity": "level", "description": "desc"}}
            """
            
            response = await self.generate_content_async(prompt)
            
            try:
                return json.loads(response.strip())
            except json.JSONDecodeError:
                return self._create_default_analysis()
                
        except Exception as e:
            self.logger.error(f"å¼‚æ­¥Bugåˆ†æå¤±è´¥: {e}")
            return self._create_default_analysis()
    
    def generate_cognitive_strategy(self, task_description: str, 
                                  context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆè®¤çŸ¥ç­–ç•¥å»ºè®®
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            Dict[str, Any]: ç­–ç•¥å»ºè®®
        """
        try:
            prompt = f"""
            è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆæœ€ä¼˜çš„è®¤çŸ¥ç­–ç•¥:
            
            ä»»åŠ¡: {task_description}
            ä¸Šä¸‹æ–‡: {json.dumps(context, ensure_ascii=False, indent=2)}
            
            è¯·åˆ†æå¹¶æä¾›:
            1. ä»»åŠ¡å¤æ‚åº¦è¯„ä¼° (1-10)
            2. å»ºè®®çš„æ‰§è¡Œç­–ç•¥
            3. é¢„æœŸçš„æŒ‘æˆ˜å’Œé£é™©
            4. æˆåŠŸæŒ‡æ ‡
            
            ä»¥JSONæ ¼å¼è¿”å›:
            {{
                "complexity": number,
                "strategy": "ç­–ç•¥æè¿°",
                "challenges": ["æŒ‘æˆ˜1", "æŒ‘æˆ˜2"],
                "success_metrics": ["æŒ‡æ ‡1", "æŒ‡æ ‡2"],
                "estimated_time": "é¢„ä¼°æ—¶é—´",
                "resource_requirements": "èµ„æºéœ€æ±‚"
            }}
            """
            
            response = self.generate_content(prompt)
            
            try:
                return json.loads(response.strip())
            except json.JSONDecodeError:
                return {
                    "complexity": 5,
                    "strategy": "æ ‡å‡†æ‰§è¡Œç­–ç•¥",
                    "challenges": ["æœªçŸ¥æŒ‘æˆ˜"],
                    "success_metrics": ["ä»»åŠ¡å®Œæˆ"],
                    "estimated_time": "ä¸­ç­‰",
                    "resource_requirements": "æ ‡å‡†èµ„æº"
                }
                
        except Exception as e:
            self.logger.error(f"è®¤çŸ¥ç­–ç•¥ç”Ÿæˆå¤±è´¥: {e}")
            return {"complexity": 5, "strategy": "é»˜è®¤ç­–ç•¥"}
    
    def health_check(self) -> bool:
        """
        å¥åº·æ£€æŸ¥
        
        Returns:
            bool: å®¢æˆ·ç«¯æ˜¯å¦æ­£å¸¸å·¥ä½œ
        """
        try:
            test_prompt = "è¯·å›å¤'OK'"
            response = self.generate_content(test_prompt)
            return "ok" in response.lower()
            
        except Exception as e:
            self.logger.error(f"Gemini Flash 2.5 å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False


def create_gemini_client(api_key: Optional[str] = None, 
                        model_name: str = "models/gemini-2.5-flash") -> Optional[GeminiFlashClient]:
    """
    åˆ›å»º Gemini Flash 2.5 å®¢æˆ·ç«¯ï¼ˆåŸºäº pythonTask æ¨¡å‹ï¼‰
    
    Args:
        api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è·å–ï¼ˆå¯é€‰ï¼ŒpythonTaskå·²å¤„ç†ï¼‰
        model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œå°†ä½¿ç”¨pythonTaskçš„é»˜è®¤é…ç½®ï¼‰
        
    Returns:
        Optional[GeminiFlashClient]: å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ pythonTask æ¨¡å‹
        if get_model("gemini_2_5_flash") is None:
            logging.error("æ— æ³•å¯¼å…¥ pythonTask ä¸­çš„ Gemini Flash 2.5 æ¨¡å‹")
            return None
        
        # æ£€æŸ¥APIå¯†é’¥
        if not os.getenv('GEMINI_API_KEY'):
            logging.warning("æœªæ‰¾åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡ï¼ŒGemini Flash 2.5 å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        
        # åˆ›å»ºé…ç½®ï¼ˆå¯é€‰ï¼Œä¸»è¦ç”¨äºå…¼å®¹æ€§ï¼‰
        config = GeminiConfig(
            api_key=api_key or os.getenv('GEMINI_API_KEY', ''),
            model_name=model_name
        )
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = GeminiFlashClient(config)
        
        # å¥åº·æ£€æŸ¥
        if client.health_check():
            logging.info("Gemini Flash 2.5 å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸï¼ˆåŸºäº pythonTask æ¨¡å‹ï¼‰")
            return client
        else:
            logging.error("Gemini Flash 2.5 å®¢æˆ·ç«¯å¥åº·æ£€æŸ¥å¤±è´¥")
            return None
            
    except Exception as e:
        logging.error(f"åˆ›å»º Gemini Flash 2.5 å®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸš€ Gemini Flash 2.5 é›†æˆæµ‹è¯•ï¼ˆåŸºäº pythonTask æ¨¡å‹ï¼‰")
    print("=" * 60)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    print("1. åˆ›å»º Gemini Flash 2.5 å®¢æˆ·ç«¯...")
    client = create_gemini_client()
    
    if client:
        print("âœ… Gemini Flash 2.5 å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ–­ç‚¹æ¡ä»¶è¯„ä¼°
        print("\n2. æµ‹è¯•æ–­ç‚¹æ¡ä»¶è¯„ä¼°...")
        test_context = {
            "layer": "è‡ªæˆ‘",
            "action": "æ‰§è¡Œä»£ç ",
            "success": False,
            "error_message": "è¯­æ³•é”™è¯¯"
        }
        
        condition = "å¦‚æœæ‰§è¡Œå¤±è´¥å¹¶ä¸”åŒ…å«è¯­æ³•é”™è¯¯"
        result = client.evaluate_breakpoint_condition(condition, test_context)
        print(f"   æ–­ç‚¹æ¡ä»¶: '{condition}'")
        print(f"   è¯„ä¼°ç»“æœ: {result}")
        
        # æµ‹è¯•bugåˆ†æ
        print("\n3. æµ‹è¯•Bugåˆ†æ...")
        step_data = {
            "step_id": "test_step",
            "layer": "è‡ªæˆ‘",
            "success": False,
            "error_message": "æœªå®šä¹‰å˜é‡",
            "execution_time": 5.0
        }
        
        bug_analysis = client.analyze_bug_potential(step_data)
        print("   Bugåˆ†æç»“æœ:")
        print(json.dumps(bug_analysis, ensure_ascii=False, indent=4))
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        
    else:
        print("âŒ Gemini Flash 2.5 å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥")
        print("   å¯èƒ½çš„åŸå› ï¼š")
        print("   - æœªè®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")
        print("   - ç½‘ç»œæ— æ³•è®¿é—® Google API æœåŠ¡")
        print("   - pythonTask æ¨¡å—å¯¼å…¥å¤±è´¥")