#!/usr/bin/env python3
"""
è°ƒè¯•DeepSeek APIå“åº”é—®é¢˜
ä¸“é—¨é’ˆå¯¹DeepSeekæ¨¡å‹çš„å“åº”åˆ†æ
"""

import sys
import os
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

def test_deepseek_response():
    """æµ‹è¯•DeepSeek APIå“åº”"""
    print("ğŸ” æµ‹è¯•DeepSeek APIå“åº”")
    print("=" * 50)
    
    try:
        # å°è¯•å¯¼å…¥ä¸åŒçš„LLMå®¢æˆ·ç«¯
        try:
            from langchain_community.chat_models import ChatDeepSeek
            print("âœ… æˆåŠŸå¯¼å…¥ChatDeepSeek")
            llm_type = "ChatDeepSeek"
        except ImportError:
            try:
                from langchain_openai import ChatOpenAI
                print("âœ… ä½¿ç”¨ChatOpenAIä½œä¸ºDeepSeekå®¢æˆ·ç«¯")
                llm_type = "ChatOpenAI"
            except ImportError:
                print("âŒ æ— æ³•å¯¼å…¥ä»»ä½•LLMå®¢æˆ·ç«¯")
                return False
        
        # æ£€æŸ¥APIå¯†é’¥
        deepseek_key = os.getenv('DEEPSEEK_API_KEY')
        openai_key = os.getenv('OPENAI_API_KEY')
        
        if deepseek_key:
            print("âœ… æ‰¾åˆ°DEEPSEEK_API_KEY")
            api_key = deepseek_key
            base_url = "https://api.deepseek.com"
        elif openai_key:
            print("âœ… æ‰¾åˆ°OPENAI_API_KEYï¼Œä½¿ç”¨OpenAI")
            api_key = openai_key  
            base_url = None
        else:
            print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
            return False
        
        # åˆå§‹åŒ–LLM
        if llm_type == "ChatDeepSeek" and deepseek_key:
            llm = ChatDeepSeek(
                model="deepseek-chat",
                deepseek_api_key=deepseek_key,
                max_tokens=1000,
                temperature=0.3
            )
            print("ğŸ¤– ä½¿ç”¨DeepSeekæ¨¡å‹")
        else:
            from langchain_openai import ChatOpenAI
            if base_url:
                llm = ChatOpenAI(
                    model="deepseek-chat",
                    openai_api_key=api_key,
                    openai_api_base=base_url,
                    max_tokens=1000,
                    temperature=0.3
                )
                print("ğŸ¤– ä½¿ç”¨DeepSeek API (é€šè¿‡OpenAIæ¥å£)")
            else:
                llm = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    openai_api_key=api_key,
                    max_tokens=1000,
                    temperature=0.3
                )
                print("ğŸ¤– ä½¿ç”¨OpenAI GPT-3.5-turbo")
        
        # æµ‹è¯•ç®€å•æç¤º
        print("\nğŸ“ æµ‹è¯•1: ç®€å•JSONå“åº”")
        simple_prompt = """è¯·ç”¨JSONæ ¼å¼å›ç­”ï¼šä½ å¥½ï¼
        
        è¿”å›æ ¼å¼ï¼š
        {
            "greeting": "ä½ çš„é—®å€™",
            "status": "ok"
        }"""
        
        try:
            response = llm.invoke(simple_prompt)
            print(f"å“åº”ç±»å‹: {type(response)}")
            print(f"å“åº”å†…å®¹: '{response.content}'")
            print(f"å“åº”é•¿åº¦: {len(response.content) if response.content else 0}")
            
            if response.content and response.content.strip():
                try:
                    parsed = json.loads(response.content.strip())
                    print("âœ… JSONè§£ææˆåŠŸ")
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹å†…å®¹: {repr(response.content)}")
            else:
                print("âš ï¸ æ”¶åˆ°ç©ºå“åº”")
                
        except Exception as e:
            print(f"âŒ ç®€å•æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•ç­–ç•¥ä¼˜åŒ–ç›¸ä¼¼çš„æç¤º
        print("\nğŸ“ æµ‹è¯•2: ç­–ç•¥ä¼˜åŒ–æç¤º")
        strategy_prompt = """åŸºäºå½“å‰æ€§èƒ½æŒ‡æ ‡ï¼Œæä¾›ä¼˜åŒ–å»ºè®®ï¼š

å½“å‰æ€§èƒ½ï¼š{"efficiency": 0.8, "accuracy": 0.9}
ç›®æ ‡ï¼š["æé«˜æ•ˆç‡"]

è¯·è¿”å›JSONæ ¼å¼ï¼š
{
    "bottleneck_analysis": "åˆ†æå†…å®¹", 
    "optimization_strategies": ["ç­–ç•¥1"],
    "implementation_priority": "medium"
}"""
        
        try:
            response = llm.invoke(strategy_prompt)
            print(f"ç­–ç•¥ä¼˜åŒ–å“åº”é•¿åº¦: {len(response.content) if response.content else 0}")
            
            if response.content and response.content.strip():
                print("âœ… ç­–ç•¥ä¼˜åŒ–æœ‰å“åº”")
                try:
                    parsed = json.loads(response.content.strip())
                    print("âœ… ç­–ç•¥ä¼˜åŒ–JSONè§£ææˆåŠŸ")
                    print(json.dumps(parsed, ensure_ascii=False, indent=2))
                except json.JSONDecodeError as e:
                    print(f"âŒ ç­–ç•¥ä¼˜åŒ–JSONè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹å“åº”: {response.content[:200]}...")
            else:
                print("âš ï¸ ç­–ç•¥ä¼˜åŒ–æ”¶åˆ°ç©ºå“åº”")
                
        except Exception as e:
            print(f"âŒ ç­–ç•¥ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•è¶…é•¿æç¤ºçš„å½±å“
        print("\nğŸ“ æµ‹è¯•3: é•¿æç¤ºå¤„ç†")
        long_data = {"å¾ˆé•¿çš„æ•°æ®": "x" * 1000}
        long_prompt = f"""åˆ†æä»¥ä¸‹æ•°æ®ï¼š

æ•°æ®ï¼š{json.dumps(long_data, ensure_ascii=False)}

è¯·ç®€å•è¿”å›ï¼š{{"status": "analyzed"}}"""
        
        try:
            print(f"é•¿æç¤ºé•¿åº¦: {len(long_prompt)} å­—ç¬¦")
            response = llm.invoke(long_prompt)
            
            if response.content and response.content.strip():
                print("âœ… é•¿æç¤ºæœ‰å“åº”")
            else:
                print("âš ï¸ é•¿æç¤ºæ”¶åˆ°ç©ºå“åº”")
                
        except Exception as e:
            print(f"âŒ é•¿æç¤ºæµ‹è¯•å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


def analyze_prompt_issues():
    """åˆ†æå¯èƒ½å¯¼è‡´ç©ºå“åº”çš„æç¤ºé—®é¢˜"""
    print("\nğŸ” åˆ†ææç¤ºé—®é¢˜")
    print("=" * 50)
    
    # æ£€æŸ¥è¶…æˆ‘æ™ºèƒ½ä½“çš„æç¤ºæ¨¡æ¿
    problematic_patterns = [
        "è¿‡é•¿çš„JSONç¤ºä¾‹",
        "å¤æ‚çš„åµŒå¥—ç»“æ„",
        "ä¸­è‹±æ–‡æ··åˆ",
        "ç‰¹æ®Šå­—ç¬¦",
        "è¿‡å¤šçš„æŒ‡ä»¤è¦æ±‚"
    ]
    
    print("ğŸ¯ å¯èƒ½å¯¼è‡´ç©ºå“åº”çš„é—®é¢˜:")
    for i, pattern in enumerate(problematic_patterns, 1):
        print(f"  {i}. {pattern}")
    
    print("\nğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
    print("  1. ç®€åŒ–æç¤ºè¯ç»“æ„")
    print("  2. å‡å°‘JSONç¤ºä¾‹çš„å¤æ‚åº¦") 
    print("  3. ä½¿ç”¨æ›´ç›´æ¥çš„æŒ‡ä»¤")
    print("  4. é™åˆ¶æç¤ºè¯é•¿åº¦")
    print("  5. åˆ†æ­¥éª¤è¯·æ±‚è€Œä¸æ˜¯ä¸€æ¬¡æ€§å¤æ‚è¯·æ±‚")


def suggest_prompt_optimization():
    """å»ºè®®æç¤ºä¼˜åŒ–ç­–ç•¥"""
    print("\nğŸ¯ æç¤ºä¼˜åŒ–å»ºè®®")
    print("=" * 50)
    
    print("åŸå§‹å¤æ‚æç¤º â†’ ç®€åŒ–æç¤º:")
    print()
    
    print("âŒ é—®é¢˜æç¤º:")
    print("""åŸºäºå½“å‰æ€§èƒ½æŒ‡æ ‡å’Œä¸Šä¸‹æ–‡ï¼Œä¼˜åŒ–è®¤çŸ¥ç­–ç•¥ï¼š

å½“å‰æ€§èƒ½ï¼š{å¤æ‚çš„æ€§èƒ½æ•°æ®}
ä¸Šä¸‹æ–‡ï¼š{å¤æ‚çš„ä¸Šä¸‹æ–‡æ•°æ®}  
ç›®æ ‡ï¼š{å¤æ‚çš„ç›®æ ‡åˆ—è¡¨}

è¯·åˆ†æå¹¶æä¾›ï¼š
1. å½“å‰ç­–ç•¥çš„ç“¶é¢ˆåˆ†æ
2. ä¼˜åŒ–å»ºè®®å’Œå…·ä½“ç­–ç•¥  
3. é¢„æœŸæ”¹è¿›æ•ˆæœ
4. å®æ–½ä¼˜å…ˆçº§

è¿”å›JSONæ ¼å¼ï¼š{å¤æ‚çš„JSONæ¨¡æ¿}""")
    
    print("\nâœ… ä¼˜åŒ–æç¤º:")
    print("""è¯·æä¾›ç­–ç•¥ä¼˜åŒ–å»ºè®®ã€‚

ç®€å•è¿”å›ï¼š
{
    "analysis": "ç®€è¦åˆ†æ",
    "strategies": ["å»ºè®®1", "å»ºè®®2"],  
    "priority": "high"
}""")


if __name__ == "__main__":
    print("ğŸ”§ DeepSeekå“åº”è°ƒè¯•å·¥å…·")
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # è¿è¡Œæµ‹è¯•
    success = test_deepseek_response()
    
    # åˆ†æé—®é¢˜
    analyze_prompt_issues()
    
    # å»ºè®®ä¼˜åŒ–
    suggest_prompt_optimization()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š è°ƒè¯•æ€»ç»“:")
    if success:
        print("âœ… åŸºç¡€APIè¿æ¥æ­£å¸¸")
        print("ğŸ’¡ é‡ç‚¹æ£€æŸ¥æç¤ºè¯å¤æ‚åº¦å’Œé•¿åº¦")
    else:
        print("âŒ APIè¿æ¥æˆ–é…ç½®æœ‰é—®é¢˜")
        print("ğŸ’¡ ä¼˜å…ˆæ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")