#!/usr/bin/env python3
"""
å…¨é¢æµ‹è¯•SuperEgoAgentçš„æ‰€æœ‰æ–¹æ³•
éªŒè¯æ‰€æœ‰JSONè¾“å‡ºæ–¹æ³•éƒ½å·²æ›´æ–°ä¸ºç»“æ„åŒ–è¾“å‡º
"""

import sys
import os
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)


def test_all_superego_methods():
    """æµ‹è¯•SuperEgoAgentçš„æ‰€æœ‰ä¸»è¦æ–¹æ³•"""
    print("ğŸ§  å…¨é¢æµ‹è¯•SuperEgoAgentæ–¹æ³•")
    print("=" * 60)
    
    try:
        from embodied_cognitive_workflow import SuperEgoAgent
        from langchain_openai import ChatOpenAI
        
        # åˆå§‹åŒ–LLM
        if os.getenv('DEEPSEEK_API_KEY'):
            llm = ChatOpenAI(
                model="deepseek-chat",
                openai_api_key=os.getenv('DEEPSEEK_API_KEY'),
                openai_api_base="https://api.deepseek.com",
                max_tokens=1000,
                temperature=0.3
            )
            print("ğŸ¤– ä½¿ç”¨DeepSeekæ¨¡å‹")
        elif os.getenv('OPENAI_API_KEY'):
            llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                max_tokens=1000,
                temperature=0.3
            )
            print("ğŸ¤– ä½¿ç”¨OpenAI GPT-3.5-turbo")
        else:
            print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
            return False
        
        # åˆ›å»ºç»“æ„åŒ–æ¨¡å¼SuperEgo
        print("\nğŸ”¹ åˆ›å»ºç»“æ„åŒ–æ¨¡å¼SuperEgo")
        super_ego = SuperEgoAgent(
            llm=llm,
            enable_ultra_think=True,
            use_structured_output=True
        )
        
        success_count = 0
        total_tests = 0
        
        # æµ‹è¯•1: ç­–ç•¥ä¼˜åŒ–
        print("\nğŸ“ˆ æµ‹è¯•ç­–ç•¥ä¼˜åŒ–")
        total_tests += 1
        try:
            result = super_ego.strategy_optimizer.optimize_strategy(
                {"efficiency": 0.8, "accuracy": 0.9},
                {"task": "æµ‹è¯•", "environment": "å¼€å‘"},
                ["æé«˜æ€§èƒ½", "å‡å°‘é”™è¯¯"]
            )
            
            if 'error' not in result and _validate_strategy_schema(result):
                print("âœ… ç­–ç•¥ä¼˜åŒ–æˆåŠŸ")
                success_count += 1
            else:
                print(f"âŒ ç­–ç•¥ä¼˜åŒ–å¤±è´¥æˆ–æ ¼å¼é”™è¯¯: {result}")
                
        except Exception as e:
            print(f"âŒ ç­–ç•¥ä¼˜åŒ–å¼‚å¸¸: {e}")
        
        # æµ‹è¯•2: ç­–ç•¥è°ƒèŠ‚  
        print("\nâš™ï¸ æµ‹è¯•ç­–ç•¥è°ƒèŠ‚")
        total_tests += 1
        try:
            result = super_ego.ultra_think.regulate_cognitive_strategy(
                {"situation": "æµ‹è¯•åœºæ™¯", "load": "ä¸­ç­‰"},
                ["ä¿æŒç¨³å®š", "ä¼˜åŒ–æ€§èƒ½"]
            )
            
            if 'error' not in result and _validate_regulation_schema(result):
                print("âœ… ç­–ç•¥è°ƒèŠ‚æˆåŠŸ")
                success_count += 1
            else:
                print(f"âŒ ç­–ç•¥è°ƒèŠ‚å¤±è´¥æˆ–æ ¼å¼é”™è¯¯: {result}")
                
        except Exception as e:
            print(f"âŒ ç­–ç•¥è°ƒèŠ‚å¼‚å¸¸: {e}")
        
        # æµ‹è¯•3: ç»éªŒåæ€
        print("\nğŸ¤” æµ‹è¯•ç»éªŒåæ€")
        total_tests += 1
        try:
            result = super_ego.reflection_engine.reflect_on_experience(
                {"action": "æµ‹è¯•æ‰§è¡Œ", "context": "å¼€å‘ç¯å¢ƒ"},
                {"success": True, "duration": 120}
            )
            
            if 'error' not in result and _validate_reflection_schema(result):
                print("âœ… ç»éªŒåæ€æˆåŠŸ")
                success_count += 1
            else:
                print(f"âŒ ç»éªŒåæ€å¤±è´¥æˆ–æ ¼å¼é”™è¯¯: {result}")
                
        except Exception as e:
            print(f"âŒ ç»éªŒåæ€å¼‚å¸¸: {e}")
        
        # æµ‹è¯•4: è®¤çŸ¥ç›‘ç£
        print("\nğŸ‘ï¸ æµ‹è¯•è®¤çŸ¥ç›‘ç£")
        total_tests += 1
        try:
            # åˆ›å»ºæ¨¡æ‹Ÿçš„å†³ç­–ç»“æœ
            mock_ego_result = {
                "decision": "æ‰§è¡Œä»»åŠ¡A",
                "reasoning": "åŸºäºå½“å‰æƒ…å†µåˆ†æ",
                "confidence": 0.8
            }
            
            mock_id_result = {
                "motivation": "å®Œæˆç›®æ ‡",
                "emotional_state": "ä¸“æ³¨",
                "energy_level": 0.9
            }
            
            result = super_ego.supervise_cognitive_process(
                ego_result=mock_ego_result,
                id_result=mock_id_result,
                context={"task": "æµ‹è¯•ç›‘ç£"}
            )
            
            if result and 'supervision_summary' in result:
                print("âœ… è®¤çŸ¥ç›‘ç£æˆåŠŸ")
                success_count += 1
            else:
                print(f"âŒ è®¤çŸ¥ç›‘ç£å¤±è´¥: {result}")
                
        except Exception as e:
            print(f"âŒ è®¤çŸ¥ç›‘ç£å¼‚å¸¸: {e}")
        
        # æµ‹è¯•5: ç»¼åˆç¨³å®šæ€§æµ‹è¯•
        print("\nğŸ”„ ç»¼åˆç¨³å®šæ€§æµ‹è¯• (5æ¬¡)")
        stability_success = 0
        for i in range(5):
            try:
                result = super_ego.strategy_optimizer.optimize_strategy(
                    {"metric": 0.7 + i * 0.05}, 
                    {"iteration": i}, 
                    [f"ç›®æ ‡{i+1}"]
                )
                if 'error' not in result and _validate_strategy_schema(result):
                    stability_success += 1
            except Exception:
                pass
        
        stability_rate = (stability_success / 5) * 100
        print(f"ç¨³å®šæ€§æµ‹è¯•æˆåŠŸç‡: {stability_rate:.1f}% ({stability_success}/5)")
        if stability_rate >= 80:
            success_count += 1
        total_tests += 1
        
        # ç»“æœç»Ÿè®¡
        success_rate = (success_count / total_tests) * 100
        print(f"\nğŸ“Š æ€»ä½“æµ‹è¯•ç»“æœ: {success_rate:.1f}% ({success_count}/{total_tests})")
        
        return success_rate >= 80
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def _validate_strategy_schema(result: dict) -> bool:
    """éªŒè¯ç­–ç•¥ä¼˜åŒ–ç»“æœæ˜¯å¦ç¬¦åˆschema"""
    required_fields = ["analysis", "strategies", "priority", "confidence"]
    
    for field in required_fields:
        if field not in result:
            return False
    
    if not isinstance(result["analysis"], str):
        return False
    if not isinstance(result["strategies"], list) or len(result["strategies"]) == 0:
        return False
    if result["priority"] not in ["high", "medium", "low"]:
        return False
    if not isinstance(result["confidence"], (int, float)) or not (0.0 <= result["confidence"] <= 1.0):
        return False
    
    return True


def _validate_regulation_schema(result: dict) -> bool:
    """éªŒè¯ç­–ç•¥è°ƒèŠ‚ç»“æœæ˜¯å¦ç¬¦åˆschema"""
    required_fields = ["assessment", "adjustment_needed", "recommended_strategy", "confidence"]
    
    for field in required_fields:
        if field not in result:
            return False
    
    if not isinstance(result["assessment"], str):
        return False
    if not isinstance(result["adjustment_needed"], bool):
        return False
    if not isinstance(result["recommended_strategy"], str):
        return False
    if not isinstance(result["confidence"], (int, float)) or not (0.0 <= result["confidence"] <= 1.0):
        return False
    
    return True


def _validate_reflection_schema(result: dict) -> bool:
    """éªŒè¯åæ€ç»“æœæ˜¯å¦ç¬¦åˆschema"""
    required_fields = ["lessons", "suggestions", "quality"]
    
    for field in required_fields:
        if field not in result:
            return False
    
    if not isinstance(result["lessons"], list) or len(result["lessons"]) == 0:
        return False
    if not isinstance(result["suggestions"], list) or len(result["suggestions"]) == 0:
        return False
    if not isinstance(result["quality"], (int, float)) or not (0.0 <= result["quality"] <= 1.0):
        return False
    
    return True


def test_json_response_stability():
    """æµ‹è¯•JSONå“åº”ç¨³å®šæ€§"""
    print("\nğŸ“‹ JSONå“åº”ç¨³å®šæ€§ä¸“é¡¹æµ‹è¯•")
    print("=" * 60)
    
    try:
        from structured_response_optimizer import StructuredResponseOptimizer
        from langchain_openai import ChatOpenAI
        
        # åˆå§‹åŒ–LLM
        if os.getenv('DEEPSEEK_API_KEY'):
            llm = ChatOpenAI(
                model="deepseek-chat",
                openai_api_key=os.getenv('DEEPSEEK_API_KEY'),
                openai_api_base="https://api.deepseek.com",
                max_tokens=800,
                temperature=0.3
            )
        elif os.getenv('OPENAI_API_KEY'):
            llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                max_tokens=800,
                temperature=0.3
            )
        else:
            print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
            return False
        
        optimizer = StructuredResponseOptimizer(llm)
        
        # å¤§æ‰¹é‡æµ‹è¯•
        test_cases = [
            {"performance": {"speed": 0.7}, "context": {"env": "prod"}, "goals": ["optimize"]},
            {"performance": {"accuracy": 0.9}, "context": {"task": "analysis"}, "goals": ["maintain", "improve"]},
            {"performance": {"efficiency": 0.8}, "context": {"load": "high"}, "goals": ["stabilize"]},
        ]
        
        success_count = 0
        total_count = len(test_cases) * 3  # æ¯ä¸ªæµ‹è¯•æ¡ˆä¾‹é‡å¤3æ¬¡
        
        for i, test_case in enumerate(test_cases):
            print(f"\næµ‹è¯•æ¡ˆä¾‹ {i+1}: {len(test_case['goals'])} ä¸ªç›®æ ‡")
            
            for attempt in range(3):
                try:
                    result = optimizer.optimize_strategy_structured(
                        test_case["performance"],
                        test_case["context"],
                        test_case["goals"]
                    )
                    
                    if _validate_strategy_schema(result):
                        success_count += 1
                        print(f"  å°è¯• {attempt+1}: âœ…")
                    else:
                        print(f"  å°è¯• {attempt+1}: âŒ SchemaéªŒè¯å¤±è´¥")
                        
                except Exception as e:
                    print(f"  å°è¯• {attempt+1}: âŒ å¼‚å¸¸: {e}")
        
        success_rate = (success_count / total_count) * 100
        print(f"\nğŸ“ˆ JSONå“åº”ç¨³å®šæ€§: {success_rate:.1f}% ({success_count}/{total_count})")
        
        return success_rate >= 90
        
    except Exception as e:
        print(f"âŒ ç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("ğŸ¯ SuperEgo Agent å…¨é¢æµ‹è¯•å·¥å…·")
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # æµ‹è¯•æ‰€æœ‰æ–¹æ³•
    methods_success = test_all_superego_methods()
    
    # æµ‹è¯•JSONç¨³å®šæ€§
    stability_success = test_json_response_stability()
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»¼åˆæµ‹è¯•æ€»ç»“:")
    print(f"æ–¹æ³•åŠŸèƒ½æµ‹è¯•: {'âœ… æˆåŠŸ' if methods_success else 'âŒ å¤±è´¥'}")
    print(f"JSONç¨³å®šæ€§æµ‹è¯•: {'âœ… æˆåŠŸ' if stability_success else 'âŒ å¤±è´¥'}")
    
    if methods_success and stability_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("ğŸ’¡ SuperEgo Agentå·²å®Œå…¨æ”¯æŒç»“æ„åŒ–JSONè¾“å‡º")
        print("ğŸ“ˆ å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ use_structured_output=True")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥å¤±è´¥çš„å…·ä½“æ–¹æ³•å¹¶è¿›è¡Œè°ƒè¯•")