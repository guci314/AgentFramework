{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enhancedAgent_v2 import *\n",
    "from pythonTask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "调用智能体的原则='''\n",
    "\n",
    "### 智能体协同七诫\n",
    "1. **能力透明**  \n",
    "   *每个智能体必须显式声明能力边界*  \n",
    "   > 教训：未验证方法存在导致流程崩溃\n",
    "\n",
    "2. **状态显化**  \n",
    "   *跨智能体数据必须通过受控总线传递*  \n",
    "   > 教训：隐式变量共享引发不可测错误\n",
    "\n",
    "3. **错误熔断**  \n",
    "   *单点故障必须隔离在发生层*  \n",
    "   > 教训：模型错误扩散至文件验证层\n",
    "\n",
    "4. **验证前移**  \n",
    "   *关键检查点嵌入执行流中部*  \n",
    "   > 教训：后置验证增加回溯成本\n",
    "\n",
    "5. **知识反哺**  \n",
    "   *异常模式须转化为防范知识*  \n",
    "   > 教训：相同错误在不同环节重复发生\n",
    "\n",
    "6. **熵感控制**  \n",
    "   *系统需持续监测并压缩认知混乱度*  \n",
    "   > 教训：错误处理逻辑自身产生新熵\n",
    "\n",
    "7. **量子信任**  \n",
    "   *所有交互需携带可验证执行证明*  \n",
    "   > 教训：依赖未经验证的输出导致连环失败\n",
    "\n",
    "### 终极法则\n",
    "**智能体不是工具而是生态**  \n",
    "> 成功系统 = 清晰能力边界 × 严格状态管理 × 自愈机制  \n",
    "> 失败系统 = 模糊责任 + 隐式依赖 + 脆弱传递  \n",
    "\n",
    "这七条戒律构成智能体协同的免疫基因，使系统从机械执行进化为有机生命体。 \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 销售数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 销售分析任务\n",
    "# 设置代理服务器\n",
    "import os\n",
    "# os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "\n",
    "# os.environ[\"AGENT_MAX_TOKENS\"] = \"1000000\"\n",
    "from pythonTask import *\n",
    "from knowledge_agent import promgraming_knowledge\n",
    "\n",
    " \n",
    "# llm=llm_claude_sonnet_4\n",
    "# llm=llm_gemini_2_5_pro_preview_06_05_google\n",
    "# llm=llm_deepseek\n",
    "llm=llm_deepseek\n",
    "\n",
    "# 实例化 MultiStepAgent_v2 时不传入 agent_specs\n",
    "multi_agent = MultiStepAgent_v2(llm=llm_deepseek)\n",
    "# multi_agent.loadKnowledge(调用智能体的原则)\n",
    "\n",
    "# 使用 register_agent 动态注册 Agent\n",
    "general_agent = Agent(llm=llm_deepseek)\n",
    "general_agent.api_specification='''\n",
    "general_agent,擅长执行各种任务\n",
    "'''\n",
    "multi_agent.register_agent(\n",
    "    name=\"general_agent\",\n",
    "    instance=general_agent\n",
    ")\n",
    "\n",
    "document_agent = Agent(llm=llm_deepseek)\n",
    "document_agent.loadKnowledge(promgraming_knowledge)\n",
    "document_agent.loadKnowledge('如果指令要求你写文档，你应该调用llm_gemini_2_flash_openrouter语言模型生成文档')\n",
    "document_agent.api_specification='''\n",
    "文档Agent,擅长调用gemini模型写文档\n",
    "'''\n",
    "multi_agent.register_agent(\n",
    "    name=\"document_agent\",\n",
    "    instance=document_agent\n",
    ")\n",
    "\n",
    "\n",
    "# 示例主指令\n",
    "# main_instruction = \"请用python写一个hello world程序\"\n",
    "main_instruction = \"\"\"\n",
    "\n",
    "# 销售数据分析任务\n",
    "\n",
    "sales_data.csv是销售数据文件，请使用此文件进行数据分析。\n",
    "\n",
    "# 规则\n",
    "1. 不要生成图表\n",
    "2. 报告中必须包含每个地区，每个产品，每个销售人员的销售额\n",
    "3. 分析报告保存到sales_analysis_report.md\n",
    "4. 分析报告必须调用gemini模型生成\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 执行多步骤任务\n",
    "result = multi_agent.execute_multi_step(main_instruction)\n",
    "print(\"多步骤执行结果：\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=multi_agent.chat_stream('写个使用智能体的简短的经验教训总结')\n",
    "for chunk in response:\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例2：翻译模式（方案2）\n",
    "llm = llm_deepseek\n",
    "\n",
    "# 创建翻译模式的多步骤智能体（方案2：支持控制流）\n",
    "workflow_agent = MultiStepAgent_v2(llm=llm, use_autonomous_planning=False)\n",
    "\n",
    "# 注册智能体\n",
    "coder_agent = Agent(llm=llm)\n",
    "coder_agent.api_specification = '''\n",
    "通用编程智能体,擅长编写python代码\n",
    "'''\n",
    "workflow_agent.register_agent(\n",
    "    name=\"coder\",\n",
    "    instance=coder_agent\n",
    ")\n",
    "\n",
    "test_agent = Agent(llm=llm)\n",
    "test_agent.api_specification = '''\n",
    "软件测试智能体,擅长运行和测试python代码\n",
    "'''\n",
    "workflow_agent.register_agent(\n",
    "    name=\"tester\",\n",
    "    instance=test_agent\n",
    ")\n",
    "\n",
    "# 翻译模式 - 用户提供详细步骤，AI翻译为JSON计划并执行\n",
    "print(\"=== 翻译模式示例（方案2：动态控制流）===\")\n",
    "result = workflow_agent.execute_multi_step(\"\"\"\n",
    "1. coder: 实现一个简单的计算器类，包含加减乘除功能和完整单元测试\n",
    "2. coder: 把代码保存到simple_calculator.py\n",
    "3. tester: 运行simple_calculator.py，执行所有测试\n",
    "4. decision_maker: 分析测试结果，测试通过则完成工作流，测试失败则状态转移至步骤3重新执行测试\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    llm=llm_deepseek\n",
    "    code_file_editor = Agent(llm=llm)\n",
    "    code_file_editor.loadKnowledge('''\n",
    "    ## 编程任务示例代码\n",
    "    import aider_demo.aider_programming_demo\n",
    "    instruction = f\"保存代码到{file_name}\\n#代码\\n{code}\" \n",
    "    edit_file_names=[{file_name}] # 要编辑的文件列表\n",
    "    read_only_files=[] # 只读文件列表，只读文件不会被修改，是要编辑的文件依赖的文件\n",
    "    result=aider_demo.aider_programming_demo.programming(instruction,edit_file_names,read_only_files) # 执行编程任务\n",
    "    print(result) # 打印编程任务结果\n",
    "\n",
    "    ## 如果指令是编写或修改或保存python文件，优先使用aider_demo.aider_programming_demo.programming函数执行编程任务修改python文件。如果programming函数失败，直接使用python代码修改文件。\n",
    "                                ''')\n",
    "    \n",
    "    code_file_editor.api_specification=\"\"\"\n",
    "    python文件编辑Agent，擅长编辑python文件。\n",
    "    \n",
    "    输入：\n",
    "    1. 代码或者写个代码的指令\n",
    "    2. 要编辑的文件列表\n",
    "    3. 只读文件列表，只读文件不会被修改，是要编辑的文件依赖的文件\n",
    "    \n",
    "    输出：\n",
    "    1. 编辑后的代码\n",
    "    2. 编辑后的代码说明\n",
    "    \n",
    "    # 示例\n",
    "    #假设代码保存在变量code中\n",
    "    response=code_file_editor.execute_stream(f'''\n",
    "    把代码保存到/home/guci/myModule/AiResearch/math1.py\n",
    "\n",
    "    # 代码\n",
    "    {code}\n",
    "                                            ''')\n",
    "    result=None\n",
    "    for chunk in response:\n",
    "        result=chunk\n",
    "        print(chunk,end='',flush=True)\n",
    "        \n",
    "    print(result.return_value)\n",
    "    \"\"\"\n",
    "    \n",
    "    instruction=f'''\n",
    "    请把代码保存到/home/guci/myModule/AiResearch/message_compress.py\n",
    "    # 代码\n",
    "    {code}\n",
    "    '''\n",
    "    response=code_file_editor.execute_stream(instruction)\n",
    "    result=None\n",
    "    for chunk in response:\n",
    "        result=chunk\n",
    "        print(chunk,end='',flush=True)\n",
    "        \n",
    "# ====== 测试和示例代码 ======\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试代码：DeepSeek Prover 模型\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    \n",
    "    llm_prover_openrouter = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"deepseek/deepseek-prover-v2\", \n",
    "        base_url='https://openrouter.ai/api/v1',\n",
    "        api_key=os.getenv('OPENROUTER_API_KEY'),\n",
    "    )\n",
    "\n",
    "    x=llm_prover_openrouter.invoke(\"扩散模型架构是图灵完备的吗？\")\n",
    "    print(x.content)\n",
    "    \n",
    "    x=llm_prover_openrouter.invoke(\"请证明1+1=2，只允许使用纯逻辑\")\n",
    "    print(x.content)\n",
    "    \n",
    "    x=llm_prover_openrouter.invoke(\"图灵完备意味着能实现任意智能吗？\")\n",
    "    print(x.content)\n",
    "\n",
    "    x=llm_prover_openrouter.invoke(\"请用transformer架构实现一个通用图灵机，它能够模拟任意图灵机。代码注释请用中文。\")\n",
    "    print(x.content)\n",
    "\n",
    "    from pythonTask import llm_deepseek_r1\n",
    "    x=llm_deepseek_r1.invoke(\"请用transformer架构实现一个通用图灵机，它能够模拟任意图灵机。单元测试中模拟一个简单的图灵机。代码注释请用中文。\")\n",
    "    print(x.content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm=llm_deepseek\n",
    "    coder = Agent(llm=llm)\n",
    "    code_file_editor = Agent(llm=llm)\n",
    "    code_file_editor.loadKnowledge('''\n",
    "    ## 编程任务示例代码\n",
    "    import aider_demo.aider_programming_demo\n",
    "    instruction = f\"保存代码到{file_name}\\n#代码\\n{code}\" \n",
    "    edit_file_names=[{file_name}] # 要编辑的文件列表\n",
    "    read_only_files=[] # 只读文件列表，只读文件不会被修改，是要编辑的文件依赖的文件\n",
    "    result=aider_demo.aider_programming_demo.programming(instruction,edit_file_names,read_only_files) # 执行编程任务\n",
    "    print(result) # 打印编程任务结果\n",
    "\n",
    "    ## 如果指令是编写或修改或保存python文件，优先使用aider_demo.aider_programming_demo.programming函数执行编程任务修改python文件。如果programming函数失败，直接使用python代码修改文件。\n",
    "                                ''')\n",
    "    task_executer=Agent(llm=llm)\n",
    "    \n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    response=coder.execute_stream('''\n",
    "    写一个函数，计算斐波那契数列的第n个数.\n",
    "    \n",
    "    ''')\n",
    "    result:Result=None\n",
    "    for chunk in response:\n",
    "        result=chunk\n",
    "        print(chunk,end='',flush=True)\n",
    "            \n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    response=code_file_editor.execute_stream(f'''\n",
    "    把代码保存到/home/guci/myModule/AiResearch/hello_world.py\n",
    "\n",
    "    # 代码\n",
    "    {result.code}\n",
    "                                                ''')\n",
    "    result=None\n",
    "    for chunk in response:\n",
    "        result=chunk\n",
    "        print(chunk,end='',flush=True)\n",
    "\n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    response=task_executer.execute_stream(f'''\n",
    "    运行/home/guci/myModule/AiResearch/hello_world.py，判断测试是否通过\n",
    "    ''')\n",
    "    result=None\n",
    "    for chunk in response:\n",
    "        result=chunk\n",
    "        print(chunk,end='',flush=True)\n",
    "        \n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    print(result.return_value)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hello world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['https_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "# os.environ['all_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "\n",
    "# #%%\n",
    "# # 取消代理服务器环境变量设置\n",
    "# os.environ.pop('http_proxy', None)\n",
    "# os.environ.pop('https_proxy', None) \n",
    "# os.environ.pop('all_proxy', None)\n",
    "\n",
    "\n",
    "\n",
    "# 示例1：自主规划模式（默认）\n",
    "from pythonTask import llm_llama_4_maverick_openrouter, llm_deepseek\n",
    "llm = llm_deepseek\n",
    "\n",
    "# 创建自主规划模式的多步骤智能体\n",
    "multi_agent_autonomous = MultiStepAgent_v2(llm=llm, use_autonomous_planning=True)\n",
    "coder_agent = Agent(llm=llm)\n",
    "multi_agent_autonomous.register_agent(\n",
    "    name=\"coder\",\n",
    "    instance=coder_agent\n",
    ")\n",
    "\n",
    "# 自主规划模式 - AI会自主分解任务\n",
    "print(\"=== 自主规划模式示例 ===\")\n",
    "main_instruction = \"请用python写一个hello world程序\"\n",
    "multi_agent_autonomous.execute_multi_step(main_instruction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# web research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# os.environ[\"AGENT_MAX_TOKENS\"] = \"1000000\"\n",
    "from pythonTask import *\n",
    "from knowledge_agent import promgraming_knowledge\n",
    "from aiTools import *\n",
    "\n",
    "# llm=llm_gemini_2_5_pro_preview_05_06_google\n",
    "llm=llm_deepseek\n",
    "\n",
    "\n",
    "# 实例化 MultiStepAgent_v2 时不传入 agent_specs\n",
    "multi_agent = MultiStepAgent_v2(llm=llm)\n",
    "\n",
    "\n",
    "web_agent = Agent(llm=llm)\n",
    "web_agent.loadPythonModules(['aiTools'])\n",
    "web_agent.loadKnowledge('''\n",
    "如果指令要求你写文档，你应该调用llm_gemini_2_flash_openrouter语言模型生成文档\n",
    "## 调用语言模型示例\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm_gemini_2_flash_openrouter = ChatOpenAI(\n",
    "temperature=0,\n",
    "model=\"google/gemini-2.0-flash-001\", \n",
    "base_url='https://openrouter.ai/api/v1',\n",
    "api_key=os.getenv('OPENROUTER_API_KEY'\n",
    ")\n",
    "x:str=llm_gemini_2_flash_openrouter.invoke(\"你好\").content\n",
    "print(x)\n",
    "''')\n",
    "web_agent.api_specification=\"\"\"\n",
    "web_agent,擅长搜索网络信息,抓取网页内容，生成报告\n",
    "\n",
    "# api 规范\n",
    "\n",
    "## 生成报告\n",
    "### 输入\n",
    "1: 生成报告的指令，包含报告的要求和约束，这是必须的信息。\n",
    "1：参考资料，比如收集到的网页内容，大小必须小于一百万token。这是可选的信息。\n",
    "### 输出\n",
    "完整的报告\n",
    "\n",
    "# 示例\n",
    "\n",
    "```python\n",
    "with open('reference_document.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "processed_content = content.strip()\n",
    "\n",
    "prompt=f'''\n",
    "请用中文写一份销售报告。\n",
    "\n",
    "# 销售数据参考资料\n",
    "{processed_content}\n",
    "'''\n",
    "\n",
    "response=web_agent.execute_stream(prompt)\n",
    "result=None # response流最后一个元素是Result对象\n",
    "for chunk in response:\n",
    "    result=chunk\n",
    "    print(chunk,end='',flush=True)\n",
    "\n",
    "print('销售报告\\n')\n",
    "print(result.return_value)\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "multi_agent.register_agent(\n",
    "name=\"web_agent\",\n",
    "instance=web_agent\n",
    ")\n",
    "\n",
    "\n",
    "# 示例主指令\n",
    "# main_instruction = \"请用python写一个hello world程序\"\n",
    "main_instruction = \"\"\"\n",
    "\n",
    "# 任务\n",
    "1:执行者web_agent,使用关键词crewai 搜索网络信息，抓取搜索结果的前5个网页，把抓取到的网页合并保存在web_agent智能体的web_content变量中\n",
    "2:执行者web_agent,把web_agent智能体的web_content变量的内容传递给gemini模型生成crewai教程，教程必须使用中文。教程需包含crewai的系统架构，核心组件，示例代码。\n",
    "3:教程保存在crewai_tutorial.md文件中\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 执行多步骤任务\n",
    "result = multi_agent.execute_multi_step(main_instruction)\n",
    "print(\"多步骤执行结果：\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    summary_prompt='''\n",
    "    你的任务是创建一份详细的对话总结，密切关注用户的明确要求和你之前的行动。\n",
    "    这份总结应该全面捕获技术细节、代码模式和架构决策，这些对于继续对话和支持任何后续任务都是必不可少的。\n",
    "    你的总结应该按以下结构组织：\n",
    "    上下文：继续对话所需的上下文。如果根据当前任务适用，这应该包括：\n",
    "    之前的对话：关于整个与用户对话中讨论内容的高层次细节。这应该写得让别人能够跟上总体对话流程。\n",
    "    当前工作：详细描述在此次总结请求之前正在进行的工作。特别注意对话中最近的消息。\n",
    "    关键技术概念：列出所有重要的技术概念、技术、编码约定和讨论过的框架，这些可能与继续这项工作相关。\n",
    "    相关文件和代码：如果适用，枚举为任务继续而检查、修改或创建的具体文件和代码部分。特别注意最近的消息和更改。\n",
    "    问题解决：记录到目前为止解决的问题和任何正在进行的故障排除工作。\n",
    "    待处理任务和下一步：概述你被明确要求处理的所有待处理任务，以及列出你将为所有未完成工作采取的下一步，如果适用的话。在能增加清晰度的地方包含代码片段。对于任何下一步，包含来自最近对话的直接引用，准确显示你正在处理的任务以及你停止的地方。这应该是逐字逐句的，以确保任务之间的上下文没有信息丢失。\n",
    "    示例总结结构：\n",
    "    之前的对话：\n",
    "    [详细描述]\n",
    "    当前工作：\n",
    "    [详细描述]\n",
    "    关键技术概念：\n",
    "    [概念1]\n",
    "    [概念2]\n",
    "    [...]\n",
    "    相关文件和代码：\n",
    "    [文件名1]\n",
    "    [此文件重要性的总结]\n",
    "    [对此文件所做更改的总结，如有的话]\n",
    "    [重要代码片段]\n",
    "    [文件名2]\n",
    "    [重要代码片段]\n",
    "    [...]\n",
    "    问题解决：\n",
    "    [详细描述]\n",
    "    待处理任务和下一步：\n",
    "    [任务1详情和下一步]\n",
    "    [任务2详情和下一步]\n",
    "    [...]\n",
    "    仅输出到目前为止的对话总结，不要添加任何其他评论或解释。\n",
    "    '''\n",
    "\n",
    "    resonse=multi_agent.chat_stream(summary_prompt)\n",
    "    for chunk in resonse:\n",
    "        print(chunk,end='',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 磁盘分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=Agent(llm=llm_deepseek)\n",
    "response=agent.execute_stream('''\n",
    "    打印出/home/guci目录下所有size大于500M的文件\n",
    "                              ''')\n",
    "for chunk in response:\n",
    "    print(chunk,flush=True,end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
