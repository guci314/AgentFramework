#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾ªç¯é¢„é˜²æœºåˆ¶æµ‹è¯•

æµ‹è¯•æˆ‘ä»¬å®ç°çš„å¾ªç¯æ£€æµ‹å’Œé¢„é˜²æœºåˆ¶æ˜¯å¦æœ‰æ•ˆå·¥ä½œã€‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from cognitive_workflow_rule_base.domain.entities import WorkflowState, GlobalState, ProductionRule, RuleSet
from cognitive_workflow_rule_base.domain.value_objects import RulePhase
from cognitive_workflow_rule_base.services.rule_generation_service import RuleGenerationService
from cognitive_workflow_rule_base.services.language_model_service import LanguageModelService
from cognitive_workflow_rule_base.services.state_service import StateService
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_workflow_state_loop_detection():
    """æµ‹è¯•WorkflowStateçš„å¾ªç¯æ£€æµ‹åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ”¬ æµ‹è¯• WorkflowState å¾ªç¯æ£€æµ‹åŠŸèƒ½")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„WorkflowState
    workflow_state = WorkflowState(
        id="test_workflow_001",
        state="æµ‹è¯•åˆå§‹çŠ¶æ€",
        workflow_id="test_workflow",
        iteration_count=0
    )
    
    # æµ‹è¯•1: åŸºç¡€çŠ¶æ€ï¼Œåº”è¯¥æ²¡æœ‰å¾ªç¯
    print(f"ğŸ“‹ æµ‹è¯•1: åŸºç¡€çŠ¶æ€å¾ªç¯æ£€æµ‹")
    print(f"   å¾ªç¯æ£€æµ‹ç»“æœ: {workflow_state.detect_potential_loop()}")
    print(f"   çŠ¶æ€å¾ªç¯æ£€æµ‹: {workflow_state.check_state_cycle()}")
    assert not workflow_state.detect_potential_loop(), "åŸºç¡€çŠ¶æ€ä¸åº”è¯¥æ£€æµ‹åˆ°å¾ªç¯"
    
    # æµ‹è¯•2: æ¨¡æ‹Ÿè¿ç»­æ‰§è¡Œç›¸åŒè§„åˆ™
    print(f"\nğŸ“‹ æµ‹è¯•2: è¿ç»­æ‰§è¡Œç›¸åŒè§„åˆ™")
    same_rule_id = "rule_001"
    for i in range(4):  # æ‰§è¡Œ4æ¬¡ç›¸åŒè§„åˆ™
        workflow_state.mark_rule_executed(same_rule_id, success=True)
        print(f"   ç¬¬{i+1}æ¬¡æ‰§è¡Œ {same_rule_id}: è¿ç»­è®¡æ•° = {workflow_state.consecutive_same_rule_count}")
    
    print(f"   å¾ªç¯æ£€æµ‹ç»“æœ: {workflow_state.detect_potential_loop()}")
    assert workflow_state.detect_potential_loop(), "åº”è¯¥æ£€æµ‹åˆ°è¿ç»­æ‰§è¡Œå¾ªç¯"
    
    # æµ‹è¯•3: çŠ¶æ€æŒ‡çº¹å¾ªç¯æ£€æµ‹
    print(f"\nğŸ“‹ æµ‹è¯•3: çŠ¶æ€æŒ‡çº¹å¾ªç¯æ£€æµ‹") 
    # æ¨¡æ‹ŸçŠ¶æ€å¾ªç¯
    workflow_state.state = "å¾ªç¯çŠ¶æ€A"
    cycle1 = workflow_state.check_state_cycle()
    
    workflow_state.state = "å¾ªç¯çŠ¶æ€B"
    cycle2 = workflow_state.check_state_cycle()
    
    workflow_state.state = "å¾ªç¯çŠ¶æ€A"  # å›åˆ°çŠ¶æ€A
    cycle3 = workflow_state.check_state_cycle()
    
    print(f"   ç¬¬1æ¬¡çŠ¶æ€A: {cycle1}")
    print(f"   çŠ¶æ€B: {cycle2}")
    print(f"   ç¬¬2æ¬¡çŠ¶æ€A: {cycle3}")
    
    # æµ‹è¯•4: è§„åˆ™è¿‡æ»¤åŠŸèƒ½
    print(f"\nğŸ“‹ æµ‹è¯•4: è§„åˆ™è¿‡æ»¤åŠŸèƒ½")
    test_rules = [
        ProductionRule(id="rule_001", name="å·²æ‰§è¡Œè§„åˆ™", condition="test", action="test", agent_name="test"),
        ProductionRule(id="rule_002", name="å¤±è´¥è§„åˆ™", condition="test", action="test", agent_name="test"),
        ProductionRule(id="rule_003", name="å¯ç”¨è§„åˆ™", condition="test", action="test", agent_name="test"),
    ]
    
    # æ ‡è®°rule_002å¤±è´¥å¤šæ¬¡
    for _ in range(4):
        workflow_state.mark_rule_executed("rule_002", success=False)
    
    available_rules = workflow_state.get_available_rules(test_rules)
    available_rule_ids = [rule.id for rule in available_rules]
    
    print(f"   åŸå§‹è§„åˆ™: {[rule.id for rule in test_rules]}")
    print(f"   å¯ç”¨è§„åˆ™: {available_rule_ids}")
    
    assert "rule_001" not in available_rule_ids, "å·²æ‰§è¡Œè§„åˆ™åº”è¯¥è¢«è¿‡æ»¤"
    assert "rule_002" not in available_rule_ids, "å¤±è´¥è¿‡å¤šè§„åˆ™åº”è¯¥è¢«è¿‡æ»¤"
    assert "rule_003" in available_rule_ids, "æœªæ‰§è¡Œè§„åˆ™åº”è¯¥å¯ç”¨"
    
    print(f"\nâœ… WorkflowStateå¾ªç¯æ£€æµ‹åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")

def test_advanced_loop_detection():
    """æµ‹è¯•é«˜çº§å¾ªç¯æ£€æµ‹æœºåˆ¶"""
    print("\n" + "="*60)
    print("ğŸ”¬ æµ‹è¯•é«˜çº§å¾ªç¯æ£€æµ‹æœºåˆ¶")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„è¯­è¨€æ¨¡å‹æœåŠ¡
    class MockLLMService:
        def generate_natural_language_response(self, prompt):
            return "æµ‹è¯•å“åº”"
        
        def semantic_match(self, condition, state):
            from cognitive_workflow_rule_base.domain.value_objects import MatchingResult
            return MatchingResult(is_match=True, confidence=0.8, reasoning="æµ‹è¯•åŒ¹é…")
    
    # åˆ›å»ºè§„åˆ™ç”ŸæˆæœåŠ¡
    llm_service = MockLLMService()
    rule_gen_service = RuleGenerationService(llm_service)
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€ - æ™®é€šçŠ¶æ€
    normal_state = GlobalState(
        id="normal_state",
        state="æ­£å¸¸æ‰§è¡ŒçŠ¶æ€",
        iteration_count=5
    )
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€ - é«˜å¾ªç¯é£é™©çŠ¶æ€
    high_risk_state = GlobalState(
        id="high_risk_state", 
        state="ç­‰å¾…ç­‰å¾…ç­‰å¾…å‡†å¤‡å‡†å¤‡å‡†å¤‡",  # é‡å¤å…³é”®è¯
        iteration_count=20,
        execution_history=[
            "æ‰§è¡Œå¤±è´¥", "æ‰§è¡Œå¤±è´¥", "æ‰§è¡Œå¤±è´¥", "æ‰§è¡ŒæˆåŠŸ", "æ‰§è¡Œå¤±è´¥"
        ]
    )
    
    # åˆ›å»ºæµ‹è¯•è§„åˆ™é›†
    test_rule_set = RuleSet(
        id="test_ruleset",
        goal="æµ‹è¯•ç›®æ ‡",
        rules=[]
    )
    
    # æµ‹è¯•æ™®é€šçŠ¶æ€
    print(f"ğŸ“‹ æµ‹è¯•1: æ™®é€šçŠ¶æ€çš„å¾ªç¯æ£€æµ‹")
    normal_detection = rule_gen_service._advanced_loop_detection(normal_state, test_rule_set)
    print(f"   é£é™©è¯„åˆ†: {normal_detection['overall_risk_score']:.2f}")
    print(f"   æ£€æµ‹ç»“æœ: {normal_detection['recommendations']}")
    
    # æµ‹è¯•é«˜é£é™©çŠ¶æ€
    print(f"\nğŸ“‹ æµ‹è¯•2: é«˜é£é™©çŠ¶æ€çš„å¾ªç¯æ£€æµ‹")
    high_risk_detection = rule_gen_service._advanced_loop_detection(high_risk_state, test_rule_set)
    print(f"   é£é™©è¯„åˆ†: {high_risk_detection['overall_risk_score']:.2f}")
    print(f"   æ£€æµ‹ç»“æœ: {high_risk_detection['recommendations']}")
    
    # éªŒè¯é£é™©è¯„åˆ†
    assert normal_detection['overall_risk_score'] < 0.5, "æ™®é€šçŠ¶æ€é£é™©è¯„åˆ†åº”è¯¥è¾ƒä½"
    assert high_risk_detection['overall_risk_score'] >= 0.5, "é«˜é£é™©çŠ¶æ€é£é™©è¯„åˆ†åº”è¯¥è¾ƒé«˜"
    
    # æµ‹è¯•é¢„é˜²ç­–ç•¥
    print(f"\nğŸ“‹ æµ‹è¯•3: å¾ªç¯é¢„é˜²ç­–ç•¥")
    prevention_strategy = rule_gen_service._implement_loop_prevention_strategy(
        high_risk_state, high_risk_detection
    )
    
    if prevention_strategy:
        print(f"   é¢„é˜²ç­–ç•¥ç±»å‹: {prevention_strategy.decision_type}")
        print(f"   ç½®ä¿¡åº¦: {prevention_strategy.confidence}")
        print(f"   æ¨ç†: {prevention_strategy.reasoning}")
        assert prevention_strategy is not None, "é«˜é£é™©çŠ¶æ€åº”è¯¥è§¦å‘é¢„é˜²ç­–ç•¥"
    else:
        print(f"   æ²¡æœ‰è§¦å‘é¢„é˜²ç­–ç•¥")
    
    print(f"\nâœ… é«˜çº§å¾ªç¯æ£€æµ‹æœºåˆ¶æµ‹è¯•é€šè¿‡ï¼")

def test_enhanced_error_recovery():
    """æµ‹è¯•å¢å¼ºçš„é”™è¯¯æ¢å¤æœºåˆ¶"""
    print("\n" + "="*60)
    print("ğŸ”¬ æµ‹è¯•å¢å¼ºçš„é”™è¯¯æ¢å¤æœºåˆ¶")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„è¯­è¨€æ¨¡å‹æœåŠ¡å’Œä»£ç†æ³¨å†Œè¡¨
    class MockLLMService:
        def generate_natural_language_response(self, prompt):
            return "æµ‹è¯•å“åº”"
    
    class MockAgent:
        def __init__(self, name):
            self.name = name
            self.api_specification = f"{name} æ™ºèƒ½ä½“è§„èŒƒ"
    
    class MockAgentRegistry:
        def __init__(self):
            self.agents = {
                'primary_agent': MockAgent('primary_agent'),
                'backup_agent': MockAgent('backup_agent'),
                'fallback_agent': MockAgent('fallback_agent')
            }
    
    # åˆ›å»ºè§„åˆ™ç”ŸæˆæœåŠ¡
    llm_service = MockLLMService()
    agent_registry = MockAgentRegistry()
    rule_gen_service = RuleGenerationService(llm_service, agent_registry)
    rule_gen_service._current_agent_registry = agent_registry
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    test_state = GlobalState(
        id="test_error_state",
        state="é”™è¯¯æ¢å¤æµ‹è¯•çŠ¶æ€",
        iteration_count=3
    )
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„é”™è¯¯æ¢å¤
    test_cases = [
        {
            'name': 'æ™ºèƒ½ä½“ä¸å¯ç”¨é”™è¯¯',
            'failure_context': {
                'error_message': 'Agent not found: primary_agent',
                'agent_name': 'primary_agent',
                'global_state': test_state
            }
        },
        {
            'name': 'æ‰§è¡Œè¶…æ—¶é”™è¯¯',
            'failure_context': {
                'error_message': 'Execution timeout after 30 seconds',
                'agent_name': 'primary_agent',
                'global_state': test_state
            }
        },
        {
            'name': 'æ•°æ®å¤„ç†é”™è¯¯',
            'failure_context': {
                'error_message': 'Data format error in processing',
                'agent_name': 'primary_agent',
                'global_state': test_state
            }
        },
        {
            'name': 'æƒé™æ‹’ç»é”™è¯¯',
            'failure_context': {
                'error_message': 'Permission denied: access restricted',
                'agent_name': 'primary_agent',
                'global_state': test_state
            }
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ æµ‹è¯•{i}: {test_case['name']}")
        
        recovery_rules = rule_gen_service._enhanced_error_recovery_strategy(
            test_case['failure_context'], test_state
        )
        
        print(f"   ç”Ÿæˆæ¢å¤è§„åˆ™æ•°é‡: {len(recovery_rules)}")
        for j, rule in enumerate(recovery_rules):
            print(f"   è§„åˆ™{j+1}: {rule.name} (ä¼˜å…ˆçº§: {rule.priority})")
        
        assert len(recovery_rules) > 0, f"{test_case['name']}åº”è¯¥ç”Ÿæˆæ¢å¤è§„åˆ™"
    
    print(f"\nâœ… å¢å¼ºçš„é”™è¯¯æ¢å¤æœºåˆ¶æµ‹è¯•é€šè¿‡ï¼")

def test_integration():
    """é›†æˆæµ‹è¯•ï¼šæµ‹è¯•æ•´ä¸ªä¼˜åŒ–ç³»ç»Ÿçš„ååŒå·¥ä½œ"""
    print("\n" + "="*60)
    print("ğŸ”¬ é›†æˆæµ‹è¯•ï¼šä¼˜åŒ–ç³»ç»ŸååŒå·¥ä½œ")
    print("="*60)
    
    # åˆ›å»ºä¸€ä¸ªWorkflowStateå®ä¾‹æ¥æµ‹è¯•å®Œæ•´çš„å¾ªç¯é¢„é˜²æµç¨‹
    workflow_state = WorkflowState(
        id="integration_test",
        state="é›†æˆæµ‹è¯•çŠ¶æ€",
        workflow_id="integration_test",
        iteration_count=12  # ä¸­ç­‰è¿­ä»£æ¬¡æ•°
    )
    
    # æ¨¡æ‹Ÿä¸€äº›æ‰§è¡Œå†å²
    workflow_state.execution_history = [
        "[iter_1] å¼€å§‹æ‰§è¡Œä»»åŠ¡",
        "[iter_2] æ•°æ®æ”¶é›†å®Œæˆ",
        "[iter_3] å¤„ç†æ•°æ®å¤±è´¥",
        "[iter_4] é‡è¯•å¤„ç†æ•°æ®",
        "[iter_5] å¤„ç†æ•°æ®å¤±è´¥",
        "[iter_6] å°è¯•å¦ä¸€ç§æ–¹æ³•",
        "[iter_7] æ•°æ®å¤„ç†å¤±è´¥",
        "[iter_8] é‡è¯•å¤„ç†æ•°æ®",
        "[iter_9] å¤„ç†æ•°æ®å¤±è´¥",
        "[iter_10] å°è¯•ç®€åŒ–å¤„ç†",
        "[iter_11] å¤„ç†ä»ç„¶å¤±è´¥",
        "[iter_12] å½“å‰çŠ¶æ€"
    ]
    
    # æ·»åŠ ä¸€äº›å·²æ‰§è¡Œçš„è§„åˆ™
    executed_rules = ["rule_001", "rule_002", "rule_003", "rule_004", "rule_005"]
    for rule_id in executed_rules:
        workflow_state.mark_rule_executed(rule_id, success=False)  # æ¨¡æ‹Ÿå¤±è´¥
    
    print(f"ğŸ“Š å½“å‰çŠ¶æ€æ¦‚è§ˆ:")
    print(f"   è¿­ä»£æ¬¡æ•°: {workflow_state.iteration_count}")
    print(f"   å·²æ‰§è¡Œè§„åˆ™: {len(workflow_state.executed_rules)}")
    print(f"   å¤±è´¥å°è¯•: {workflow_state.failed_attempts}")
    print(f"   è¿ç»­ç›¸åŒè§„åˆ™: {workflow_state.consecutive_same_rule_count}")
    
    # æµ‹è¯•å¾ªç¯æ£€æµ‹
    print(f"\nğŸ“‹ å¾ªç¯æ£€æµ‹ç»“æœ:")
    loop_detected = workflow_state.detect_potential_loop()
    cycle_detected = workflow_state.check_state_cycle()
    
    print(f"   æ½œåœ¨å¾ªç¯: {loop_detected}")
    print(f"   çŠ¶æ€å¾ªç¯: {cycle_detected}")
    
    # æµ‹è¯•æ‰§è¡Œæ‘˜è¦
    summary = workflow_state.get_execution_summary()
    print(f"\nğŸ“Š æ‰§è¡Œæ‘˜è¦:")
    for key, value in summary.items():
        print(f"   {key}: {value}")
    
    # éªŒè¯ç³»ç»Ÿèƒ½å¤Ÿæ­£ç¡®è¯†åˆ«é—®é¢˜çŠ¶æ€
    assert summary['total_failures'] > 0, "åº”è¯¥è®°å½•åˆ°æ‰§è¡Œå¤±è´¥"
    assert summary['iteration_count'] > 10, "åº”è¯¥æ£€æµ‹åˆ°é«˜è¿­ä»£æ¬¡æ•°"
    
    print(f"\nâœ… é›†æˆæµ‹è¯•é€šè¿‡ - ä¼˜åŒ–ç³»ç»Ÿæ­£å¸¸ååŒå·¥ä½œï¼")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹å¾ªç¯é¢„é˜²æœºåˆ¶å®Œæ•´æµ‹è¯•")
    print("="*80)
    
    try:
        test_workflow_state_loop_detection()
        test_advanced_loop_detection()
        test_enhanced_error_recovery()
        test_integration()
        
        print("\n" + "="*80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¾ªç¯é¢„é˜²æœºåˆ¶å·¥ä½œæ­£å¸¸")
        print("="*80)
        
        print("\nğŸ“‹ ä¼˜åŒ–æ€»ç»“:")
        print("âœ… WorkflowState å¾ªç¯æ£€æµ‹åŠŸèƒ½å®Œå–„")
        print("âœ… é«˜çº§å¤šç»´åº¦å¾ªç¯æ£€æµ‹æœºåˆ¶æœ‰æ•ˆ")
        print("âœ… å¢å¼ºçš„é”™è¯¯æ¢å¤ç­–ç•¥åŠŸèƒ½é½å…¨")
        print("âœ… ç³»ç»Ÿå„ç»„ä»¶ååŒå·¥ä½œè‰¯å¥½")
        print("\nğŸ”§ è¿™äº›ä¼˜åŒ–åº”è¯¥èƒ½å¤Ÿæœ‰æ•ˆè§£å†³ä¹‹å‰é‡åˆ°çš„æ­»å¾ªç¯é—®é¢˜ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)