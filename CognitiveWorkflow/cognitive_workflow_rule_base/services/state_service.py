# -*- coding: utf-8 -*-
"""
çŠ¶æ€æœåŠ¡

ä¸“æ³¨äºè‡ªç„¶è¯­è¨€çŠ¶æ€ç®¡ç†ï¼Œæä¾›çŠ¶æ€æ›´æ–°ã€çŠ¶æ€æ£€æŸ¥ã€
çŠ¶æ€æŒä¹…åŒ–å’ŒçŠ¶æ€åˆ†æç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚
"""

from typing import Dict, List, Any, Optional, Tuple, TYPE_CHECKING
import logging
from datetime import datetime
import uuid

from ..domain.entities import GlobalState, WorkflowResult, ProductionRule, WorkflowState
from ..domain.repositories import StateRepository
from ..domain.value_objects import StateChangeAnalysis, MatchingResult
from .language_model_service import LanguageModelService
from ..utils.concurrent_safe_id_generator import id_generator

if TYPE_CHECKING:
    from ..domain.entities import RuleSet

logger = logging.getLogger(__name__)


class StateService:
    """çŠ¶æ€æœåŠ¡ - ä¸“æ³¨äºè‡ªç„¶è¯­è¨€çŠ¶æ€ç®¡ç†"""
    
    def __init__(self, 
                 llm_service: LanguageModelService,
                 state_repository: StateRepository):
        """
        åˆå§‹åŒ–çŠ¶æ€æœåŠ¡
        
        Args:
            llm_service: è¯­è¨€æ¨¡å‹æœåŠ¡
            state_repository: çŠ¶æ€ä»“å‚¨
        """
        self.llm_service = llm_service
        self.state_repository = state_repository
        self._current_state: Optional[GlobalState] = None
        
    def update_state(self, execution_result: WorkflowResult, global_state: GlobalState, goal: str = None, rule_set: 'RuleSet' = None) -> GlobalState:
        """
        æ›´æ–°å…¨å±€çŠ¶æ€å¹¶æ£€æŸ¥ç›®æ ‡è¾¾æˆ
        
        Args:
            execution_result: æ‰§è¡Œç»“æœ
            global_state: å½“å‰å…¨å±€çŠ¶æ€
            goal: å·¥ä½œæµç›®æ ‡ï¼ˆå¯é€‰ï¼Œç”¨äºç›®æ ‡è¾¾æˆæ£€æŸ¥ï¼‰
            rule_set: å½“å‰è§„åˆ™é›†ï¼ˆå¯é€‰ï¼Œç”¨äºæ™ºèƒ½çŠ¶æ€ç”Ÿæˆå’Œæ•°æ®æ”¶é›†ï¼‰
            
        Returns:
            GlobalState: æ›´æ–°åçš„å…¨å±€çŠ¶æ€ï¼ŒåŒ…å«ç›®æ ‡è¾¾æˆä¿¡æ¯
        """
        try:
            # ç”Ÿæˆæ–°çš„çŠ¶æ€æè¿°ï¼ˆè€ƒè™‘è§„åˆ™é›†ä¸Šä¸‹æ–‡ï¼‰
            new_description = self._generate_new_state_description(
                execution_result, global_state, rule_set
            )
            
            # ğŸ”‘ åˆ›å»ºæ–°çš„çŠ¶æ€å®ä¾‹ï¼ˆä½¿ç”¨å®‰å…¨IDç”Ÿæˆï¼‰
            new_state_id = id_generator.generate_state_id(global_state.workflow_id, global_state.iteration_count + 1)
            new_state = GlobalState(
                id=new_state_id,
                state=new_description,
                context_variables=global_state.context_variables.copy(),
                execution_history=global_state.execution_history.copy(),
                # timestamp=datetime.now(),  # Removed for LLM caching
                workflow_id=global_state.workflow_id,
                iteration_count=global_state.iteration_count + 1,
                goal_achieved=global_state.goal_achieved
            )
            
            # æ›´æ–°æ‰§è¡Œå†å²
            history_entry = self._create_history_entry(execution_result)
            new_state.execution_history.append(history_entry)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡å˜é‡
            self._update_context_variables(new_state, execution_result)
            
            # æ£€æŸ¥ç›®æ ‡è¾¾æˆï¼ˆå¦‚æœæä¾›äº†ç›®æ ‡ï¼‰
            if goal and not new_state.goal_achieved:
                is_goal_achieved = self.evaluate_goal_achievement(goal, new_state)
                if is_goal_achieved:
                    new_state.goal_achieved = True
                    logger.info(f"æ£€æµ‹åˆ°ç›®æ ‡å·²è¾¾æˆ: {goal}")
                    # æ·»åŠ ç›®æ ‡è¾¾æˆè®°å½•åˆ°å†å²
                    new_state.execution_history.append("[ç›®æ ‡è¾¾æˆ] å·¥ä½œæµç›®æ ‡å·²æˆåŠŸå®Œæˆ")
            
            # ä¿å­˜çŠ¶æ€
            self.state_repository.save_state(new_state)
            self._current_state = new_state
            
            # ä½¿ç”¨çº¢è‰²å­—ä½“æ‰“å°çŠ¶æ€æ›´æ–°ä¿¡æ¯
            self._print_state_update_in_red(new_state, execution_result)
            
            goal_status = " [ç›®æ ‡å·²è¾¾æˆ]" if new_state.goal_achieved else ""
            logger.info(f"çŠ¶æ€å·²æ›´æ–°: {new_description[:100]}...{goal_status}")
            return new_state
            
        except Exception as e:
            logger.error(f"çŠ¶æ€æ›´æ–°å¤±è´¥: {e}")
            # è¿”å›åŸçŠ¶æ€ï¼Œé¿å…ç ´åå·¥ä½œæµ
            return global_state
    
    def get_current_state(self) -> Optional[GlobalState]:
        """
        è·å–å½“å‰çŠ¶æ€
        
        Returns:
            Optional[GlobalState]: å½“å‰çŠ¶æ€ï¼Œå¯èƒ½ä¸ºNone
        """
        return self._current_state
    
    def get_state_history(self, workflow_id: str) -> List[GlobalState]:
        """
        è·å–çŠ¶æ€å†å²
        
        Args:
            workflow_id: å·¥ä½œæµID
            
        Returns:
            List[GlobalState]: çŠ¶æ€å†å²åˆ—è¡¨
        """
        try:
            return self.state_repository.get_state_history(workflow_id)
        except Exception as e:
            logger.error(f"è·å–çŠ¶æ€å†å²å¤±è´¥: {e}")
            return []
    
    def check_rule_condition_satisfied(self, 
                                     condition: str, 
                                     global_state: GlobalState) -> Tuple[bool, float, str]:
        """
        æ£€æŸ¥è§„åˆ™æ¡ä»¶æ˜¯å¦æ»¡è¶³
        
        Args:
            condition: è§„åˆ™æ¡ä»¶ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            global_state: å…¨å±€çŠ¶æ€
            
        Returns:
            Tuple[bool, float, str]: (æ˜¯å¦æ»¡è¶³, ç½®ä¿¡åº¦, è§£é‡Š)
        """
        try:
            # ä½¿ç”¨è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åŒ¹é…
            matching_result = self.llm_service.semantic_match(
                condition, global_state.state
            )
            
            return (
                matching_result.is_match,
                matching_result.confidence,
                matching_result.reasoning
            )
            
        except Exception as e:
            logger.error(f"æ¡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
            return False, 0.0, f"æ£€æŸ¥å¤±è´¥: {str(e)}"
    
    def find_applicable_rules(self, 
                            rules: List[ProductionRule], 
                            global_state: GlobalState) -> List[ProductionRule]:
        """
        æŸ¥æ‰¾é€‚ç”¨è§„åˆ™
        
        Args:
            rules: è§„åˆ™åˆ—è¡¨
            global_state: å…¨å±€çŠ¶æ€
            
        Returns:
            List[ProductionRule]: é€‚ç”¨çš„è§„åˆ™åˆ—è¡¨
        """
        applicable_rules = []
        
        for rule in rules:
            try:
                is_satisfied, confidence, _ = self.check_rule_condition_satisfied(
                    rule.condition, global_state
                )
                
                # åªæœ‰é«˜ç½®ä¿¡åº¦çš„åŒ¹é…æ‰è®¤ä¸ºæ˜¯é€‚ç”¨çš„
                if is_satisfied and confidence >= 0.7:
                    applicable_rules.append(rule)
                    logger.debug(f"è§„åˆ™é€‚ç”¨: {rule.name} (ç½®ä¿¡åº¦: {confidence:.2f})")
                
            except Exception as e:
                logger.error(f"è§„åˆ™é€‚ç”¨æ€§æ£€æŸ¥å¤±è´¥: {rule.id}, {e}")
                continue
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        applicable_rules.sort(key=lambda r: r.priority, reverse=True)
        
        logger.info(f"æ‰¾åˆ° {len(applicable_rules)} ä¸ªé€‚ç”¨è§„åˆ™")
        return applicable_rules
    
    def evaluate_goal_achievement(self, goal: str, global_state: GlobalState) -> bool:
        """
        è¯„ä¼°ç›®æ ‡æ˜¯å¦è¾¾æˆï¼ˆå¢å¼ºç‰ˆ - åŒ…å«å¾ªç¯æ£€æµ‹è€ƒè™‘ï¼‰
        
        Args:
            goal: ç›®æ ‡æè¿°
            global_state: å…¨å±€çŠ¶æ€
            
        Returns:
            bool: æ˜¯å¦è¾¾æˆç›®æ ‡
        """
        try:
            # ğŸ”‘ æ–°å¢ï¼šæ£€æŸ¥å¾ªç¯æŒ‡æ ‡ï¼Œå¦‚æœæ£€æµ‹åˆ°å¾ªç¯å€¾å‘äºè¾¾æˆç›®æ ‡
            loop_indicators = self._analyze_loop_indicators_for_goal_evaluation(global_state)
            
            # å¦‚æœæ£€æµ‹åˆ°ä¸¥é‡å¾ªç¯ï¼Œå€¾å‘äºè®¤ä¸ºç›®æ ‡å·²è¾¾æˆ
            if loop_indicators['should_force_completion']:
                logger.warning(f"æ£€æµ‹åˆ°å¾ªç¯ï¼Œå¼ºåˆ¶è®¤ä¸ºç›®æ ‡è¾¾æˆ: {loop_indicators['reason']}")
                return True
            
            # åŸºç¡€çš„LLMç›®æ ‡è¯„ä¼°
            is_achieved, confidence, analysis = self.llm_service.evaluate_goal_achievement(
                goal, global_state.state
            )
            
            # ğŸ”‘ å¢å¼ºï¼šæ ¹æ®å¾ªç¯é£é™©è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
            confidence_threshold = self._get_adaptive_confidence_threshold(loop_indicators)
            
            logger.info(f"ç›®æ ‡è¾¾æˆè¯„ä¼°: {is_achieved} (ç½®ä¿¡åº¦: {confidence:.2f}, é˜ˆå€¼: {confidence_threshold:.2f})")
            logger.debug(f"åˆ†æ: {analysis}")
            logger.debug(f"å¾ªç¯æŒ‡æ ‡: {loop_indicators}")
            
            # æ ¹æ®å¾ªç¯æƒ…å†µè°ƒæ•´è¯„ä¼°ç»“æœ
            final_result = is_achieved and confidence >= confidence_threshold
            
            # å¦‚æœæ™®é€šè¯„ä¼°å¤±è´¥ä½†æœ‰å¾ªç¯æŒ‡æ ‡ï¼Œè€ƒè™‘éƒ¨åˆ†è¾¾æˆ
            if not final_result and loop_indicators['partial_completion_likely']:
                logger.info("è™½ç„¶æœªå®Œå…¨è¾¾æˆç›®æ ‡ï¼Œä½†è€ƒè™‘åˆ°å¾ªç¯æƒ…å†µï¼Œè®¤ä¸ºå·²éƒ¨åˆ†è¾¾æˆ")
                final_result = True
            
            return final_result
            
        except Exception as e:
            logger.error(f"ç›®æ ‡è¾¾æˆè¯„ä¼°å¤±è´¥: {e}")
            return False
    
    def save_state(self, global_state: GlobalState) -> bool:
        """
        ä¿å­˜çŠ¶æ€
        
        Args:
            global_state: è¦ä¿å­˜çš„çŠ¶æ€
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            self.state_repository.save_state(global_state)
            self._current_state = global_state
            return True
        except Exception as e:
            logger.error(f"çŠ¶æ€ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def load_state(self, state_id: str) -> Optional[GlobalState]:
        """
        åŠ è½½çŠ¶æ€
        
        Args:
            state_id: çŠ¶æ€ID
            
        Returns:
            Optional[GlobalState]: åŠ è½½çš„çŠ¶æ€ï¼Œå¯èƒ½ä¸ºNone
        """
        try:
            state = self.state_repository.load_state(state_id)
            self._current_state = state
            return state
        except Exception as e:
            logger.error(f"çŠ¶æ€åŠ è½½å¤±è´¥: {e}")
            return None
    
    def analyze_state_changes(self, 
                            before: GlobalState, 
                            after: GlobalState) -> StateChangeAnalysis:
        """
        åˆ†æçŠ¶æ€å˜åŒ–
        
        Args:
            before: å˜åŒ–å‰çŠ¶æ€
            after: å˜åŒ–åçŠ¶æ€
            
        Returns:
            StateChangeAnalysis: çŠ¶æ€å˜åŒ–åˆ†æ
        """
        try:
            # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
            similarity = self.llm_service.evaluate_semantic_similarity(
                before.state, after.state
            )
            
            # è¯†åˆ«å…³é”®å˜åŒ–
            key_changes = self._identify_key_changes(before, after)
            
            # è¯„ä¼°å˜åŒ–é‡è¦æ€§
            change_significance = self._evaluate_change_significance(
                before, after, similarity
            )
            
            return StateChangeAnalysis(
                before_state=before.state,
                after_state=after.state,
                key_changes=key_changes,
                semantic_similarity=similarity,
                change_significance=change_significance,
                timestamp=datetime.now()  # Keep this as it's part of analysis, not state
            )
            
        except Exception as e:
            logger.error(f"çŠ¶æ€å˜åŒ–åˆ†æå¤±è´¥: {e}")
            return StateChangeAnalysis(
                before_state=before.state,
                after_state=after.state,
                key_changes=[],
                semantic_similarity=0.0,
                change_significance='unknown',
                timestamp=datetime.now()  # Keep this as it's part of analysis, not state
            )
    
    def create_initial_state(self, goal: str, workflow_id: str) -> GlobalState:
        """
        åˆ›å»ºåˆå§‹çŠ¶æ€
        
        Args:
            goal: å·¥ä½œæµç›®æ ‡
            workflow_id: å·¥ä½œæµID
            
        Returns:
            GlobalState: åˆå§‹çŠ¶æ€
        """
        initial_description = f"å·¥ä½œæµå·²å¯åŠ¨ï¼Œç›®æ ‡ï¼š{goal}ã€‚å½“å‰å¤„äºåˆå§‹çŠ¶æ€ï¼Œç­‰å¾…è§„åˆ™ç”Ÿæˆå’Œæ‰§è¡Œã€‚"
        
        # ğŸ”‘ ä½¿ç”¨å®‰å…¨IDç”Ÿæˆåˆå§‹çŠ¶æ€
        initial_state_id = id_generator.generate_state_id(workflow_id, 0)
        initial_state = GlobalState(
            id=initial_state_id,
            state=initial_description,
            context_variables={'goal': goal},
            execution_history=[f"[iter_0] å·¥ä½œæµå¯åŠ¨"],  # Use iteration instead of timestamp
            # timestamp=datetime.now(),  # Removed for LLM caching
            workflow_id=workflow_id,
            iteration_count=0,
            goal_achieved=False
        )
        
        # ä¿å­˜åˆå§‹çŠ¶æ€
        self.save_state(initial_state)
        
        logger.info(f"åˆå§‹çŠ¶æ€å·²åˆ›å»º: {workflow_id}")
        return initial_state
    
    def _generate_new_state_description(self, 
                                       execution_result: WorkflowResult, 
                                       current_state: GlobalState,
                                       rule_set: 'RuleSet' = None) -> str:
        """
        ç”Ÿæˆæ–°çš„çŠ¶æ€æè¿°ï¼Œè€ƒè™‘è§„åˆ™é›†ä¸Šä¸‹æ–‡
        
        Args:
            execution_result: æ‰§è¡Œç»“æœ
            current_state: å½“å‰çŠ¶æ€
            rule_set: å½“å‰è§„åˆ™é›†ï¼ˆç”¨äºäº†è§£å¯èƒ½éœ€è¦çš„æ•°æ®å’Œåç»­è§„åˆ™ï¼‰
            
        Returns:
            str: æ–°çš„çŠ¶æ€æè¿°
        """
        try:
            # æ„å»ºè§„åˆ™é›†ä¸Šä¸‹æ–‡ä¿¡æ¯
            rule_context = ""
            if rule_set:
                rule_context = f"""

## å½“å‰è§„åˆ™é›†ä¸Šä¸‹æ–‡
ç›®æ ‡: {rule_set.goal}
å¯ç”¨è§„åˆ™æ¦‚è§ˆ:
{self._format_rules_for_context(rule_set.rules)}

## æ•°æ®æ”¶é›†æŒ‡å¯¼
è¯·åœ¨çŠ¶æ€æè¿°ä¸­ç‰¹åˆ«å…³æ³¨å’Œæ”¶é›†ä»¥ä¸‹ç±»å‹çš„ä¿¡æ¯ï¼š
1. è§„åˆ™æ‰§è¡Œç›¸å…³çš„å…³é”®æ•°æ®å’Œå˜é‡
2. å¯èƒ½è§¦å‘åç»­è§„åˆ™çš„çŠ¶æ€å˜åŒ–
3. ç›®æ ‡è¾¾æˆè¿›åº¦çš„å…·ä½“æŒ‡æ ‡
4. å¯èƒ½å½±å“è§„åˆ™é€‰æ‹©çš„ç¯å¢ƒå› ç´ 
"""
            
            prompt = f"""
åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆæ–°çš„ç³»ç»ŸçŠ¶æ€æè¿°ï¼š

å½“å‰çŠ¶æ€: {current_state.state}

æ‰§è¡Œç»“æœ:
- æˆåŠŸ: {'æ˜¯' if execution_result.success else 'å¦'}
- æ¶ˆæ¯: {execution_result.message}
- æ•°æ®: {execution_result.data if execution_result.data else 'æ— '}
{rule_context}

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®çš„æ–°çŠ¶æ€æè¿°ï¼Œé‡ç‚¹è¯´æ˜ï¼š
1. æ‰§è¡Œçš„æ“ä½œå’Œç»“æœ
2. å½“å‰ç³»ç»Ÿçš„ä¸»è¦çŠ¶æ€
3. ä¸‹ä¸€æ­¥å¯èƒ½çš„è¡ŒåŠ¨æ–¹å‘
4. ã€é‡è¦ã€‘æ”¶é›†å¹¶æåŠè§„åˆ™é›†å¯èƒ½ç”¨åˆ°çš„å…³é”®æ•°æ®å’ŒçŠ¶æ€ä¿¡æ¯

çŠ¶æ€æè¿°åº”è¯¥æ¸…æ™°ã€å®¢è§‚ï¼Œä¾¿äºåç»­çš„è§„åˆ™åŒ¹é…å’Œå†³ç­–ã€‚
"""
            
            new_description = self.llm_service.generate_natural_language_response(prompt)
            
            # ç¡®ä¿æè¿°ä¸ä¸ºç©º
            if not new_description.strip():
                new_description = f"æ‰§è¡Œå®Œæˆ: {execution_result.message}"
            
            return new_description
            
        except Exception as e:
            logger.error(f"çŠ¶æ€æè¿°ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•çš„æè¿°
            status = "æˆåŠŸ" if execution_result.success else "å¤±è´¥"
            return f"ä¸Šä¸€æ­¥æ‰§è¡Œ{status}: {execution_result.message}"
    
    def _create_history_entry(self, execution_result: WorkflowResult) -> str:
        """
        åˆ›å»ºå†å²è®°å½•æ¡ç›®
        
        Args:
            execution_result: æ‰§è¡Œç»“æœ
            
        Returns:
            str: å†å²è®°å½•æ¡ç›®
        """
        # Use deterministic identifier instead of timestamp
        status = "æˆåŠŸ" if execution_result.success else "å¤±è´¥"
        return f"[æ‰§è¡Œ{status}] {execution_result.message}"
    
    def _update_context_variables(self, state: GlobalState, execution_result: WorkflowResult) -> None:
        """
        æ›´æ–°ä¸Šä¸‹æ–‡å˜é‡
        
        Args:
            state: è¦æ›´æ–°çš„çŠ¶æ€
            execution_result: æ‰§è¡Œç»“æœ
        """
        # ä»æ‰§è¡Œç»“æœçš„å…ƒæ•°æ®ä¸­æ›´æ–°ä¸Šä¸‹æ–‡
        if execution_result.metadata:
            for key, value in execution_result.metadata.items():
                if key.startswith('context_'):
                    # ç§»é™¤å‰ç¼€å¹¶æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                    context_key = key[8:]  # ç§»é™¤ 'context_' å‰ç¼€
                    state.context_variables[context_key] = value
        
        # æ›´æ–°æ‰§è¡Œç»Ÿè®¡
        state.context_variables['last_execution_success'] = execution_result.success
        # state.context_variables['last_execution_time'] = execution_result.timestamp.isoformat()  # Removed for LLM caching
        
        # å¦‚æœæ‰§è¡Œç»“æœåŒ…å«æ•°æ®ï¼Œå¯èƒ½éœ€è¦æ›´æ–°ç‰¹å®šçš„ä¸Šä¸‹æ–‡å˜é‡
        if execution_result.data and isinstance(execution_result.data, dict):
            for key, value in execution_result.data.items():
                if key.startswith('state_'):
                    # çŠ¶æ€ç›¸å…³çš„æ•°æ®
                    context_key = key[6:]  # ç§»é™¤ 'state_' å‰ç¼€
                    state.context_variables[context_key] = value
    
    def _identify_key_changes(self, before: GlobalState, after: GlobalState) -> List[str]:
        """
        è¯†åˆ«å…³é”®å˜åŒ–
        
        Args:
            before: å˜åŒ–å‰çŠ¶æ€
            after: å˜åŒ–åçŠ¶æ€
            
        Returns:
            List[str]: å…³é”®å˜åŒ–åˆ—è¡¨
        """
        changes = []
        
        # æ¯”è¾ƒä¸Šä¸‹æ–‡å˜é‡
        before_context = before.context_variables
        after_context = after.context_variables
        
        # æ–°å¢çš„å˜é‡
        new_keys = set(after_context.keys()) - set(before_context.keys())
        for key in new_keys:
            changes.append(f"æ–°å¢ä¸Šä¸‹æ–‡å˜é‡: {key} = {after_context[key]}")
        
        # ä¿®æ”¹çš„å˜é‡
        common_keys = set(before_context.keys()) & set(after_context.keys())
        for key in common_keys:
            if before_context[key] != after_context[key]:
                changes.append(f"æ›´æ–°ä¸Šä¸‹æ–‡å˜é‡: {key} = {after_context[key]}")
        
        # åˆ é™¤çš„å˜é‡
        removed_keys = set(before_context.keys()) - set(after_context.keys())
        for key in removed_keys:
            changes.append(f"åˆ é™¤ä¸Šä¸‹æ–‡å˜é‡: {key}")
        
        # è¿­ä»£æ¬¡æ•°å˜åŒ–
        if after.iteration_count != before.iteration_count:
            changes.append(f"è¿­ä»£æ¬¡æ•°: {before.iteration_count} -> {after.iteration_count}")
        
        return changes
    
    def _evaluate_change_significance(self, 
                                    before: GlobalState, 
                                    after: GlobalState, 
                                    similarity: float) -> str:
        """
        è¯„ä¼°å˜åŒ–é‡è¦æ€§
        
        Args:
            before: å˜åŒ–å‰çŠ¶æ€
            after: å˜åŒ–åçŠ¶æ€
            similarity: è¯­ä¹‰ç›¸ä¼¼åº¦
            
        Returns:
            str: å˜åŒ–é‡è¦æ€§çº§åˆ«
        """
        # åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦åˆ¤æ–­
        if similarity >= 0.9:
            return 'minor'
        elif similarity >= 0.7:
            return 'moderate'
        else:
            return 'major'
    
    def _print_state_update_in_red(self, new_state: GlobalState, execution_result: WorkflowResult) -> None:
        """
        ä½¿ç”¨çº¢è‰²å­—ä½“æ‰“å°çŠ¶æ€æ›´æ–°ä¿¡æ¯
        
        Args:
            new_state: æ›´æ–°åçš„å…¨å±€çŠ¶æ€
            execution_result: æ‰§è¡Œç»“æœ
        """
        # ANSIçº¢è‰²å­—ä½“ä»£ç 
        RED = '\033[91m'
        GREEN = '\033[92m'
        YELLOW = '\033[93m'
        BOLD = '\033[1m'
        RESET = '\033[0m'
        
        try:
            print(f"\n{RED}{BOLD}ğŸ”„ çŠ¶æ€ç®¡ç†å™¨ - çŠ¶æ€æ›´æ–°{RESET}")
            print(f"{RED}{'=' * 50}{RESET}")
            
            # æ‰“å°æ‰§è¡Œç»“æœçŠ¶æ€
            status_color = GREEN if execution_result.success else RED
            status_icon = "âœ…" if execution_result.success else "âŒ"
            print(f"{RED}{BOLD}ğŸ“Š æ‰§è¡ŒçŠ¶æ€:{RESET} {status_color}{status_icon} {'æˆåŠŸ' if execution_result.success else 'å¤±è´¥'}{RESET}")
            
            # æ‰“å°æ‰§è¡Œæ¶ˆæ¯
            print(f"{RED}{BOLD}ğŸ’¬ æ‰§è¡Œæ¶ˆæ¯:{RESET}")
            print(f"{RED}   {execution_result.message}{RESET}")
            
            # æ‰“å°æ–°çŠ¶æ€æè¿°
            print(f"{RED}{BOLD}ğŸ¯ æ–°çŠ¶æ€æè¿°:{RESET}")
            # é™åˆ¶æ˜¾ç¤ºé•¿åº¦ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
            state_desc = new_state.state
            if len(state_desc) > 150:
                state_desc = state_desc[:150] + "..."
            print(f"{RED}   {state_desc}{RESET}")
            
            # æ‰“å°è¿­ä»£ä¿¡æ¯
            print(f"{RED}{BOLD}ğŸ”¢ è¿­ä»£æ¬¡æ•°:{RESET} {RED}{new_state.iteration_count}{RESET}")
            
            # æ‰“å°ç›®æ ‡è¾¾æˆçŠ¶æ€
            goal_color = GREEN if new_state.goal_achieved else YELLOW
            goal_icon = "ğŸ‰" if new_state.goal_achieved else "â³"
            goal_text = "å·²è¾¾æˆ" if new_state.goal_achieved else "è¿›è¡Œä¸­"
            print(f"{RED}{BOLD}ğŸ¯ ç›®æ ‡çŠ¶æ€:{RESET} {goal_color}{goal_icon} {goal_text}{RESET}")
            
            # æ‰“å°ä¸Šä¸‹æ–‡å˜é‡å˜åŒ–ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if execution_result.metadata:
                context_changes = []
                for key, value in execution_result.metadata.items():
                    if key.startswith('context_'):
                        context_key = key[8:]  # ç§»é™¤ 'context_' å‰ç¼€
                        context_changes.append(f"{context_key}={value}")
                
                if context_changes:
                    print(f"{RED}{BOLD}ğŸ“ ä¸Šä¸‹æ–‡æ›´æ–°:{RESET}")
                    for change in context_changes[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå˜åŒ–
                        print(f"{RED}   + {change}{RESET}")
                    if len(context_changes) > 3:
                        print(f"{RED}   ... è¿˜æœ‰ {len(context_changes) - 3} ä¸ªå˜åŒ–{RESET}")
            
            # æ‰“å°æœ€è¿‘çš„æ‰§è¡Œå†å²ï¼ˆæœ€å2æ¡ï¼‰
            if new_state.execution_history:
                recent_history = new_state.execution_history[-2:]
                print(f"{RED}{BOLD}ğŸ“š æœ€è¿‘å†å²:{RESET}")
                for history_item in recent_history:
                    # é™åˆ¶å†å²æ¡ç›®é•¿åº¦
                    history_display = history_item[:80] + "..." if len(history_item) > 80 else history_item
                    print(f"{RED}   â€¢ {history_display}{RESET}")
            
            # å¦‚æœæœ‰é”™è¯¯è¯¦æƒ…ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            if not execution_result.success and execution_result.error_details:
                print(f"{RED}{BOLD}âš ï¸  é”™è¯¯è¯¦æƒ…:{RESET}")
                error_details = execution_result.error_details
                if len(error_details) > 100:
                    error_details = error_details[:100] + "..."
                print(f"{RED}   {error_details}{RESET}")
            
            print(f"{RED}{'=' * 50}{RESET}\n")
            
        except Exception as e:
            # å¦‚æœæ‰“å°å¤±è´¥ï¼Œè‡³å°‘è®°å½•åˆ°æ—¥å¿—
            logger.error(f"çº¢è‰²çŠ¶æ€æ‰“å°å¤±è´¥: {e}")
            # ç®€å•çš„å¤‡ç”¨æ‰“å°
            status = "æˆåŠŸ" if execution_result.success else "å¤±è´¥"
            goal_status = " [ç›®æ ‡å·²è¾¾æˆ]" if new_state.goal_achieved else ""
            print(f"\nğŸ”„ çŠ¶æ€æ›´æ–°: {status} | è¿­ä»£ {new_state.iteration_count}{goal_status}")
            print(f"æè¿°: {new_state.state[:100]}...\n")
    
    def _format_rules_for_context(self, rules) -> str:
        """
        æ ¼å¼åŒ–è§„åˆ™ä¿¡æ¯ä¾›çŠ¶æ€ç”Ÿæˆä¸Šä¸‹æ–‡ä½¿ç”¨
        
        Args:
            rules: è§„åˆ™åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–çš„è§„åˆ™æ¦‚è§ˆä¿¡æ¯
        """
        if not rules:
            return "æ— å¯ç”¨è§„åˆ™"
        
        # æŒ‰é˜¶æ®µåˆ†ç»„è§„åˆ™
        phases = {}
        for rule in rules:
            phase = rule.phase.value
            if phase not in phases:
                phases[phase] = []
            phases[phase].append(rule)
        
        formatted_lines = []
        for phase, phase_rules in phases.items():
            formatted_lines.append(f"ã€{phase}é˜¶æ®µã€‘")
            for rule in phase_rules[:3]:  # æ¯ä¸ªé˜¶æ®µæœ€å¤šæ˜¾ç¤º3ä¸ªè§„åˆ™
                formatted_lines.append(f"  - {rule.name}: {rule.condition[:50]}...")
            if len(phase_rules) > 3:
                formatted_lines.append(f"  - ... è¿˜æœ‰{len(phase_rules) - 3}ä¸ªè§„åˆ™")
        
        return '\n'.join(formatted_lines)
    
    def _analyze_loop_indicators_for_goal_evaluation(self, global_state: GlobalState) -> Dict[str, Any]:
        """
        åˆ†æå¾ªç¯æŒ‡æ ‡ä»¥è¾…åŠ©ç›®æ ‡è¯„ä¼°
        
        Args:
            global_state: å…¨å±€çŠ¶æ€
            
        Returns:
            Dict[str, Any]: å¾ªç¯åˆ†æç»“æœ
        """
        indicators = {
            'should_force_completion': False,
            'partial_completion_likely': False,
            'reason': '',
            'loop_risk_level': 'low'
        }
        
        try:
            # å¦‚æœæ˜¯WorkflowStateï¼Œä½¿ç”¨å…¶é«˜çº§å¾ªç¯æ£€æµ‹
            if isinstance(global_state, WorkflowState):
                # æ£€æŸ¥æ½œåœ¨å¾ªç¯
                if global_state.detect_potential_loop():
                    indicators['should_force_completion'] = True
                    indicators['reason'] = f"è¿ç»­æ‰§è¡Œç›¸åŒè§„åˆ™ {global_state.consecutive_same_rule_count} æ¬¡"
                    indicators['loop_risk_level'] = 'high'
                
                # æ£€æŸ¥çŠ¶æ€å¾ªç¯
                elif global_state.check_state_cycle():
                    indicators['should_force_completion'] = True
                    indicators['reason'] = "æ£€æµ‹åˆ°çŠ¶æ€å¾ªç¯æ¨¡å¼"
                    indicators['loop_risk_level'] = 'critical'
                
                # æ£€æŸ¥è§„åˆ™æ‰§è¡Œæƒ…å†µ
                elif len(global_state.executed_rules) >= 5:
                    indicators['partial_completion_likely'] = True
                    indicators['reason'] = f"å·²æ‰§è¡Œ {len(global_state.executed_rules)} ä¸ªè§„åˆ™ï¼Œå¯èƒ½å·²å……åˆ†æ¨è¿›ç›®æ ‡"
                    indicators['loop_risk_level'] = 'medium'
            
            # å¯¹æ‰€æœ‰çŠ¶æ€ç±»å‹è¿›è¡ŒåŸºç¡€æ£€æŸ¥
            if global_state.iteration_count > 15:
                indicators['should_force_completion'] = True
                indicators['reason'] = f"è¿­ä»£æ¬¡æ•°è¿‡å¤š ({global_state.iteration_count})"
                indicators['loop_risk_level'] = 'high'
            elif global_state.iteration_count > 10:
                indicators['partial_completion_likely'] = True
                indicators['reason'] = f"è¿­ä»£æ¬¡æ•°è¾ƒå¤š ({global_state.iteration_count})"
                indicators['loop_risk_level'] = 'medium'
            
            # æ£€æŸ¥æ‰§è¡Œå†å²é‡å¤æ¨¡å¼
            if len(global_state.execution_history) >= 6:
                recent_history = global_state.execution_history[-6:]
                # ç®€å•çš„é‡å¤æ£€æµ‹
                if len(set(recent_history)) <= 3:  # æœ€è¿‘6æ¡å†å²ä¸­åªæœ‰3ç§ä¸åŒçš„æ¨¡å¼
                    indicators['partial_completion_likely'] = True
                    indicators['reason'] = "æ£€æµ‹åˆ°æ‰§è¡Œå†å²é‡å¤æ¨¡å¼"
                    indicators['loop_risk_level'] = 'medium'
            
            return indicators
            
        except Exception as e:
            logger.error(f"å¾ªç¯æŒ‡æ ‡åˆ†æå¤±è´¥: {e}")
            return indicators
    
    def _get_adaptive_confidence_threshold(self, loop_indicators: Dict[str, Any]) -> float:
        """
        æ ¹æ®å¾ªç¯æŒ‡æ ‡è·å–è‡ªé€‚åº”çš„ç½®ä¿¡åº¦é˜ˆå€¼
        
        Args:
            loop_indicators: å¾ªç¯æŒ‡æ ‡
            
        Returns:
            float: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        # åŸºç¡€é˜ˆå€¼
        base_threshold = 0.8
        
        # æ ¹æ®å¾ªç¯é£é™©è°ƒæ•´é˜ˆå€¼
        risk_level = loop_indicators.get('loop_risk_level', 'low')
        
        if risk_level == 'critical':
            return 0.3  # ä¸¥é‡å¾ªç¯æ—¶ï¼Œå¾ˆä½çš„ç½®ä¿¡åº¦å°±è®¤ä¸ºè¾¾æˆ
        elif risk_level == 'high':
            return 0.5  # é«˜é£é™©æ—¶ï¼Œä¸­ç­‰ç½®ä¿¡åº¦å³å¯
        elif risk_level == 'medium':
            return 0.65  # ä¸­ç­‰é£é™©æ—¶ï¼Œé™ä½ä¸€äº›è¦æ±‚
        else:
            return base_threshold  # ä½é£é™©æ—¶ï¼Œä¿æŒåŸæœ‰æ ‡å‡†