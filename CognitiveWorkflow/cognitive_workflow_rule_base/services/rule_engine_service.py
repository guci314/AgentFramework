# -*- coding: utf-8 -*-
"""
è§„åˆ™å¼•æ“æœåŠ¡

æ ¸å¿ƒè§„åˆ™å¼•æ“æœåŠ¡ï¼Œä½œä¸ºæ•´ä¸ªäº§ç”Ÿå¼è§„åˆ™ç³»ç»Ÿçš„åè°ƒè€…ã€‚
è´Ÿè´£ç¼–æ’å„ä¸ªä¸“é—¨æœåŠ¡ï¼Œç®¡ç†å®Œæ•´çš„å·¥ä½œæµç¨‹ã€‚
"""

from typing import Dict, List, Any, Optional
import logging
from datetime import datetime
import uuid

from ..domain.entities import (
    ProductionRule, RuleSet, RuleExecution, GlobalState, DecisionResult
)
from ..domain.repositories import RuleRepository, StateRepository, ExecutionRepository
from ..domain.value_objects import (
    DecisionType, ExecutionStatus, WorkflowExecutionResult, ExecutionMetrics, RuleConstants
)
from .rule_generation_service import RuleGenerationService
# from .rule_matching_service import RuleMatchingService  # Removed - functionality integrated into RuleEngineService
from .rule_execution_service import RuleExecutionService
from .state_service import StateService
from .adaptive_replacement_service import AdaptiveReplacementService
from ..utils.concurrent_safe_id_generator import id_generator

logger = logging.getLogger(__name__)


class RuleEngineService:
    """æ ¸å¿ƒè§„åˆ™å¼•æ“æœåŠ¡ - æ•´ä¸ªäº§ç”Ÿå¼è§„åˆ™ç³»ç»Ÿçš„åè°ƒè€…"""
    
    def __init__(self,
                 rule_repository: RuleRepository,
                 state_repository: StateRepository,
                 execution_repository: ExecutionRepository,
                 rule_execution: RuleExecutionService,
                 rule_generation: RuleGenerationService,
                 state_service: StateService,
                 enable_auto_recovery: bool = True,
                 max_iterations: int = RuleConstants.MAX_ITERATIONS,
                 enable_adaptive_replacement: bool = True):
        """
        åˆå§‹åŒ–è§„åˆ™å¼•æ“æœåŠ¡
        
        Args:
            rule_repository: è§„åˆ™ä»“å‚¨
            state_repository: çŠ¶æ€ä»“å‚¨
            execution_repository: æ‰§è¡Œä»“å‚¨
            rule_execution: è§„åˆ™æ‰§è¡ŒæœåŠ¡
            rule_generation: è§„åˆ™ç”ŸæˆæœåŠ¡
            state_service: çŠ¶æ€æœåŠ¡
            enable_auto_recovery: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ¢å¤
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            enable_adaptive_replacement: æ˜¯å¦å¯ç”¨è‡ªé€‚åº”è§„åˆ™æ›¿æ¢
        """
        self.rule_repository = rule_repository
        self.state_repository = state_repository
        self.execution_repository = execution_repository
        self.rule_execution = rule_execution
        self.rule_generation = rule_generation
        self.state_service = state_service
        self.enable_auto_recovery = enable_auto_recovery
        self.max_iterations = max_iterations
        self.enable_adaptive_replacement = enable_adaptive_replacement
        
        # åˆå§‹åŒ–è‡ªé€‚åº”æ›¿æ¢æœåŠ¡
        if enable_adaptive_replacement:
            self.adaptive_replacement = AdaptiveReplacementService(
                llm_service=rule_generation.llm_service,
                enable_effectiveness_tracking=True  # å¯ç”¨Phase 2å¢å¼ºåŠŸèƒ½
            )
        else:
            self.adaptive_replacement = None
        
        # è¿è¡Œæ—¶çŠ¶æ€
        self._current_rule_set: Optional[RuleSet] = None
        self._workflow_id: Optional[str] = None
        
    def execute_workflow(self, goal: str, agent_registry: Any) -> WorkflowExecutionResult:
        """
        æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹
        
        Args:
            goal: å·¥ä½œæµç›®æ ‡
            agent_registry: æ™ºèƒ½ä½“æ³¨å†Œè¡¨
            
        Returns:
            WorkflowExecutionResult: å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        # ğŸ”‘ åˆå§‹åŒ–å·¥ä½œæµ - ä½¿ç”¨å¹¶å‘å®‰å…¨çš„IDç”Ÿæˆå™¨
        workflow_id = id_generator.generate_workflow_id(goal)
        self._workflow_id = workflow_id
        logger.info(f"ç”Ÿæˆå¹¶å‘å®‰å…¨çš„å·¥ä½œæµID: {workflow_id}")
        self._current_agent_registry = agent_registry  # è®¾ç½®å½“å‰æ™ºèƒ½ä½“æ³¨å†Œè¡¨ä¾›å†³ç­–ä½¿ç”¨
        self.rule_generation._current_agent_registry = agent_registry  # ä¸ºRuleGenerationServiceè®¾ç½®æ™ºèƒ½ä½“æ³¨å†Œè¡¨
        
        start_time = datetime.now()
        logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {goal} (ID: {workflow_id})")
        
        try:
            # 1. ç”Ÿæˆåˆå§‹è§„åˆ™é›†
            rule_set = self.rule_generation.generate_rule_set(goal, agent_registry)
            self._current_rule_set = rule_set
            self.rule_repository.save_rule_set(rule_set)
            
            # 2. åˆ›å»ºåˆå§‹çŠ¶æ€
            global_state = self.state_service.create_initial_state(goal, workflow_id)
            
            # 3. æ‰§è¡Œä¸»å¾ªç¯
            iteration_count = 0
            goal_achieved = False
            
            # å¾ªç¯æ£€æµ‹æœºåˆ¶
            decision_history = []  # å­˜å‚¨æœ€è¿‘çš„å†³ç­–å†å²
            MAX_LOOP_DETECTION = 5  # æ£€æµ‹å¾ªç¯çš„æœ€å¤§å†å²è®°å½•æ•°
            
            while iteration_count < self.max_iterations and not goal_achieved:
                iteration_count += 1
                logger.info(f"å¼€å§‹ç¬¬ {iteration_count} æ¬¡è¿­ä»£")
                
                # è¿›è¡Œå†³ç­–ï¼ˆé€‰æ‹©è§„åˆ™ã€æ·»åŠ è§„åˆ™ã€æˆ–åˆ¤æ–­ç›®æ ‡è¾¾æˆï¼‰
                decision = self.rule_generation.make_decision(global_state, rule_set)
                
                # å¾ªç¯æ£€æµ‹ï¼šè®°å½•å†³ç­–å†å²
                decision_signature = f"{decision.decision_type.value}_{getattr(decision, 'selected_rule', None) and decision.selected_rule.id}_{global_state.state[:50]}"
                decision_history.append(decision_signature)
                
                # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                if len(decision_history) > MAX_LOOP_DETECTION:
                    decision_history.pop(0)
                
                # æ£€æµ‹å¾ªç¯ï¼šå¦‚æœæœ€è¿‘çš„å†³ç­–é‡å¤å‡ºç°ï¼Œå¯èƒ½é™·å…¥å¾ªç¯
                if len(decision_history) >= 3:
                    recent_decisions = decision_history[-3:]
                    if len(set(recent_decisions)) == 1:  # æœ€è¿‘3æ¬¡å†³ç­–å®Œå…¨ç›¸åŒ
                        logger.warning(f"æ£€æµ‹åˆ°å†³ç­–å¾ªç¯: {recent_decisions[0]}")
                        logger.warning("å¼ºåˆ¶ç»ˆæ­¢å¾ªç¯ï¼Œæ ‡è®°ç›®æ ‡å¤±è´¥")
                        break
                
                # å¤„ç†å†³ç­–ç»“æœ
                if decision.decision_type == DecisionType.EXECUTE_SELECTED_RULE:
                    # æ‰§è¡Œé€‰ä¸­çš„è§„åˆ™
                    rule_execution = self.rule_execution.execute_rule(
                        decision.selected_rule, global_state
                    )
                    
                    # æ›´æ–°çŠ¶æ€ï¼ˆåŒ…å«ç›®æ ‡è¾¾æˆæ£€æŸ¥å’Œè§„åˆ™é›†ä¸Šä¸‹æ–‡ï¼‰
                    global_state = self.state_service.update_state(
                        rule_execution.result, global_state, goal, rule_set
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é”™è¯¯æ¢å¤
                    if not rule_execution.is_successful() and self.enable_auto_recovery:
                        recovery_rules = self.handle_rule_failure(rule_execution, global_state)
                        if recovery_rules:
                            # ä½¿ç”¨è‡ªé€‚åº”æ›¿æ¢ä»£æ›¿ç®€å•extend
                            optimized_rules = self._apply_adaptive_replacement(
                                rule_set.rules, recovery_rules, global_state, {
                                    'goal': goal,
                                    'iteration_count': iteration_count,
                                    'context_type': 'error_recovery',
                                    'failed_rule_id': rule_execution.rule_id
                                }
                            )
                            rule_set.rules = optimized_rules
                            self.rule_repository.save_rule_set(rule_set)
                            logger.info(f"é”™è¯¯æ¢å¤å®Œæˆ: è§„åˆ™æ•°é‡ {len(rule_set.rules)}")
                
                elif decision.decision_type == DecisionType.ADD_RULE:
                    # ä½¿ç”¨å†³ç­–ä¸­ç”Ÿæˆçš„æ–°è§„åˆ™
                    if decision.new_rules:
                        # ä½¿ç”¨è‡ªé€‚åº”æ›¿æ¢ä»£æ›¿ç®€å•extend
                        optimized_rules = self._apply_adaptive_replacement(
                            rule_set.rules, decision.new_rules, global_state, {
                                'goal': goal,
                                'iteration_count': iteration_count,
                                'context_type': 'add_new_rules'
                            }
                        )
                        rule_set.rules = optimized_rules
                        self.rule_repository.save_rule_set(rule_set)
                        logger.info(f"æ™ºèƒ½æ·»åŠ è§„åˆ™å®Œæˆ: è§„åˆ™æ•°é‡ {len(rule_set.rules)}")
                    else:
                        logger.warning("ADD_RULE å†³ç­–ä¸­æ²¡æœ‰æ–°è§„åˆ™")
                
                elif decision.decision_type == DecisionType.GOAL_ACHIEVED:
                    goal_achieved = True
                    global_state.goal_achieved = True
                    self.state_service.save_state(global_state)
                    logger.info("ç›®æ ‡å·²è¾¾æˆï¼Œå·¥ä½œæµå®Œæˆ")
                    break
                    
                elif decision.decision_type == DecisionType.GOAL_FAILED:
                    logger.warning("ç›®æ ‡æ‰§è¡Œå¤±è´¥ï¼Œå°è¯•ç­–ç•¥è°ƒæ•´")
                    strategy_rules = self.rule_generation.generate_strategy_adjustment_rules({
                        'goal': goal,
                        'current_state': global_state.state,
                        'execution_history': global_state.execution_history,
                        'iteration_count': iteration_count
                    })
                    if strategy_rules:
                        # ä½¿ç”¨è‡ªé€‚åº”æ›¿æ¢ä»£æ›¿ç®€å•extend
                        optimized_rules = self._apply_adaptive_replacement(
                            rule_set.rules, strategy_rules, global_state, {
                                'goal': goal,
                                'iteration_count': iteration_count,
                                'context_type': 'strategy_adjustment'
                            }
                        )
                        rule_set.rules = optimized_rules
                        self.rule_repository.save_rule_set(rule_set)
                        logger.info(f"ç­–ç•¥è°ƒæ•´å®Œæˆ: è§„åˆ™æ•°é‡ {len(rule_set.rules)}")
                
                # æ£€æŸ¥å…¨å±€çŠ¶æ€ä¸­çš„ç›®æ ‡è¾¾æˆçŠ¶æ€ï¼ˆæ¯æ¬¡è§„åˆ™æ‰§è¡ŒåçŠ¶æ€æ›´æ–°æ—¶å·²åŒ…å«ç›®æ ‡éªŒè¯ï¼‰
                if global_state.goal_achieved:
                    goal_achieved = True
                    logger.info("ç›®æ ‡å·²è¾¾æˆï¼ˆä»å…¨å±€çŠ¶æ€ä¸­æ£€æµ‹åˆ°ï¼‰")
                    break
            
            # 4. ç”Ÿæˆæ‰§è¡Œç»“æœ
            end_time = datetime.now()
            execution_metrics = self._calculate_execution_metrics(workflow_id)
            
            # ç¡®å®šæœ€ç»ˆçŠ¶æ€
            final_message = ""
            if goal_achieved:
                final_message = f"å·¥ä½œæµæˆåŠŸå®Œæˆï¼Œç›®æ ‡å·²è¾¾æˆ"
            elif iteration_count >= self.max_iterations:
                final_message = f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({self.max_iterations})ï¼Œå·¥ä½œæµç»ˆæ­¢"
            else:
                final_message = "å·¥ä½œæµå¼‚å¸¸ç»ˆæ­¢"
            
            workflow_result = WorkflowExecutionResult(
                goal=goal,
                is_successful=goal_achieved,
                final_state=global_state.state,
                total_iterations=iteration_count,
                execution_metrics=execution_metrics,
                final_message=final_message,
                completion_timestamp=end_time
            )
            
            logger.info(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {final_message}")
            
            # ğŸ”‘ é‡Šæ”¾å·¥ä½œæµIDï¼ˆå¹¶å‘å®‰å…¨ï¼‰
            try:
                id_generator.release_workflow_id(workflow_id)
                logger.debug(f"å·²é‡Šæ”¾å·¥ä½œæµID: {workflow_id}")
            except Exception as e:
                logger.warning(f"é‡Šæ”¾å·¥ä½œæµIDå¤±è´¥: {e}")
            
            return workflow_result
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            
            # åˆ›å»ºå¤±è´¥ç»“æœ
            end_time = datetime.now()
            execution_metrics = ExecutionMetrics(
                total_rules_executed=0,
                successful_executions=0,
                failed_executions=1,
                average_execution_time=0.0,
                total_execution_time=(end_time - start_time).total_seconds(),
                rule_match_accuracy=0.0
            )
            
            return WorkflowExecutionResult(
                goal=goal,
                is_successful=False,
                final_state=f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}",
                total_iterations=0,
                execution_metrics=execution_metrics,
                final_message=f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                completion_timestamp=end_time
            )
    
    
    def handle_rule_failure(self, 
                          rule_execution: RuleExecution, 
                          global_state: GlobalState) -> List[ProductionRule]:
        """
        å¤„ç†è§„åˆ™æ‰§è¡Œå¤±è´¥ï¼Œç”Ÿæˆæ¢å¤è§„åˆ™
        
        Args:
            rule_execution: å¤±è´¥çš„è§„åˆ™æ‰§è¡Œ
            global_state: å…¨å±€çŠ¶æ€
            
        Returns:
            List[ProductionRule]: æ¢å¤è§„åˆ™åˆ—è¡¨
        """
        try:
            logger.info(f"å¤„ç†è§„åˆ™æ‰§è¡Œå¤±è´¥: {rule_execution.rule_id}")
            
            # æ„å»ºå¤±è´¥ä¸Šä¸‹æ–‡
            failure_context = {
                'rule_id': rule_execution.rule_id,
                'failure_reason': rule_execution.failure_reason,
                'execution_context': rule_execution.execution_context,
                'global_state': global_state.state,
                'error_message': rule_execution.failure_reason or 'Unknown error'
            }
            
            # ç”Ÿæˆæ¢å¤è§„åˆ™
            recovery_rules = self.rule_generation.generate_recovery_rules(failure_context)
            
            logger.info(f"ç”Ÿæˆäº† {len(recovery_rules)} ä¸ªæ¢å¤è§„åˆ™")
            return recovery_rules
            
        except Exception as e:
            logger.error(f"è§„åˆ™å¤±è´¥å¤„ç†å¼‚å¸¸: {e}")
            return []
    
    # evaluate_goal_achievementæ–¹æ³•å·²ç§»é™¤ - ç›´æ¥ä½¿ç”¨global_state.goal_achievedå­—æ®µ
    # ç†ç”±ï¼šæ¯æ¬¡è§„åˆ™æ‰§è¡ŒåçŠ¶æ€æ›´æ–°å·²åŒ…å«ç›®æ ‡éªŒè¯ï¼Œæ— éœ€é¢å¤–æ£€æŸ¥
    
    def manage_rule_lifecycle(self, rule_set: RuleSet) -> None:
        """
        ç®¡ç†è§„åˆ™ç”Ÿå‘½å‘¨æœŸ
        
        Args:
            rule_set: è§„åˆ™é›†
        """
        try:
            # éªŒè¯è§„åˆ™é›†
            issues = self.rule_generation.validate_rule_set(rule_set)
            if issues:
                logger.warning(f"è§„åˆ™é›†å­˜åœ¨é—®é¢˜: {', '.join(issues[:3])}")
            
            # ä¼˜åŒ–è§„åˆ™ä¼˜å…ˆçº§
            if len(rule_set.rules) > 5:
                optimized_rules = self.rule_generation.optimize_rule_priorities(rule_set.rules)
                rule_set.rules = optimized_rules
                self.rule_repository.save_rule_set(rule_set)
                logger.info("è§„åˆ™ä¼˜å…ˆçº§å·²ä¼˜åŒ–")
            
            # æ¸…ç†è¿‡æœŸæˆ–æ— æ•ˆè§„åˆ™
            self._cleanup_invalid_rules(rule_set)
            
        except Exception as e:
            logger.error(f"è§„åˆ™ç”Ÿå‘½å‘¨æœŸç®¡ç†å¤±è´¥: {e}")
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµçŠ¶æ€
        
        Returns:
            Dict[str, Any]: å·¥ä½œæµçŠ¶æ€ä¿¡æ¯
        """
        try:
            current_state = self.state_service.get_current_state()
            
            status = {
                'workflow_id': self._workflow_id,
                'current_state': current_state.state if current_state else 'No active workflow',
                'iteration_count': current_state.iteration_count if current_state else 0,
                'goal_achieved': current_state.goal_achieved if current_state else False,
                'rule_count': len(self._current_rule_set.rules) if self._current_rule_set else 0
                # 'timestamp': datetime.now().isoformat()  # Removed for LLM caching
            }
            
            return status
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {e}")
            return {
                'workflow_id': self._workflow_id,
                'current_state': 'Status unavailable',
                'error': str(e)
            }
    
    def pause_workflow(self) -> bool:
        """
        æš‚åœå·¥ä½œæµ
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæš‚åœ
        """
        try:
            # ä¿å­˜å½“å‰çŠ¶æ€
            current_state = self.state_service.get_current_state()
            if current_state:
                current_state.context_variables['workflow_paused'] = True
                self.state_service.save_state(current_state)
            
            logger.info("å·¥ä½œæµå·²æš‚åœ")
            return True
            
        except Exception as e:
            logger.error(f"æš‚åœå·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    def resume_workflow(self) -> bool:
        """
        æ¢å¤å·¥ä½œæµ
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¢å¤
        """
        try:
            # æ¢å¤çŠ¶æ€
            current_state = self.state_service.get_current_state()
            if current_state:
                current_state.context_variables.pop('workflow_paused', None)
                self.state_service.save_state(current_state)
            
            logger.info("å·¥ä½œæµå·²æ¢å¤")
            return True
            
        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    def _generate_new_rules_for_situation(self, 
                                        global_state: GlobalState, 
                                        goal: str) -> List[ProductionRule]:
        """
        ä¸ºå½“å‰æƒ…å†µç”Ÿæˆæ–°è§„åˆ™
        
        Args:
            global_state: å…¨å±€çŠ¶æ€
            goal: ç›®æ ‡
            
        Returns:
            List[ProductionRule]: æ–°ç”Ÿæˆçš„è§„åˆ™åˆ—è¡¨
        """
        try:
            # åˆ†æå½“å‰æƒ…å†µ
            situation_context = {
                'goal': goal,
                'current_state': global_state.state,
                'iteration_count': global_state.iteration_count,
                'context_variables': global_state.context_variables,
                'recent_history': global_state.execution_history[-5:] if global_state.execution_history else []
            }
            
            # åˆ¤æ–­éœ€è¦ä»€ä¹ˆç±»å‹çš„è§„åˆ™
            if global_state.iteration_count > 10:
                # å¦‚æœè¿­ä»£æ¬¡æ•°è¾ƒå¤šï¼Œå¯èƒ½éœ€è¦ç­–ç•¥è°ƒæ•´è§„åˆ™
                return self.rule_generation.generate_strategy_adjustment_rules(situation_context)
            else:
                # å¦åˆ™ç”ŸæˆæŠ€æœ¯ä¿®å¤è§„åˆ™
                return self.rule_generation.generate_recovery_rules(situation_context)
                
        except Exception as e:
            logger.error(f"æ–°è§„åˆ™ç”Ÿæˆå¤±è´¥: {e}")
            return []
    
    def _calculate_execution_metrics(self, workflow_id: str) -> ExecutionMetrics:
        """
        è®¡ç®—æ‰§è¡ŒæŒ‡æ ‡
        
        Args:
            workflow_id: å·¥ä½œæµID
            
        Returns:
            ExecutionMetrics: æ‰§è¡ŒæŒ‡æ ‡
        """
        try:
            # è·å–æ‰€æœ‰ç›¸å…³çš„æ‰§è¡Œè®°å½•
            stats = self.rule_execution.get_execution_statistics()
            
            return ExecutionMetrics(
                total_rules_executed=stats.get('total_executions', 0),
                successful_executions=stats.get('successful_executions', 0),
                failed_executions=stats.get('failed_executions', 0),
                average_execution_time=stats.get('average_execution_time', 0.0),
                total_execution_time=stats.get('total_execution_time', 0.0),
                rule_match_accuracy=stats.get('rule_match_accuracy', 0.0)
            )
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒæŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return ExecutionMetrics(
                total_rules_executed=0,
                successful_executions=0,
                failed_executions=0,
                average_execution_time=0.0,
                total_execution_time=0.0,
                rule_match_accuracy=0.0
            )
    
    def _cleanup_invalid_rules(self, rule_set: RuleSet) -> None:
        """
        æ¸…ç†æ— æ•ˆè§„åˆ™
        
        Args:
            rule_set: è§„åˆ™é›†
        """
        try:
            original_count = len(rule_set.rules)
            
            # ç§»é™¤ç©ºçš„æˆ–æ— æ•ˆçš„è§„åˆ™
            valid_rules = []
            for rule in rule_set.rules:
                if (rule.condition and rule.condition.strip() and 
                    rule.action and rule.action.strip() and
                    rule.agent_name and rule.agent_name.strip()):
                    valid_rules.append(rule)
                else:
                    logger.warning(f"ç§»é™¤æ— æ•ˆè§„åˆ™: {rule.id}")
            
            rule_set.rules = valid_rules
            
            removed_count = original_count - len(valid_rules)
            if removed_count > 0:
                logger.info(f"æ¸…ç†äº† {removed_count} ä¸ªæ— æ•ˆè§„åˆ™")
                self.rule_repository.save_rule_set(rule_set)
                
        except Exception as e:
            logger.error(f"è§„åˆ™æ¸…ç†å¤±è´¥: {e}")
    
    def get_rule_set(self) -> Optional[RuleSet]:
        """
        è·å–å½“å‰è§„åˆ™é›†
        
        Returns:
            Optional[RuleSet]: å½“å‰è§„åˆ™é›†
        """
        return self._current_rule_set
    
    def add_rule_to_current_set(self, rule: ProductionRule) -> bool:
        """
        å‘å½“å‰è§„åˆ™é›†æ·»åŠ è§„åˆ™
        
        Args:
            rule: è¦æ·»åŠ çš„è§„åˆ™
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            if self._current_rule_set:
                self._current_rule_set.add_rule(rule)
                self.rule_repository.save_rule_set(self._current_rule_set)
                logger.info(f"è§„åˆ™å·²æ·»åŠ : {rule.name}")
                return True
            else:
                logger.warning("æ²¡æœ‰æ´»è·ƒçš„è§„åˆ™é›†ï¼Œæ— æ³•æ·»åŠ è§„åˆ™")
                return False
                
        except Exception as e:
            logger.error(f"æ·»åŠ è§„åˆ™å¤±è´¥: {e}")
            return False
    
    
    def _should_generate_new_rule(self, global_state: GlobalState, rule_set: RuleSet) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆæ–°è§„åˆ™
        
        Args:
            global_state: å½“å‰å…¨å±€çŠ¶æ€
            rule_set: è§„åˆ™é›†
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥ç”Ÿæˆæ–°è§„åˆ™
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å°è¯•ç”Ÿæˆè¿‡å¤ªå¤šæ¬¡æ–°è§„åˆ™
            generation_count = global_state.context_variables.get('new_rule_generation_count', 0)
            if generation_count >= 3:  # æœ€å¤šç”Ÿæˆ3æ¬¡æ–°è§„åˆ™
                logger.warning("å·²è¾¾åˆ°æ–°è§„åˆ™ç”Ÿæˆæ¬¡æ•°ä¸Šé™")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆé€‚çš„æ™ºèƒ½ä½“èƒ½åŠ›æ¥å¤„ç†å½“å‰æƒ…å†µ
            current_situation = f"{global_state.state} | ç›®æ ‡: {rule_set.goal}"
            
            # ä½¿ç”¨è¯­è¨€æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦æ–°è§„åˆ™
            prompt = f"""
è¯·åˆ¤æ–­å½“å‰æƒ…å†µæ˜¯å¦éœ€è¦ç”Ÿæˆæ–°çš„äº§ç”Ÿå¼è§„åˆ™ï¼š

å½“å‰çŠ¶æ€: {global_state.state}
ç›®æ ‡: {rule_set.goal}
ç°æœ‰è§„åˆ™æ•°é‡: {len(rule_set.rules)}
æ‰§è¡Œå†å²: {chr(10).join(global_state.execution_history[-3:]) if global_state.execution_history else 'æ— '}

åˆ†æè¦ç‚¹ï¼š
1. ç°æœ‰è§„åˆ™æ˜¯å¦èƒ½è¦†ç›–å½“å‰æƒ…å†µ
2. æ˜¯å¦é‡åˆ°äº†æ–°çš„é—®é¢˜éœ€è¦è§£å†³
3. æ˜¯å¦éœ€è¦æ–°çš„æ‰§è¡Œç­–ç•¥

å¦‚æœç¡®å®éœ€è¦æ–°è§„åˆ™æ¥æ¨è¿›ç›®æ ‡å®Œæˆï¼Œè¿”å›"æ˜¯"ï¼Œå¦åˆ™è¿”å›"å¦"ã€‚
"""
            
            response = self.rule_generation.llm_service.generate_natural_language_response(prompt)
            should_generate = "æ˜¯" in response.strip()
            
            if should_generate:
                # æ›´æ–°ç”Ÿæˆè®¡æ•°
                global_state.context_variables['new_rule_generation_count'] = generation_count + 1
                logger.info("åˆ¤æ–­éœ€è¦ç”Ÿæˆæ–°è§„åˆ™")
            
            return should_generate
            
        except Exception as e:
            logger.error(f"æ–°è§„åˆ™ç”Ÿæˆåˆ¤æ–­å¤±è´¥: {e}")
            return False
    
    # å†³ç­–ç›¸å…³æ–¹æ³•å·²è¿ç§»åˆ°RuleGenerationService
    
    # å†³ç­–ç›¸å…³æ–¹æ³•å·²è¿ç§»åˆ°RuleGenerationService 
    # - _format_rules_for_decision
    # - _get_available_capabilities  
    # - _parse_llm_decision
    # - _create_rule_from_llm_data
    # - _print_decision_in_red
    
    def _apply_adaptive_replacement(self,
                                  existing_rules: List[ProductionRule],
                                  new_rules: List[ProductionRule],
                                  global_state: GlobalState,
                                  context: Dict[str, Any]) -> List[ProductionRule]:
        """
        åº”ç”¨è‡ªé€‚åº”è§„åˆ™æ›¿æ¢ç­–ç•¥
        
        Args:
            existing_rules: ç°æœ‰è§„åˆ™åˆ—è¡¨
            new_rules: æ–°è§„åˆ™åˆ—è¡¨
            global_state: å½“å‰å…¨å±€çŠ¶æ€
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            List[ProductionRule]: ä¼˜åŒ–åçš„è§„åˆ™åˆ—è¡¨
        """
        try:
            # å¦‚æœæœªå¯ç”¨è‡ªé€‚åº”æ›¿æ¢ï¼Œä½¿ç”¨ä¿å®ˆåˆå¹¶
            if not self.enable_adaptive_replacement or not self.adaptive_replacement:
                logger.debug("è‡ªé€‚åº”æ›¿æ¢æœªå¯ç”¨ï¼Œä½¿ç”¨ä¿å®ˆåˆå¹¶")
                return self._conservative_rule_merge(existing_rules, new_rules)
            
            # ä½¿ç”¨è‡ªé€‚åº”æ›¿æ¢æœåŠ¡è¿›è¡Œæ™ºèƒ½æ›¿æ¢
            logger.info(f"åº”ç”¨è‡ªé€‚åº”æ›¿æ¢: {context.get('context_type', 'unknown')} - "
                       f"ç°æœ‰è§„åˆ™{len(existing_rules)}ä¸ª, æ–°è§„åˆ™{len(new_rules)}ä¸ª")
            
            optimized_rules = self.adaptive_replacement.execute_adaptive_replacement(
                existing_rules=existing_rules,
                new_rules=new_rules,
                global_state=global_state,
                context=context
            )
            
            logger.info(f"è‡ªé€‚åº”æ›¿æ¢å®Œæˆ: {len(existing_rules)} -> {len(optimized_rules)} ä¸ªè§„åˆ™")
            return optimized_rules
            
        except Exception as e:
            logger.error(f"è‡ªé€‚åº”æ›¿æ¢å¤±è´¥: {e}ï¼Œä½¿ç”¨ä¿å®ˆåˆå¹¶")
            return self._conservative_rule_merge(existing_rules, new_rules)
    
    def _conservative_rule_merge(self, 
                               existing_rules: List[ProductionRule],
                               new_rules: List[ProductionRule]) -> List[ProductionRule]:
        """
        ä¿å®ˆçš„è§„åˆ™åˆå¹¶ç­–ç•¥ï¼ˆè‡ªé€‚åº”æ›¿æ¢å¤±è´¥æ—¶çš„åå¤‡æ–¹æ¡ˆï¼‰
        
        Args:
            existing_rules: ç°æœ‰è§„åˆ™
            new_rules: æ–°è§„åˆ™
            
        Returns:
            List[ProductionRule]: åˆå¹¶åçš„è§„åˆ™åˆ—è¡¨
        """
        # ç®€å•åˆå¹¶ï¼Œé¿å…é‡å¤ID
        all_rules = existing_rules + new_rules
        seen_ids = set()
        unique_rules = []
        
        for rule in all_rules:
            if rule.id not in seen_ids:
                unique_rules.append(rule)
                seen_ids.add(rule.id)
        
        # åº”ç”¨åŸºæœ¬çš„æ•°é‡é™åˆ¶
        max_total_rules = 15  # ç¡¬æ€§é™åˆ¶é¿å…è§„åˆ™è¿‡å¤š
        if len(unique_rules) > max_total_rules:
            # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä¿ç•™æœ€é«˜ä¼˜å…ˆçº§çš„è§„åˆ™
            unique_rules.sort(key=lambda r: r.priority, reverse=True)
            unique_rules = unique_rules[:max_total_rules]
            logger.warning(f"è§„åˆ™æ•°é‡è¶…é™ï¼Œä¿ç•™å‰{max_total_rules}ä¸ªé«˜ä¼˜å…ˆçº§è§„åˆ™")
        
        return unique_rules