# %%
from agent_base import Result, reduce_memory_decorator_compress
from pythonTask import StatefulExecutor, Agent, llm_deepseek
from langchain_core.language_models import BaseChatModel
from typing import Dict, List, Any, Optional, Tuple, NamedTuple
import json
import re
import random
from datetime import datetime as dt
from collections import deque, OrderedDict
import copy
from abc import ABC, abstractmethod
import threading
import time
import asyncio
from typing import Union, List
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from prompts import team_manager_system_message_share_state, team_manager_system_message_no_share_state
import logging
import sys
from enum import Enum
from string import Template

# å¯¼å…¥å¤šæ–¹æ¡ˆå“åº”è§£æå™¨
try:
    from response_parser_v2 import (
        ParserFactory, ParserMethod, ParserConfig,
        MultiMethodResponseParser, ParsedStateInfo, ResponseQuality
    )
    RESPONSE_PARSER_AVAILABLE = True
except ImportError as e:
    RESPONSE_PARSER_AVAILABLE = False
    logging.warning(f"å¤šæ–¹æ¡ˆå“åº”è§£æå™¨ä¸å¯ç”¨: {e}")

# é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å° - åªåœ¨æ²¡æœ‰é…ç½®è¿‡æ—¶æ‰é…ç½®
if not logging.getLogger().handlers:
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler()]
    )

logger = logging.getLogger(__name__)
# åªè®¾ç½®å½“å‰æ¨¡å—çš„æ—¥å¿—çº§åˆ«ï¼Œä¸å½±å“å…¨å±€é…ç½®
logger.setLevel(logging.DEBUG)

# å¯¼å…¥é…ç½®ç³»ç»Ÿ
try:
    from config_system import (
        get_config, initialize_config, ApplicationConfig,
        StateHistoryConfig, AIUpdaterConfig, MonitoringConfig, OptimizationConfig
    )
    CONFIG_SYSTEM_AVAILABLE = True
except ImportError:
    CONFIG_SYSTEM_AVAILABLE = False
    logger.warning("é…ç½®ç³»ç»Ÿä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")

# å¯¼å…¥æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
try:
    from performance_monitor import (
        get_performance_monitor, configure_performance_monitoring,
        PerformanceMonitor, monitor_performance
    )
    PERFORMANCE_MONITOR_AVAILABLE = True
except ImportError:
    PERFORMANCE_MONITOR_AVAILABLE = False
    logger.warning("æ€§èƒ½ç›‘æ§ç³»ç»Ÿä¸å¯ç”¨ï¼Œå°†è·³è¿‡æ€§èƒ½ç›‘æ§åŠŸèƒ½")

class StateHistoryEntry(NamedTuple):
    """çŠ¶æ€å†å²æ¡ç›®"""
    timestamp: dt
    state_snapshot: str
    source: Optional[str] = None

class PromptScenario(Enum):
    """æç¤ºæ¨¡æ¿åœºæ™¯æšä¸¾"""
    INITIALIZATION = "initialization"          # åˆå§‹åŒ–åœºæ™¯
    SUCCESS_COMPLETION = "success_completion"  # æˆåŠŸå®Œæˆåœºæ™¯
    ERROR_HANDLING = "error_handling"          # é”™è¯¯å¤„ç†åœºæ™¯
    STATE_TRANSITION = "state_transition"      # çŠ¶æ€è½¬æ¢åœºæ™¯
    PROGRESS_UPDATE = "progress_update"        # è¿›åº¦æ›´æ–°åœºæ™¯
    SUMMARY = "summary"                        # æ€»ç»“åœºæ™¯
    CUSTOM = "custom"                          # è‡ªå®šä¹‰åœºæ™¯

class PromptTemplate:
    """æç¤ºæ¨¡æ¿ç±»"""
    
    def __init__(self, 
                 scenario: PromptScenario,
                 system_message: str,
                 user_template: str,
                 version: str = "1.0",
                 description: str = ""):
        """
        åˆå§‹åŒ–æç¤ºæ¨¡æ¿
        
        Args:
            scenario: æ¨¡æ¿ä½¿ç”¨åœºæ™¯
            system_message: ç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿
            user_template: ç”¨æˆ·æ¶ˆæ¯æ¨¡æ¿ï¼ˆæ”¯æŒå˜é‡æ›¿æ¢ï¼‰
            version: æ¨¡æ¿ç‰ˆæœ¬
            description: æ¨¡æ¿æè¿°
        """
        self.scenario = scenario
        self.system_message = system_message
        self.user_template = Template(user_template)
        self.version = version
        self.description = description
        self.created_at = dt.now()
        
    def render(self, variables: Dict[str, Any]) -> Tuple[str, str]:
        """
        æ¸²æŸ“æ¨¡æ¿
        
        Args:
            variables: æ¨¡æ¿å˜é‡å­—å…¸
            
        Returns:
            (system_message, user_message) å…ƒç»„
        """
        try:
            # å¤„ç†ç¼ºå¤±å˜é‡çš„é»˜è®¤å€¼
            safe_variables = self._prepare_safe_variables(variables)
            user_message = self.user_template.safe_substitute(safe_variables)
            return self.system_message, user_message
        except Exception as e:
            raise ValueError(f"æ¨¡æ¿æ¸²æŸ“å¤±è´¥: {e}")
    
    def _prepare_safe_variables(self, variables: Dict[str, Any]) -> Dict[str, str]:
        """
        å‡†å¤‡å®‰å…¨çš„å˜é‡å­—å…¸ï¼Œä¸ºç¼ºå¤±å˜é‡æä¾›é»˜è®¤å€¼
        
        Args:
            variables: åŸå§‹å˜é‡å­—å…¸
            
        Returns:
            å®‰å…¨çš„å˜é‡å­—å…¸
        """
        safe_vars = {}
        for key, value in variables.items():
            if value is None:
                safe_vars[key] = "æœªæä¾›"
            elif isinstance(value, str):
                safe_vars[key] = value
            else:
                safe_vars[key] = str(value)
        
        # ä¸ºå¸¸ç”¨å˜é‡æä¾›é»˜è®¤å€¼
        defaults = {
            'current_state': 'æ— å½“å‰çŠ¶æ€',
            'step_description': 'æœªçŸ¥æ­¥éª¤',
            'step_status': 'æœªçŸ¥',
            'step_type': 'æœªçŸ¥ç±»å‹',
            'execution_success': 'æœªçŸ¥',
            'execution_output': 'æ— è¾“å‡º',
            'error_message': 'æ— é”™è¯¯ä¿¡æ¯',
            'previous_state': 'æ— å‰ç½®çŠ¶æ€',
            'workflow_progress': 'è¿›åº¦æœªçŸ¥'
        }
        
        for key, default_value in defaults.items():
            if key not in safe_vars:
                safe_vars[key] = default_value
                
        return safe_vars
    
    def get_required_variables(self) -> List[str]:
        """
        è·å–æ¨¡æ¿æ‰€éœ€çš„å˜é‡åˆ—è¡¨
        
        Returns:
            å˜é‡ååˆ—è¡¨
        """
        import re
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ¨¡æ¿ä¸­çš„å˜é‡
        pattern = r'\$\{([^}]+)\}|\$([A-Za-z_][A-Za-z0-9_]*)'
        matches = re.findall(pattern, self.user_template.template)
        variables = []
        for match in matches:
            var_name = match[0] if match[0] else match[1]
            if var_name and var_name not in variables:
                variables.append(var_name)
        return variables

class PromptTemplateManager:
    """æç¤ºæ¨¡æ¿ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡æ¿ç®¡ç†å™¨"""
        self._templates: Dict[PromptScenario, PromptTemplate] = {}
        self._logger = logging.getLogger(f"{__name__}.PromptTemplateManager")
        
        # åˆå§‹åŒ–é»˜è®¤æ¨¡æ¿
        self._initialize_default_templates()
        
        self._logger.info(f"æç¤ºæ¨¡æ¿ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½äº†{len(self._templates)}ä¸ªæ¨¡æ¿")
    
    def _initialize_default_templates(self):
        """åˆå§‹åŒ–é»˜è®¤æ¨¡æ¿"""
        
        # åˆå§‹åŒ–åœºæ™¯æ¨¡æ¿
        initialization_template = PromptTemplate(
            scenario=PromptScenario.INITIALIZATION,
            system_message="""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ä¸ºæ–°å¼€å§‹çš„å·¥ä½œæµç”Ÿæˆåˆå§‹çŠ¶æ€æè¿°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼ˆ1-2å¥è¯ï¼‰
2. é‡ç‚¹æè¿°å·¥ä½œæµçš„ç›®æ ‡å’Œåˆå§‹é˜¶æ®µ
3. ä½“ç°å·¥ä½œæµåˆšå¼€å§‹çš„çŠ¶æ€
4. ä½¿ç”¨ç§¯æçš„è¯­è°ƒè¡¨è¾¾å¼€å§‹çš„æ„å›¾""",
            user_template="""å·¥ä½œæµåˆå§‹åŒ–ä¿¡æ¯ï¼š

## å·¥ä½œæµç›®æ ‡
ä¸»è¦æŒ‡ä»¤ï¼š$main_instruction

## å½“å‰æƒ…å†µ
- å·¥ä½œæµçŠ¶æ€ï¼šåˆšå¼€å§‹
- åˆå§‹æ­¥éª¤ï¼š$step_description
- æ­¥éª¤ç±»å‹ï¼š$step_type

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„åˆå§‹çŠ¶æ€æè¿°ï¼ˆ1-2å¥è¯ï¼‰ï¼Œè¯´æ˜å·¥ä½œæµåˆšå¼€å§‹ï¼Œå‡†å¤‡æ‰§è¡Œä»€ä¹ˆä»»åŠ¡ã€‚""",
            version="1.0",
            description="ç”¨äºå·¥ä½œæµåˆå§‹åŒ–æ—¶çš„çŠ¶æ€æè¿°ç”Ÿæˆ"
        )
        
        # æˆåŠŸå®Œæˆåœºæ™¯æ¨¡æ¿
        success_template = PromptTemplate(
            scenario=PromptScenario.SUCCESS_COMPLETION,
            system_message="""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ä¸ºæˆåŠŸå®Œæˆçš„æ­¥éª¤ç”ŸæˆçŠ¶æ€æ›´æ–°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼ˆ1-3å¥è¯ï¼‰
2. é‡ç‚¹æè¿°å®Œæˆçš„æˆæœå’Œè¿›å±•
3. ä½“ç°è¿è´¯çš„çŠ¶æ€æ¼”è¿›
4. ä½¿ç”¨ç§¯æçš„è¯­è°ƒè¡¨è¾¾æˆåŠŸ""",
            user_template="""æ­¥éª¤æˆåŠŸå®Œæˆä¿¡æ¯ï¼š

## å½“å‰çŠ¶æ€
å½“å‰çŠ¶æ€ï¼š$current_state

## å®Œæˆçš„æ­¥éª¤
æ­¥éª¤æè¿°ï¼š$step_description
æ­¥éª¤ç±»å‹ï¼š$step_type
æ‰§è¡Œç»“æœï¼š$execution_output

## çŠ¶æ€å†å²
$state_history

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„çŠ¶æ€æè¿°ï¼ˆ1-3å¥è¯ï¼‰ï¼Œåæ˜ è¿™ä¸ªæ­¥éª¤çš„æˆåŠŸå®Œæˆå’Œå½“å‰å·¥ä½œæµçš„è¿›å±•ã€‚""",
            version="1.0",
            description="ç”¨äºæ­¥éª¤æˆåŠŸå®Œæˆæ—¶çš„çŠ¶æ€æè¿°ç”Ÿæˆ"
        )
        
        # é”™è¯¯å¤„ç†åœºæ™¯æ¨¡æ¿
        error_template = PromptTemplate(
            scenario=PromptScenario.ERROR_HANDLING,
            system_message="""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ä¸ºé‡åˆ°é”™è¯¯çš„æ­¥éª¤ç”ŸæˆçŠ¶æ€æ›´æ–°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼ˆ1-3å¥è¯ï¼‰
2. æ˜ç¡®æŒ‡å‡ºé‡åˆ°çš„é—®é¢˜ä½†ä¸è¿‡åˆ†å¼ºè°ƒå¤±è´¥
3. å¦‚æœå¯èƒ½ï¼Œæš—ç¤ºè§£å†³æ–¹å‘æˆ–ä¸‹ä¸€æ­¥è®¡åˆ’
4. ä¿æŒä¸“ä¸šå’Œå»ºè®¾æ€§çš„è¯­è°ƒ""",
            user_template="""æ­¥éª¤æ‰§è¡Œé‡åˆ°é”™è¯¯ï¼š

## å½“å‰çŠ¶æ€
å½“å‰çŠ¶æ€ï¼š$current_state

## é‡åˆ°é—®é¢˜çš„æ­¥éª¤
æ­¥éª¤æè¿°ï¼š$step_description
æ­¥éª¤ç±»å‹ï¼š$step_type
é”™è¯¯ä¿¡æ¯ï¼š$error_message
æ‰§è¡Œè¾“å‡ºï¼š$execution_output

## çŠ¶æ€å†å²
$state_history

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„çŠ¶æ€æè¿°ï¼ˆ1-3å¥è¯ï¼‰ï¼Œè¯´æ˜é‡åˆ°çš„é—®é¢˜å’Œå½“å‰çš„å·¥ä½œæµçŠ¶æ€ï¼Œé¿å…è¿‡åº¦å¼ºè°ƒå¤±è´¥ã€‚""",
            version="1.0",
            description="ç”¨äºæ­¥éª¤æ‰§è¡Œå¤±è´¥æ—¶çš„çŠ¶æ€æè¿°ç”Ÿæˆ"
        )
        
        # çŠ¶æ€è½¬æ¢åœºæ™¯æ¨¡æ¿
        transition_template = PromptTemplate(
            scenario=PromptScenario.STATE_TRANSITION,
            system_message="""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ä¸ºå¤æ‚çŠ¶æ€è½¬æ¢ç”Ÿæˆæè¿°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼ˆ2-3å¥è¯ï¼‰
2. æ¸…æ¥šåœ°è¡¨è¾¾ä»ä¸€ä¸ªé˜¶æ®µåˆ°å¦ä¸€ä¸ªé˜¶æ®µçš„è½¬æ¢
3. ä½“ç°å·¥ä½œæµçš„è¿ç»­æ€§å’Œè¿›å±•
4. çªå‡ºå…³é”®çš„è½¬æ¢èŠ‚ç‚¹""",
            user_template="""å·¥ä½œæµçŠ¶æ€è½¬æ¢ä¿¡æ¯ï¼š

## è½¬æ¢å‰çŠ¶æ€
å‰ä¸€çŠ¶æ€ï¼š$previous_state

## å½“å‰çŠ¶æ€
å½“å‰çŠ¶æ€ï¼š$current_state

## è½¬æ¢è§¦å‘æ­¥éª¤
æ­¥éª¤æè¿°ï¼š$step_description
æ­¥éª¤ç±»å‹ï¼š$step_type
æ‰§è¡Œç»“æœï¼š$execution_output

## å·¥ä½œæµè¿›å±•
æ•´ä½“è¿›åº¦ï¼š$workflow_progress

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„çŠ¶æ€æè¿°ï¼ˆ2-3å¥è¯ï¼‰ï¼Œæ¸…æ¥šåœ°è¡¨è¾¾è¿™æ¬¡çŠ¶æ€è½¬æ¢å’Œå·¥ä½œæµçš„è¿›å±•æƒ…å†µã€‚""",
            version="1.0",
            description="ç”¨äºå¤æ‚çŠ¶æ€è½¬æ¢æ—¶çš„çŠ¶æ€æè¿°ç”Ÿæˆ"
        )
        
        # è¿›åº¦æ›´æ–°åœºæ™¯æ¨¡æ¿
        progress_template = PromptTemplate(
            scenario=PromptScenario.PROGRESS_UPDATE,
            system_message="""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ç”Ÿæˆä¸­é—´è¿›åº¦çš„çŠ¶æ€æ›´æ–°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼ˆ1-2å¥è¯ï¼‰
2. é‡ç‚¹ä½“ç°å½“å‰çš„è¿›å±•æƒ…å†µ
3. ä¿æŒä¸ä¹‹å‰çŠ¶æ€çš„è¿è´¯æ€§
4. ä½“ç°ç§¯æçš„æ¨è¿›æ€åº¦""",
            user_template="""å·¥ä½œæµè¿›åº¦æ›´æ–°ï¼š

## å½“å‰çŠ¶æ€
å½“å‰çŠ¶æ€ï¼š$current_state

## æœ€æ–°æ­¥éª¤
æ­¥éª¤æè¿°ï¼š$step_description
æ­¥éª¤ç±»å‹ï¼š$step_type
æ‰§è¡Œæƒ…å†µï¼š$execution_success

## æ•´ä½“è¿›å±•
å·¥ä½œæµè¿›åº¦ï¼š$workflow_progress

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„çŠ¶æ€æè¿°ï¼ˆ1-2å¥è¯ï¼‰ï¼Œåæ˜ å½“å‰çš„è¿›å±•æƒ…å†µã€‚""",
            version="1.0",
            description="ç”¨äºä¸­é—´è¿›åº¦æ›´æ–°æ—¶çš„çŠ¶æ€æè¿°ç”Ÿæˆ"
        )
        
        # æ€»ç»“åœºæ™¯æ¨¡æ¿
        summary_template = PromptTemplate(
            scenario=PromptScenario.SUMMARY,
            system_message="""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£ç”Ÿæˆå·¥ä½œæµå®Œæˆæˆ–é˜¶æ®µæ€§æ€»ç»“çš„çŠ¶æ€æè¿°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼ˆ2-4å¥è¯ï¼‰
2. æ€»ç»“ä¸»è¦æˆæœå’Œå®Œæˆæƒ…å†µ
3. ä½“ç°å·¥ä½œæµçš„æ•´ä½“ä»·å€¼
4. ä½¿ç”¨ç§¯æå’Œæ€»ç»“æ€§çš„è¯­è°ƒ""",
            user_template="""å·¥ä½œæµæ€»ç»“ä¿¡æ¯ï¼š

## æœ€ç»ˆ/é˜¶æ®µçŠ¶æ€
å½“å‰çŠ¶æ€ï¼š$current_state

## å®Œæˆæƒ…å†µ
ä¸»è¦æˆæœï¼š$execution_output
å®Œæˆæ­¥éª¤ï¼š$step_description
æ•´ä½“è¿›åº¦ï¼š$workflow_progress

## çŠ¶æ€å†å²å›é¡¾
$state_history

è¯·ç”Ÿæˆä¸€ä¸ªæ€»ç»“æ€§çš„çŠ¶æ€æè¿°ï¼ˆ2-4å¥è¯ï¼‰ï¼Œæ¦‚æ‹¬å·¥ä½œæµçš„ä¸»è¦æˆæœå’Œå®Œæˆæƒ…å†µã€‚""",
            version="1.0",
            description="ç”¨äºå·¥ä½œæµå®Œæˆæˆ–é˜¶æ®µæ€§æ€»ç»“æ—¶çš„çŠ¶æ€æè¿°ç”Ÿæˆ"
        )
        
        # æ³¨å†Œæ‰€æœ‰æ¨¡æ¿
        self._templates[PromptScenario.INITIALIZATION] = initialization_template
        self._templates[PromptScenario.SUCCESS_COMPLETION] = success_template
        self._templates[PromptScenario.ERROR_HANDLING] = error_template
        self._templates[PromptScenario.STATE_TRANSITION] = transition_template
        self._templates[PromptScenario.PROGRESS_UPDATE] = progress_template
        self._templates[PromptScenario.SUMMARY] = summary_template
    
    def get_template(self, scenario: PromptScenario) -> Optional[PromptTemplate]:
        """
        è·å–æŒ‡å®šåœºæ™¯çš„æ¨¡æ¿
        
        Args:
            scenario: åœºæ™¯æšä¸¾å€¼
            
        Returns:
            æ¨¡æ¿å®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        return self._templates.get(scenario)
    
    def add_template(self, template: PromptTemplate) -> None:
        """
        æ·»åŠ æ–°æ¨¡æ¿
        
        Args:
            template: æ¨¡æ¿å®ä¾‹
        """
        self._templates[template.scenario] = template
        self._logger.info(f"æ·»åŠ æ–°æ¨¡æ¿: {template.scenario.value} v{template.version}")
    
    def list_templates(self) -> List[Tuple[PromptScenario, str, str]]:
        """
        åˆ—å‡ºæ‰€æœ‰æ¨¡æ¿
        
        Returns:
            [(scenario, version, description), ...] åˆ—è¡¨
        """
        return [(scenario, template.version, template.description) 
                for scenario, template in self._templates.items()]
    
    def render_template(self, scenario: PromptScenario, variables: Dict[str, Any]) -> Tuple[str, str]:
        """
        æ¸²æŸ“æŒ‡å®šåœºæ™¯çš„æ¨¡æ¿
        
        Args:
            scenario: åœºæ™¯æšä¸¾å€¼
            variables: æ¨¡æ¿å˜é‡å­—å…¸
            
        Returns:
            (system_message, user_message) å…ƒç»„
            
        Raises:
            ValueError: æ¨¡æ¿ä¸å­˜åœ¨æˆ–æ¸²æŸ“å¤±è´¥
        """
        template = self.get_template(scenario)
        if template is None:
            raise ValueError(f"åœºæ™¯æ¨¡æ¿ä¸å­˜åœ¨: {scenario.value}")
        
        try:
            return template.render(variables)
        except Exception as e:
            self._logger.error(f"æ¨¡æ¿æ¸²æŸ“å¤±è´¥ [{scenario.value}]: {e}")
            raise
    
    def get_template_variables(self, scenario: PromptScenario) -> List[str]:
        """
        è·å–æŒ‡å®šåœºæ™¯æ¨¡æ¿æ‰€éœ€çš„å˜é‡åˆ—è¡¨
        
        Args:
            scenario: åœºæ™¯æšä¸¾å€¼
            
        Returns:
            å˜é‡ååˆ—è¡¨
        """
        template = self.get_template(scenario)
        if template is None:
            return []
        return template.get_required_variables()
    
    def validate_variables(self, scenario: PromptScenario, variables: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        éªŒè¯å˜é‡æ˜¯å¦æ»¡è¶³æ¨¡æ¿è¦æ±‚
        
        Args:
            scenario: åœºæ™¯æšä¸¾å€¼
            variables: å¾…éªŒè¯çš„å˜é‡å­—å…¸
            
        Returns:
            (æ˜¯å¦é€šè¿‡éªŒè¯, ç¼ºå¤±çš„å˜é‡åˆ—è¡¨)
        """
        required_vars = self.get_template_variables(scenario)
        provided_vars = set(variables.keys())
        required_vars_set = set(required_vars)
        
        missing_vars = list(required_vars_set - provided_vars)
        return len(missing_vars) == 0, missing_vars


class ParsedStateInfo(NamedTuple):
    """è§£æåçš„çŠ¶æ€ä¿¡æ¯ç»“æ„"""
    main_content: str                      # ä¸»è¦çŠ¶æ€å†…å®¹
    confidence_score: float               # ç½®ä¿¡åº¦è¯„åˆ† (0.0-1.0)
    extracted_entities: Dict[str, str]    # æå–çš„å®ä½“ä¿¡æ¯
    sentiment: Optional[str] = None       # æƒ…æ„Ÿåˆ†æç»“æœ
    intent: Optional[str] = None          # æ„å›¾è¯†åˆ«ç»“æœ
    quality_metrics: Dict[str, Any] = {}  # è´¨é‡æŒ‡æ ‡


class ResponseQuality(Enum):
    """å“åº”è´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"    # æä½³
    GOOD = "good"             # è‰¯å¥½  
    ACCEPTABLE = "acceptable" # å¯æ¥å—
    POOR = "poor"             # è¾ƒå·®
    INVALID = "invalid"       # æ— æ•ˆ


class ResponseParser:
    """æ™ºèƒ½LLMå“åº”è§£æå™¨"""
    
    def __init__(self, enable_sentiment_analysis: bool = True, 
                 enable_intent_recognition: bool = True):
        """
        åˆå§‹åŒ–å“åº”è§£æå™¨
        
        Args:
            enable_sentiment_analysis: æ˜¯å¦å¯ç”¨æƒ…æ„Ÿåˆ†æ
            enable_intent_recognition: æ˜¯å¦å¯ç”¨æ„å›¾è¯†åˆ«
        """
        self.enable_sentiment_analysis = enable_sentiment_analysis
        self.enable_intent_recognition = enable_intent_recognition
        self._logger = logging.getLogger(f"{__name__}.ResponseParser")
        
        # é¢„å®šä¹‰å…³é”®è¯é›†åˆ
        self._success_keywords = {
            "æˆåŠŸ", "å®Œæˆ", "å®ç°", "åˆ›å»º", "å»ºç«‹", "ç”Ÿæˆ", "æ„å»º", "è¾¾æˆ", 
            "è·å¾—", "è§£å†³", "ä¿®å¤", "æ­£å¸¸", "é¡ºåˆ©", "æœ‰æ•ˆ", "å¯ç”¨"
        }
        
        self._error_keywords = {
            "é”™è¯¯", "å¤±è´¥", "å¼‚å¸¸", "æ•…éšœ", "é—®é¢˜", "æ— æ³•", "ä¸èƒ½", "ä¸­æ–­",
            "å´©æºƒ", "è¶…æ—¶", "æ‹’ç»", "ä¸¢å¤±", "æŸå", "æ— æ•ˆ", "ä¸å¯ç”¨"
        }
        
        self._progress_keywords = {
            "æ­£åœ¨", "å¼€å§‹", "è¿›è¡Œ", "å¤„ç†", "æ‰§è¡Œ", "è¿è¡Œ", "åŠ è½½", "å‡†å¤‡",
            "åˆå§‹åŒ–", "é…ç½®", "ç­‰å¾…", "å°è¯•", "æ£€æŸ¥", "éªŒè¯"
        }
        
        # æƒ…æ„Ÿå…³é”®è¯
        self._positive_sentiment_keywords = {
            "é¡ºåˆ©", "æµç•…", "é«˜æ•ˆ", "ä¼˜ç§€", "ç¨³å®š", "å¯é ", "æ»¡æ„", "ç†æƒ³"
        }
        
        self._negative_sentiment_keywords = {
            "å›°éš¾", "å¤æ‚", "ç¼“æ…¢", "ä¸ç¨³å®š", "ç¹ç", "æŒ«æŠ˜", "éšœç¢", "ç“¶é¢ˆ"
        }
        
        # æ„å›¾å…³é”®è¯
        self._intent_patterns = {
            "request_action": ["éœ€è¦", "è¯·", "è¦æ±‚", "å¸Œæœ›", "å»ºè®®"],
            "report_status": ["å½“å‰", "ç›®å‰", "ç°åœ¨", "çŠ¶æ€", "æƒ…å†µ"],
            "indicate_completion": ["å®Œæˆ", "ç»“æŸ", "å®Œæ¯•", "è¾¾æˆ", "å®ç°"],
            "signal_error": ["å‡ºç°", "å‘ç”Ÿ", "é‡åˆ°", "é”™è¯¯", "é—®é¢˜", "å¼‚å¸¸"],
            "describe_progress": ["æ­£åœ¨", "è¿›è¡Œä¸­", "å¼€å§‹", "ç»§ç»­", "å¤„ç†"]
        }
        
        self._logger.debug(f"ResponseParseråˆå§‹åŒ–å®Œæˆ - æƒ…æ„Ÿåˆ†æ: {enable_sentiment_analysis}, æ„å›¾è¯†åˆ«: {enable_intent_recognition}")

    def parse_response(self, raw_response: str, context: Optional[Dict[str, Any]] = None) -> ParsedStateInfo:
        """
        è§£æLLMå“åº”å¹¶æå–ç»“æ„åŒ–ä¿¡æ¯
        
        Args:
            raw_response: åŸå§‹LLMå“åº”
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ParsedStateInfo: è§£æåçš„ç»“æ„åŒ–çŠ¶æ€ä¿¡æ¯
        """
        try:
            self._logger.debug(f"å¼€å§‹è§£æå“åº”ï¼Œé•¿åº¦: {len(raw_response) if raw_response else 0}")
            
            if not raw_response:
                return self._create_empty_parsed_info("ç©ºå“åº”")
            
            # 1. åŸºç¡€æ¸…ç†å’Œé¢„å¤„ç†
            cleaned_content = self._preprocess_response(raw_response)
            
            # 2. æå–ä¸»è¦å†…å®¹
            main_content = self._extract_main_content(cleaned_content)
            
            # 3. å®ä½“æå–
            entities = self._extract_entities(cleaned_content, context)
            
            # 4. è®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(cleaned_content, entities)
            
            # 5. æƒ…æ„Ÿåˆ†æï¼ˆå¯é€‰ï¼‰
            sentiment = None
            if self.enable_sentiment_analysis:
                sentiment = self._analyze_sentiment(cleaned_content)
            
            # 6. æ„å›¾è¯†åˆ«ï¼ˆå¯é€‰ï¼‰
            intent = None  
            if self.enable_intent_recognition:
                intent = self._recognize_intent(cleaned_content)
            
            # 7. è´¨é‡è¯„ä¼°
            quality_metrics = self._assess_quality(cleaned_content, entities, confidence)
            
            parsed_info = ParsedStateInfo(
                main_content=main_content,
                confidence_score=confidence,
                extracted_entities=entities,
                sentiment=sentiment,
                intent=intent,
                quality_metrics=quality_metrics
            )
            
            self._logger.info(f"å“åº”è§£æå®Œæˆ - ç½®ä¿¡åº¦: {confidence:.2f}, è´¨é‡: {quality_metrics.get('overall_quality', 'unknown')}")
            return parsed_info
            
        except Exception as e:
            self._logger.error(f"å“åº”è§£æå¤±è´¥: {e}")
            return self._create_empty_parsed_info(f"è§£æå¼‚å¸¸: {str(e)}")

    def _preprocess_response(self, response: str) -> str:
        """é¢„å¤„ç†å“åº”æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
        cleaned = re.sub(r'\s+', ' ', response.strip())
        
        # ç§»é™¤å¸¸è§çš„æ ¼å¼åŒ–å­—ç¬¦
        cleaned = re.sub(r'[*_`~]', '', cleaned)
        
        # ç§»é™¤HTMLæ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
        
        return cleaned

    def _extract_main_content(self, content: str) -> str:
        """æå–ä¸»è¦çŠ¶æ€å†…å®¹"""
        # å¦‚æœå†…å®¹å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(content) <= 100:
            return content
        
        # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´å¥å­æˆ–æ®µè½
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]\s*', content)
        if sentences:
            # é€‰æ‹©æœ€æœ‰ä¿¡æ¯é‡çš„å¥å­
            main_sentence = max(sentences, key=lambda s: len(s.strip()) if len(s.strip()) > 10 else 0)
            if main_sentence.strip():
                return main_sentence.strip()
        
        # å¦‚æœæ²¡æœ‰æ˜æ˜¾å¥å­ç»“æ„ï¼Œè¿”å›å‰100ä¸ªå­—ç¬¦
        return content[:100] + "..." if len(content) > 100 else content

    def _extract_entities(self, content: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, str]:
        """æå–å…³é”®å®ä½“ä¿¡æ¯"""
        entities = {}
        
        # æå–çŠ¶æ€ç±»å‹
        if any(keyword in content for keyword in self._success_keywords):
            entities["status_type"] = "success"
        elif any(keyword in content for keyword in self._error_keywords):
            entities["status_type"] = "error"  
        elif any(keyword in content for keyword in self._progress_keywords):
            entities["status_type"] = "progress"
        else:
            entities["status_type"] = "neutral"
        
        # æå–æ—¶é—´ç›¸å…³ä¿¡æ¯
        time_patterns = [
            r'(\d+)\s*åˆ†é’Ÿ',
            r'(\d+)\s*ç§’',
            r'(\d+)\s*å°æ—¶',
            r'(\d+)\s*å¤©'
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, content)
            if match:
                entities["time_reference"] = match.group(0)
                break
        
        # æå–æ•°å­—ä¿¡æ¯
        numbers = re.findall(r'\d+', content)
        if numbers:
            entities["numeric_values"] = ",".join(numbers[:3])  # æœ€å¤šä¿ç•™3ä¸ªæ•°å­—
        
        # ä»ä¸Šä¸‹æ–‡ä¸­æå–ç›¸å…³ä¿¡æ¯
        if context:
            if "step_name" in context:
                entities["related_step"] = str(context["step_name"])
            if "execution_success" in context:
                entities["execution_result"] = str(context["execution_success"])
        
        return entities

    def _calculate_confidence(self, content: str, entities: Dict[str, str]) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦è¯„åˆ†"""
        confidence = 0.5  # åŸºç¡€åˆ†æ•°
        
        # é•¿åº¦å› å­ï¼ˆåˆç†é•¿åº¦åŠ åˆ†ï¼‰
        length = len(content)
        if 20 <= length <= 200:
            confidence += 0.2
        elif 10 <= length < 20 or 200 < length <= 300:
            confidence += 0.1
        elif length < 10:
            confidence -= 0.2
        
        # å®ä½“æå–è´¨é‡
        entity_score = len(entities) * 0.05
        confidence += min(entity_score, 0.2)
        
        # å…³é”®è¯åŒ¹é…
        all_keywords = self._success_keywords | self._error_keywords | self._progress_keywords
        keyword_matches = sum(1 for keyword in all_keywords if keyword in content)
        keyword_score = keyword_matches * 0.03
        confidence += min(keyword_score, 0.15)
        
        # å¥å­ç»“æ„å®Œæ•´æ€§
        if re.search(r'[ã€‚ï¼ï¼Ÿ.!?]', content):
            confidence += 0.1
        
        return min(max(confidence, 0.0), 1.0)

    def _analyze_sentiment(self, content: str) -> Optional[str]:
        """åˆ†ææƒ…æ„Ÿå€¾å‘"""
        positive_count = sum(1 for keyword in self._positive_sentiment_keywords if keyword in content)
        negative_count = sum(1 for keyword in self._negative_sentiment_keywords if keyword in content)
        
        # ä¹Ÿè€ƒè™‘æˆåŠŸ/é”™è¯¯å…³é”®è¯çš„æƒ…æ„Ÿå€¾å‘
        success_count = sum(1 for keyword in self._success_keywords if keyword in content)
        error_count = sum(1 for keyword in self._error_keywords if keyword in content)
        
        total_positive = positive_count + success_count
        total_negative = negative_count + error_count
        
        if total_positive > total_negative:
            return "positive"
        elif total_negative > total_positive:
            return "negative"
        else:
            return "neutral"

    def _recognize_intent(self, content: str) -> Optional[str]:
        """è¯†åˆ«æ„å›¾"""
        intent_scores = {}
        
        for intent_type, keywords in self._intent_patterns.items():
            score = sum(1 for keyword in keywords if keyword in content)
            if score > 0:
                intent_scores[intent_type] = score
        
        if intent_scores:
            # è¿”å›å¾—åˆ†æœ€é«˜çš„æ„å›¾
            return max(intent_scores, key=intent_scores.get)
        
        return None

    def _assess_quality(self, content: str, entities: Dict[str, str], confidence: float) -> Dict[str, Any]:
        """è¯„ä¼°å“åº”è´¨é‡"""
        metrics = {
            "content_length": len(content),
            "entity_count": len(entities),
            "confidence_score": confidence
        }
        
        # ç¡®å®šæ•´ä½“è´¨é‡ç­‰çº§
        if confidence >= 0.8 and len(content) >= 20 and len(entities) >= 2:
            overall_quality = ResponseQuality.EXCELLENT
        elif confidence >= 0.6 and len(content) >= 15:
            overall_quality = ResponseQuality.GOOD
        elif confidence >= 0.4 and len(content) >= 10:
            overall_quality = ResponseQuality.ACCEPTABLE
        elif confidence >= 0.2:
            overall_quality = ResponseQuality.POOR
        else:
            overall_quality = ResponseQuality.INVALID
        
        metrics["overall_quality"] = overall_quality.value
        metrics["is_valid"] = overall_quality != ResponseQuality.INVALID
        
        return metrics

    def _create_empty_parsed_info(self, reason: str) -> ParsedStateInfo:
        """åˆ›å»ºç©ºçš„è§£æä¿¡æ¯"""
        return ParsedStateInfo(
            main_content=f"è§£æå¤±è´¥: {reason}",
            confidence_score=0.0,
            extracted_entities={"status_type": "error", "error_reason": reason},
            sentiment="negative",
            intent="signal_error",
            quality_metrics={"overall_quality": ResponseQuality.INVALID.value, "is_valid": False}
        )

    def validate_parsed_info(self, parsed_info: ParsedStateInfo, 
                           min_confidence: float = 0.3) -> Tuple[bool, List[str]]:
        """
        éªŒè¯è§£æåçš„ä¿¡æ¯æ˜¯å¦ç¬¦åˆè¦æ±‚
        
        Args:
            parsed_info: è§£æåçš„çŠ¶æ€ä¿¡æ¯
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦æœ‰æ•ˆ, é—®é¢˜åˆ—è¡¨)
        """
        issues = []
        
        # ç½®ä¿¡åº¦æ£€æŸ¥
        if parsed_info.confidence_score < min_confidence:
            issues.append(f"ç½®ä¿¡åº¦è¿‡ä½: {parsed_info.confidence_score:.2f} < {min_confidence}")
        
        # å†…å®¹é•¿åº¦æ£€æŸ¥
        if len(parsed_info.main_content) < 5:
            issues.append("ä¸»è¦å†…å®¹è¿‡çŸ­")
        
        # è´¨é‡æ£€æŸ¥
        if not parsed_info.quality_metrics.get("is_valid", False):
            issues.append("å“åº”è´¨é‡ä¸åˆæ ¼")
        
        # å®ä½“æ£€æŸ¥
        if not parsed_info.extracted_entities:
            issues.append("æœªæå–åˆ°æœ‰æ•ˆå®ä½“")
        
        is_valid = len(issues) == 0
        return is_valid, issues

    def suggest_improvements(self, parsed_info: ParsedStateInfo) -> List[str]:
        """å»ºè®®æ”¹è¿›æªæ–½"""
        suggestions = []
        
        if parsed_info.confidence_score < 0.5:
            suggestions.append("å»ºè®®é‡æ–°ç”Ÿæˆæ›´è¯¦ç»†çš„çŠ¶æ€æè¿°")
        
        if len(parsed_info.extracted_entities) < 2:
            suggestions.append("å»ºè®®åœ¨çŠ¶æ€æè¿°ä¸­åŒ…å«æ›´å¤šå…·ä½“ä¿¡æ¯")
        
        if parsed_info.quality_metrics.get("overall_quality") in ["poor", "invalid"]:
            suggestions.append("å»ºè®®æ£€æŸ¥LLMæç¤ºæ¨¡æ¿å’Œå‚æ•°è®¾ç½®")
        
        return suggestions


class StateRelevanceType(Enum):
    """çŠ¶æ€ç›¸å…³æ€§ç±»å‹æšä¸¾"""
    HIGH = "high"           # é«˜ç›¸å…³æ€§ - ç›´æ¥ç›¸å…³çš„çŠ¶æ€ä¿¡æ¯
    MEDIUM = "medium"       # ä¸­ç­‰ç›¸å…³æ€§ - å¯èƒ½æœ‰ç”¨çš„çŠ¶æ€ä¿¡æ¯
    LOW = "low"             # ä½ç›¸å…³æ€§ - æ¬¡è¦çš„çŠ¶æ€ä¿¡æ¯
    NONE = "none"           # æ— ç›¸å…³æ€§ - ä¸ç›¸å…³çš„çŠ¶æ€ä¿¡æ¯


class InstructionOptimizationType(Enum):
    """æŒ‡ä»¤ä¼˜åŒ–ç±»å‹æšä¸¾"""
    CONTEXT_ENHANCEMENT = "context_enhancement"       # ä¸Šä¸‹æ–‡å¢å¼º
    ERROR_PREVENTION = "error_prevention"             # é”™è¯¯é¢„é˜²
    EFFICIENCY_IMPROVEMENT = "efficiency_improvement" # æ•ˆç‡æå‡
    CLARITY_OPTIMIZATION = "clarity_optimization"     # æ¸…æ™°åº¦ä¼˜åŒ–
    DEPENDENCY_AWARENESS = "dependency_awareness"     # ä¾èµ–å…³ç³»æ„ŸçŸ¥
    PATTERN_LEARNING = "pattern_learning"             # æ¨¡å¼å­¦ä¹ 


class OptimizationStrategy(Enum):
    """ä¼˜åŒ–ç­–ç•¥æšä¸¾"""
    CONSERVATIVE = "conservative"         # ä¿å®ˆç­–ç•¥ - æœ€å°åŒ–ä¿®æ”¹
    MODERATE = "moderate"                # é€‚ä¸­ç­–ç•¥ - å¹³è¡¡ä¿®æ”¹å’ŒåŸå§‹æ„å›¾
    AGGRESSIVE = "aggressive"            # æ¿€è¿›ç­–ç•¥ - æœ€å¤§åŒ–ä¼˜åŒ–æ•ˆæœ
    ADAPTIVE = "adaptive"                # è‡ªé€‚åº”ç­–ç•¥ - æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´


class DecisionNodeType(Enum):
    """å†³ç­–èŠ‚ç‚¹ç±»å‹æšä¸¾"""
    CONDITIONAL = "conditional"       # æ¡ä»¶å†³ç­– - if/else
    SWITCH = "switch"                # å¤šè·¯å†³ç­– - switch/case
    LOOP_CONDITION = "loop_condition" # å¾ªç¯æ¡ä»¶ - while/for
    VALIDATION = "validation"        # éªŒè¯å†³ç­– - æ•°æ®éªŒè¯
    APPROVAL = "approval"            # å®¡æ‰¹å†³ç­– - äººå·¥å®¡æ‰¹
    THRESHOLD = "threshold"          # é˜ˆå€¼å†³ç­– - åŸºäºæ•°å€¼æ¯”è¾ƒ


class ConditionOperator(Enum):
    """æ¡ä»¶æ“ä½œç¬¦æšä¸¾"""
    EQUALS = "=="              # ç­‰äº
    NOT_EQUALS = "!="          # ä¸ç­‰äº
    GREATER_THAN = ">"         # å¤§äº
    LESS_THAN = "<"            # å°äº
    GREATER_EQUAL = ">="       # å¤§äºç­‰äº
    LESS_EQUAL = "<="          # å°äºç­‰äº
    CONTAINS = "contains"      # åŒ…å«
    NOT_CONTAINS = "not_contains"  # ä¸åŒ…å«
    STARTS_WITH = "starts_with"    # å¼€å§‹äº
    ENDS_WITH = "ends_with"        # ç»“æŸäº
    IN = "in"                      # åœ¨åˆ—è¡¨ä¸­
    NOT_IN = "not_in"              # ä¸åœ¨åˆ—è¡¨ä¸­
    IS_EMPTY = "is_empty"          # ä¸ºç©º
    IS_NOT_EMPTY = "is_not_empty"  # ä¸ä¸ºç©º
    REGEX_MATCH = "regex_match"    # æ­£åˆ™åŒ¹é…


class DecisionResult(NamedTuple):
    """å†³ç­–ç»“æœç»“æ„"""
    next_step_id: Optional[str]           # ä¸‹ä¸€æ­¥ID
    decision_made: bool                   # æ˜¯å¦æˆåŠŸåšå‡ºå†³ç­–
    decision_reason: str                  # å†³ç­–ç†ç”±
    evaluated_conditions: List[Dict[str, Any]]  # è¯„ä¼°çš„æ¡ä»¶
    state_variables_used: List[str]       # ä½¿ç”¨çš„çŠ¶æ€å˜é‡
    confidence: float                     # å†³ç­–ç½®ä¿¡åº¦ (0.0-1.0)
    additional_actions: List[str]         # é¢å¤–çš„è¡ŒåŠ¨å»ºè®®


class InstructionOptimizationResult(NamedTuple):
    """æŒ‡ä»¤ä¼˜åŒ–ç»“æœç»“æ„"""
    original_instruction: str                      # åŸå§‹æŒ‡ä»¤
    optimized_instruction: str                     # ä¼˜åŒ–åçš„æŒ‡ä»¤
    optimization_types: List[InstructionOptimizationType]  # åº”ç”¨çš„ä¼˜åŒ–ç±»å‹
    confidence_score: float                        # ä¼˜åŒ–ç½®ä¿¡åº¦ (0.0-1.0)
    applied_enhancements: List[str]               # åº”ç”¨çš„å¢å¼ºåŠŸèƒ½
    predicted_improvement: float                   # é¢„æœŸæ”¹è¿›ç¨‹åº¦ (0.0-1.0)
    optimization_reasoning: str                    # ä¼˜åŒ–ç†ç”±
    risk_assessment: Dict[str, Any]               # é£é™©è¯„ä¼°


class StateContextExtractor:
    """çŠ¶æ€ä¸Šä¸‹æ–‡æå–å™¨ - æ™ºèƒ½åˆ†æå’Œæå–ç›¸å…³çŠ¶æ€ä¿¡æ¯"""
    
    def __init__(self):
        # å®šä¹‰å…³é”®è¯æ˜ å°„è¡¨ï¼Œç”¨äºè¯†åˆ«æ­¥éª¤ç±»å‹å’Œç›¸å…³æ€§
        self.step_type_keywords = {
            'file_operations': ['æ–‡ä»¶', 'åˆ›å»º', 'å†™å…¥', 'è¯»å–', 'ä¿å­˜', 'åˆ é™¤', 'file', 'create', 'write', 'read', 'save', 'delete'],
            'database': ['æ•°æ®åº“', 'è¿æ¥', 'æŸ¥è¯¢', 'æ’å…¥', 'æ›´æ–°', 'database', 'db', 'query', 'insert', 'update', 'mysql', 'postgres'],
            'api': ['API', 'HTTP', 'è¯·æ±‚', 'å“åº”', 'æ¥å£', 'request', 'response', 'endpoint', 'service'],
            'configuration': ['é…ç½®', 'è®¾ç½®', 'å‚æ•°', 'config', 'configuration', 'setting', 'parameter'],
            'testing': ['æµ‹è¯•', 'éªŒè¯', 'æ£€æŸ¥', 'test', 'verify', 'check', 'validation'],
            'deployment': ['éƒ¨ç½²', 'å‘å¸ƒ', 'ä¸Šçº¿', 'deploy', 'deployment', 'release', 'publish'],
            'security': ['å®‰å…¨', 'è®¤è¯', 'æˆæƒ', 'åŠ å¯†', 'security', 'auth', 'authentication', 'encryption'],
            'ui': ['ç•Œé¢', 'UI', 'å‰ç«¯', 'é¡µé¢', 'frontend', 'page', 'interface', 'view'],
            'data_processing': ['æ•°æ®', 'å¤„ç†', 'åˆ†æ', 'è½¬æ¢', 'data', 'process', 'analysis', 'transform'],
            'error_handling': ['é”™è¯¯', 'å¼‚å¸¸', 'å¤±è´¥', 'ä¿®å¤', 'error', 'exception', 'failure', 'fix', 'debug']
        }
        
        # çŠ¶æ€ä¿¡æ¯ä¼˜å…ˆçº§æ˜ å°„
        self.state_priority_patterns = {
            'error_context': ['é”™è¯¯', 'å¤±è´¥', 'å¼‚å¸¸', 'error', 'failed', 'exception'],
            'file_paths': ['è·¯å¾„', 'æ–‡ä»¶å', 'ç›®å½•', 'path', 'file', 'directory', 'folder'],
            'api_endpoints': ['API', 'URL', 'ç«¯ç‚¹', 'endpoint', 'service'],
            'database_info': ['æ•°æ®åº“', 'è¿æ¥å­—ç¬¦ä¸²', 'database', 'connection'],
            'config_values': ['é…ç½®', 'å‚æ•°', 'è®¾ç½®', 'config', 'parameter', 'setting'],
            'completion_status': ['å®Œæˆ', 'æˆåŠŸ', 'çŠ¶æ€', 'completed', 'success', 'status']
        }
    
    def extract_relevant_context(self, step: Dict[str, Any], global_state: 'WorkflowState') -> Dict[str, Any]:
        """
        æå–ä¸å½“å‰æ­¥éª¤ç›¸å…³çš„çŠ¶æ€ä¸Šä¸‹æ–‡
        
        Args:
            step: å½“å‰æ­¥éª¤ä¿¡æ¯
            global_state: å…¨å±€å·¥ä½œæµçŠ¶æ€
            
        Returns:
            ç›¸å…³çŠ¶æ€ä¸Šä¸‹æ–‡å­—å…¸
        """
        context = {
            'high_relevance': [],
            'medium_relevance': [],
            'low_relevance': [],
            'state_summary': '',
            'extracted_entities': {}
        }
        
        try:
            # åˆ†ææ­¥éª¤ç±»å‹å’Œå…³é”®è¯
            step_analysis = self._analyze_step_requirements(step)
            
            # è·å–å½“å‰å…¨å±€çŠ¶æ€
            current_state = global_state.get_global_state()
            if not current_state:
                return context
            
            # æå–çŠ¶æ€å®ä½“
            context['extracted_entities'] = self._extract_state_entities(current_state, step_analysis)
            
            # æ ¹æ®ç›¸å…³æ€§åˆ†ç±»çŠ¶æ€ä¿¡æ¯
            context = self._categorize_state_relevance(current_state, step_analysis, context)
            
            # ç”ŸæˆçŠ¶æ€æ‘˜è¦
            context['state_summary'] = self._generate_context_summary(context, step_analysis)
            
            return context
            
        except Exception as e:
            logger.error(f"çŠ¶æ€ä¸Šä¸‹æ–‡æå–å¤±è´¥: {e}")
            return context
    
    def _analyze_step_requirements(self, step: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ­¥éª¤éœ€æ±‚å’Œç±»å‹"""
        analysis = {
            'step_types': [],
            'keywords': [],
            'instruction_content': step.get('instruction', '').lower(),
            'step_name': step.get('name', '').lower(),
            'expected_output': step.get('expected_output', '').lower(),
            'agent_type': step.get('agent_name', '').lower()
        }
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ
        full_text = f"{analysis['instruction_content']} {analysis['step_name']} {analysis['expected_output']}"
        
        # è¯†åˆ«æ­¥éª¤ç±»å‹
        for step_type, keywords in self.step_type_keywords.items():
            if any(keyword in full_text for keyword in keywords):
                analysis['step_types'].append(step_type)
                analysis['keywords'].extend([kw for kw in keywords if kw in full_text])
        
        return analysis
    
    def _extract_state_entities(self, state_content: str, step_analysis: Dict[str, Any]) -> Dict[str, str]:
        """ä»çŠ¶æ€å†…å®¹ä¸­æå–å®ä½“ä¿¡æ¯"""
        entities = {}
        state_lower = state_content.lower()
        
        # æå–æ–‡ä»¶è·¯å¾„
        import re
        file_patterns = [
            r'[a-zA-Z]?[:/\\][^\\s]+\\.[a-zA-Z0-9]+',  # æ–‡ä»¶è·¯å¾„
            r'[./][^\\s]+\\.[a-zA-Z0-9]+',             # ç›¸å¯¹è·¯å¾„
            r'[a-zA-Z0-9_-]+\\.[a-zA-Z0-9]+',         # æ–‡ä»¶å
        ]
        
        for pattern in file_patterns:
            matches = re.findall(pattern, state_content)
            if matches:
                entities['file_paths'] = matches[:3]  # æœ€å¤šä¿ç•™3ä¸ªæ–‡ä»¶è·¯å¾„
        
        # æå–é…ç½®é”®å€¼å¯¹
        config_pattern = r'([a-zA-Z_][a-zA-Z0-9_]*)[\\s]*[:=][\\s]*([^\\n,;]+)'
        config_matches = re.findall(config_pattern, state_content)
        if config_matches:
            entities['config_pairs'] = dict(config_matches[:5])  # æœ€å¤šä¿ç•™5ä¸ªé…ç½®å¯¹
        
        # æå–é”™è¯¯ä¿¡æ¯
        error_patterns = [
            r'é”™è¯¯[ï¼š:][^\\n]+',
            r'error[:\\s]+[^\\n]+',
            r'å¤±è´¥[ï¼š:][^\\n]+',
            r'failed[:\\s]+[^\\n]+'
        ]
        
        for pattern in error_patterns:
            matches = re.findall(pattern, state_content, re.IGNORECASE)
            if matches:
                entities['errors'] = matches[:2]  # æœ€å¤šä¿ç•™2ä¸ªé”™è¯¯ä¿¡æ¯
                break
        
        # æå–APIç›¸å…³ä¿¡æ¯
        api_pattern = r'(https?://[^\\s]+|/api/[^\\s]+|[a-zA-Z]+API)'
        api_matches = re.findall(api_pattern, state_content, re.IGNORECASE)
        if api_matches:
            entities['api_info'] = api_matches[:3]
        
        return entities
    
    def _categorize_state_relevance(self, state_content: str, step_analysis: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®ç›¸å…³æ€§å¯¹çŠ¶æ€ä¿¡æ¯è¿›è¡Œåˆ†ç±»"""
        state_lines = [line.strip() for line in state_content.split('\\n') if line.strip()]
        step_keywords = set(step_analysis['keywords'])
        step_types = step_analysis['step_types']
        
        for line in state_lines:
            line_lower = line.lower()
            relevance_score = 0
            
            # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
            # 1. å…³é”®è¯åŒ¹é…
            matching_keywords = sum(1 for keyword in step_keywords if keyword in line_lower)
            relevance_score += matching_keywords * 2
            
            # 2. æ­¥éª¤ç±»å‹ç›¸å…³æ€§
            for step_type in step_types:
                type_keywords = self.step_type_keywords.get(step_type, [])
                type_matches = sum(1 for keyword in type_keywords if keyword in line_lower)
                relevance_score += type_matches
            
            # 3. ä¼˜å…ˆçº§æ¨¡å¼åŒ¹é…
            for priority_type, patterns in self.state_priority_patterns.items():
                if any(pattern in line_lower for pattern in patterns):
                    relevance_score += 3
            
            # 4. å®ä½“æå–ç›¸å…³æ€§
            if context['extracted_entities']:
                for entity_type, entities in context['extracted_entities'].items():
                    if isinstance(entities, list):
                        for entity in entities:
                            if str(entity).lower() in line_lower:
                                relevance_score += 2
                    elif isinstance(entities, dict):
                        for key, value in entities.items():
                            if key.lower() in line_lower or str(value).lower() in line_lower:
                                relevance_score += 2
            
            # æ ¹æ®å¾—åˆ†åˆ†ç±»
            if relevance_score >= 5:
                context['high_relevance'].append(line)
            elif relevance_score >= 2:
                context['medium_relevance'].append(line)
            elif relevance_score >= 1:
                context['low_relevance'].append(line)
        
        return context
    
    def _generate_context_summary(self, context: Dict[str, Any], step_analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦"""
        summary_parts = []
        
        # é«˜ç›¸å…³æ€§ä¿¡æ¯æ‘˜è¦
        if context['high_relevance']:
            summary_parts.append(f"**å…³é”®çŠ¶æ€** ({len(context['high_relevance'])}é¡¹):")
            summary_parts.extend([f"â€¢ {item}" for item in context['high_relevance'][:3]])
        
        # æå–çš„å®ä½“æ‘˜è¦
        if context['extracted_entities']:
            entity_summary = []
            for entity_type, entities in context['extracted_entities'].items():
                if isinstance(entities, list) and entities:
                    entity_summary.append(f"{entity_type}: {', '.join(str(e) for e in entities[:2])}")
                elif isinstance(entities, dict) and entities:
                    pairs = [f"{k}={v}" for k, v in list(entities.items())[:2]]
                    entity_summary.append(f"{entity_type}: {', '.join(pairs)}")
            
            if entity_summary:
                summary_parts.append("**æå–å®ä½“**: " + "; ".join(entity_summary))
        
        # æ­¥éª¤ç±»å‹ç›¸å…³æç¤º
        if step_analysis['step_types']:
            summary_parts.append(f"**æ­¥éª¤ç±»å‹**: {', '.join(step_analysis['step_types'])}")
        
        return "\n".join(summary_parts) if summary_parts else "æ— ç‰¹åˆ«ç›¸å…³çš„çŠ¶æ€ä¿¡æ¯"


class InstructionOptimizer(ABC):
    """æŒ‡ä»¤ä¼˜åŒ–å™¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    def can_optimize(self, instruction: str, step: Dict[str, Any], 
                    global_state: 'WorkflowState', context: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦å¯ä»¥ä¼˜åŒ–æŒ‡å®šçš„æŒ‡ä»¤
        
        Args:
            instruction: åŸå§‹æŒ‡ä»¤
            step: æ­¥éª¤ä¿¡æ¯
            global_state: å…¨å±€çŠ¶æ€
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            æ˜¯å¦å¯ä»¥ä¼˜åŒ–
        """
        pass
    
    @abstractmethod
    def optimize_instruction(self, instruction: str, step: Dict[str, Any], 
                           global_state: 'WorkflowState', context: Dict[str, Any]) -> InstructionOptimizationResult:
        """
        ä¼˜åŒ–æŒ‡ä»¤
        
        Args:
            instruction: åŸå§‹æŒ‡ä»¤
            step: æ­¥éª¤ä¿¡æ¯
            global_state: å…¨å±€çŠ¶æ€
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            æŒ‡ä»¤ä¼˜åŒ–ç»“æœ
        """
        pass
    
    @abstractmethod
    def get_optimization_priority(self) -> int:
        """
        è·å–ä¼˜åŒ–å™¨ä¼˜å…ˆçº§ (æ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜)
        
        Returns:
            ä¼˜å…ˆçº§æ•°å€¼
        """
        pass


class StateAwareInstructionOptimizer(InstructionOptimizer):
    """çŠ¶æ€æ„ŸçŸ¥çš„æŒ‡ä»¤ä¼˜åŒ–å™¨"""
    
    def __init__(self, strategy: OptimizationStrategy = OptimizationStrategy.MODERATE):
        self.strategy = strategy
        self.logger = logging.getLogger(f"{__name__}.StateAwareInstructionOptimizer")
        
        # ä¼˜åŒ–è§„åˆ™é…ç½®
        self.optimization_rules = {
            InstructionOptimizationType.CONTEXT_ENHANCEMENT: True,
            InstructionOptimizationType.ERROR_PREVENTION: True,
            InstructionOptimizationType.EFFICIENCY_IMPROVEMENT: True,
            InstructionOptimizationType.CLARITY_OPTIMIZATION: True,
            InstructionOptimizationType.DEPENDENCY_AWARENESS: True,
            InstructionOptimizationType.PATTERN_LEARNING: False,  # é»˜è®¤å…³é—­ï¼Œå¯æ ¹æ®éœ€è¦å¯ç”¨
        }
        
        # ä¼˜åŒ–ç»Ÿè®¡
        self.optimization_stats = {
            'total_optimizations': 0,
            'successful_optimizations': 0,
            'optimization_types_used': {},
            'average_confidence': 0.0,
            'average_improvement': 0.0
        }
        
        # é”™è¯¯æ¨¡å¼å­¦ä¹ 
        self.error_patterns = []
        self.success_patterns = []
        
    def can_optimize(self, instruction: str, step: Dict[str, Any], 
                    global_state: 'WorkflowState', context: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥ä¼˜åŒ–æŒ‡ä»¤"""
        if not instruction or not instruction.strip():
            return False
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¨å±€çŠ¶æ€ä¿¡æ¯å¯ç”¨äºä¼˜åŒ–
        state_content = global_state.get_global_state()
        if not state_content or len(state_content.strip()) < 10:
            return False
            
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        if not step or not context:
            return False
            
        # å¦‚æœæŒ‡ä»¤å·²ç»å¾ˆè¯¦ç»†ï¼ˆåŒ…å«çŠ¶æ€æ„ŸçŸ¥ä¿¡æ¯ï¼‰ï¼Œé™ä½ä¼˜åŒ–ä¼˜å…ˆçº§
        if "çŠ¶æ€æ„ŸçŸ¥" in instruction or "## ğŸ¯" in instruction:
            return len(instruction) < 1000  # åªæœ‰å½“æŒ‡ä»¤ä¸æ˜¯å¤ªé•¿æ—¶æ‰ä¼˜åŒ–
            
        return True
    
    def optimize_instruction(self, instruction: str, step: Dict[str, Any], 
                           global_state: 'WorkflowState', context: Dict[str, Any]) -> InstructionOptimizationResult:
        """ä¼˜åŒ–æŒ‡ä»¤"""
        self.optimization_stats['total_optimizations'] += 1
        
        try:
            # åˆ†ææŒ‡ä»¤å’Œä¸Šä¸‹æ–‡
            analysis = self._analyze_instruction_context(instruction, step, global_state, context)
            
            # ç¡®å®šéœ€è¦åº”ç”¨çš„ä¼˜åŒ–ç±»å‹
            optimization_types = self._determine_optimization_types(analysis)
            
            # åº”ç”¨ä¼˜åŒ–
            optimized_instruction = self._apply_optimizations(
                instruction, step, global_state, context, analysis, optimization_types
            )
            
            # è®¡ç®—ç½®ä¿¡åº¦å’Œé¢„æœŸæ”¹è¿›
            confidence_score = self._calculate_optimization_confidence(analysis, optimization_types)
            predicted_improvement = self._predict_improvement(analysis, optimization_types)
            
            # è¿›è¡Œé£é™©è¯„ä¼°
            risk_assessment = self._assess_optimization_risk(instruction, optimized_instruction, analysis)
            
            # ç”Ÿæˆä¼˜åŒ–ç†ç”±
            reasoning = self._generate_optimization_reasoning(optimization_types, analysis)
            
            # åˆ›å»ºç»“æœ
            result = InstructionOptimizationResult(
                original_instruction=instruction,
                optimized_instruction=optimized_instruction,
                optimization_types=optimization_types,
                confidence_score=confidence_score,
                applied_enhancements=self._get_applied_enhancements(optimization_types),
                predicted_improvement=predicted_improvement,
                optimization_reasoning=reasoning,
                risk_assessment=risk_assessment
            )
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_optimization_stats(result)
            
            self.logger.info(f"æŒ‡ä»¤ä¼˜åŒ–å®Œæˆ - ç½®ä¿¡åº¦: {confidence_score:.2f}, é¢„æœŸæ”¹è¿›: {predicted_improvement:.2f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"æŒ‡ä»¤ä¼˜åŒ–å¤±è´¥: {e}")
            # è¿”å›æœªä¼˜åŒ–çš„ç»“æœ
            return InstructionOptimizationResult(
                original_instruction=instruction,
                optimized_instruction=instruction,
                optimization_types=[],
                confidence_score=0.0,
                applied_enhancements=[],
                predicted_improvement=0.0,
                optimization_reasoning=f"ä¼˜åŒ–å¤±è´¥: {str(e)}",
                risk_assessment={'error': str(e)}
            )
    
    def get_optimization_priority(self) -> int:
        """è·å–ä¼˜åŒ–å™¨ä¼˜å…ˆçº§"""
        return 10  # ä¸­ç­‰ä¼˜å…ˆçº§
    
    def _analyze_instruction_context(self, instruction: str, step: Dict[str, Any], 
                                   global_state: 'WorkflowState', context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææŒ‡ä»¤å’Œä¸Šä¸‹æ–‡"""
        analysis = {
            'instruction_length': len(instruction),
            'instruction_complexity': self._assess_instruction_complexity(instruction),
            'has_state_info': "çŠ¶æ€" in instruction.lower(),
            'has_context_info': any(word in instruction.lower() for word in ['ä¸Šä¸‹æ–‡', 'èƒŒæ™¯', 'ç¯å¢ƒ']),
            'has_error_handling': any(word in instruction.lower() for word in ['é”™è¯¯', 'å¼‚å¸¸', 'å¤±è´¥']),
            'step_type': step.get('type', 'unknown'),
            'step_complexity': self._assess_step_complexity(step),
            'state_richness': len(global_state.get_global_state()),
            'context_richness': len(str(context)),
            'historical_errors': self._get_historical_errors(context),
            'recent_failures': self._get_recent_failures(global_state),
            'dependency_info': self._analyze_dependencies(step, context),
        }
        
        return analysis
    
    def _determine_optimization_types(self, analysis: Dict[str, Any]) -> List[InstructionOptimizationType]:
        """ç¡®å®šéœ€è¦åº”ç”¨çš„ä¼˜åŒ–ç±»å‹"""
        optimization_types = []
        
        # ä¸Šä¸‹æ–‡å¢å¼º
        if (not analysis['has_context_info'] and analysis['state_richness'] > 50 
            and self.optimization_rules[InstructionOptimizationType.CONTEXT_ENHANCEMENT]):
            optimization_types.append(InstructionOptimizationType.CONTEXT_ENHANCEMENT)
        
        # é”™è¯¯é¢„é˜²
        if ((analysis['historical_errors'] or analysis['recent_failures']) 
            and self.optimization_rules[InstructionOptimizationType.ERROR_PREVENTION]):
            optimization_types.append(InstructionOptimizationType.ERROR_PREVENTION)
        
        # æ•ˆç‡æå‡
        if (analysis['instruction_complexity'] < 0.3 and analysis['step_complexity'] > 0.7
            and self.optimization_rules[InstructionOptimizationType.EFFICIENCY_IMPROVEMENT]):
            optimization_types.append(InstructionOptimizationType.EFFICIENCY_IMPROVEMENT)
        
        # æ¸…æ™°åº¦ä¼˜åŒ–
        if (analysis['instruction_length'] < 100 and analysis['step_complexity'] > 0.5
            and self.optimization_rules[InstructionOptimizationType.CLARITY_OPTIMIZATION]):
            optimization_types.append(InstructionOptimizationType.CLARITY_OPTIMIZATION)
        
        # ä¾èµ–å…³ç³»æ„ŸçŸ¥
        if (analysis['dependency_info']['has_dependencies'] 
            and self.optimization_rules[InstructionOptimizationType.DEPENDENCY_AWARENESS]):
            optimization_types.append(InstructionOptimizationType.DEPENDENCY_AWARENESS)
        
        return optimization_types
    
    def _apply_optimizations(self, instruction: str, step: Dict[str, Any], 
                           global_state: 'WorkflowState', context: Dict[str, Any],
                           analysis: Dict[str, Any], optimization_types: List[InstructionOptimizationType]) -> str:
        """åº”ç”¨æŒ‡ä»¤ä¼˜åŒ–"""
        optimized_instruction = instruction
        
        for opt_type in optimization_types:
            if opt_type == InstructionOptimizationType.CONTEXT_ENHANCEMENT:
                optimized_instruction = self._enhance_context(optimized_instruction, global_state, context)
            elif opt_type == InstructionOptimizationType.ERROR_PREVENTION:
                optimized_instruction = self._add_error_prevention(optimized_instruction, analysis)
            elif opt_type == InstructionOptimizationType.EFFICIENCY_IMPROVEMENT:
                optimized_instruction = self._improve_efficiency(optimized_instruction, step, context)
            elif opt_type == InstructionOptimizationType.CLARITY_OPTIMIZATION:
                optimized_instruction = self._optimize_clarity(optimized_instruction, step)
            elif opt_type == InstructionOptimizationType.DEPENDENCY_AWARENESS:
                optimized_instruction = self._add_dependency_awareness(optimized_instruction, analysis)
        
        return optimized_instruction
    
    def _enhance_context(self, instruction: str, global_state: 'WorkflowState', context: Dict[str, Any]) -> str:
        """å¢å¼ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        state_content = global_state.get_global_state()
        
        # æå–å…³é”®çŠ¶æ€ä¿¡æ¯
        key_info = []
        if "é…ç½®" in state_content.lower():
            key_info.append("ğŸ“‹ å½“å‰æœ‰ç›¸å…³é…ç½®ä¿¡æ¯å¯ç”¨")
        if "é”™è¯¯" in state_content.lower():
            key_info.append("âš ï¸ æ³¨æ„ä¹‹å‰å‡ºç°çš„é”™è¯¯")
        if "å®Œæˆ" in state_content.lower():
            key_info.append("âœ… æŸäº›å‰ç½®ä»»åŠ¡å·²å®Œæˆ")
        if "æ–‡ä»¶" in state_content.lower():
            key_info.append("ğŸ“ æ¶‰åŠæ–‡ä»¶æ“ä½œç›¸å…³çš„çŠ¶æ€")
        
        if key_info:
            enhanced = f"{instruction}\n\n**ğŸ¯ é‡è¦ä¸Šä¸‹æ–‡æç¤º:**\n"
            for info in key_info:
                enhanced += f"- {info}\n"
            enhanced += f"\n**è¯·ç»“åˆä¸Šè¿°ä¸Šä¸‹æ–‡ä¿¡æ¯æ‰§è¡Œä»»åŠ¡ï¼Œç¡®ä¿ä¸å½“å‰å·¥ä½œæµçŠ¶æ€ä¿æŒä¸€è‡´ã€‚**"
            return enhanced
        
        return instruction
    
    def _add_error_prevention(self, instruction: str, analysis: Dict[str, Any]) -> str:
        """æ·»åŠ é”™è¯¯é¢„é˜²ä¿¡æ¯"""
        prevention_tips = []
        
        if analysis['historical_errors']:
            prevention_tips.append("ğŸš¨ **é”™è¯¯é¢„é˜²**: ä¹‹å‰æ‰§è¡Œä¸­å‡ºç°è¿‡é”™è¯¯ï¼Œè¯·ç‰¹åˆ«æ³¨æ„é”™è¯¯å¤„ç†")
        
        if analysis['recent_failures']:
            prevention_tips.append("ğŸ”§ **æ•…éšœé¢„é˜²**: è¿‘æœŸæœ‰ä»»åŠ¡å¤±è´¥ï¼Œå»ºè®®éªŒè¯å‰ç½®æ¡ä»¶")
        
        if prevention_tips:
            enhanced = f"{instruction}\n\n"
            for tip in prevention_tips:
                enhanced += f"{tip}\n"
            return enhanced
        
        return instruction
    
    def _improve_efficiency(self, instruction: str, step: Dict[str, Any], context: Dict[str, Any]) -> str:
        """æå‡æ•ˆç‡"""
        efficiency_tips = []
        
        step_name = step.get('name', '').lower()
        if 'test' in step_name or 'verify' in step_name:
            efficiency_tips.append("âš¡ **æ•ˆç‡æç¤º**: è¿™æ˜¯æµ‹è¯•/éªŒè¯æ­¥éª¤ï¼Œå¯ä»¥å¹¶è¡Œæˆ–æ‰¹é‡æ‰§è¡Œ")
        
        if 'install' in step_name or 'setup' in step_name:
            efficiency_tips.append("ğŸ“¦ **æ•ˆç‡æç¤º**: å®‰è£…/é…ç½®ä»»åŠ¡ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜ä»¥é¿å…é‡å¤å·¥ä½œ")
        
        if efficiency_tips:
            enhanced = f"{instruction}\n\n"
            for tip in efficiency_tips:
                enhanced += f"{tip}\n"
            return enhanced
        
        return instruction
    
    def _optimize_clarity(self, instruction: str, step: Dict[str, Any]) -> str:
        """ä¼˜åŒ–æ¸…æ™°åº¦"""
        # å¦‚æœæŒ‡ä»¤å¤ªçŸ­ï¼Œæ·»åŠ æ›´è¯¦ç»†çš„è¯´æ˜
        if len(instruction) < 50:
            step_name = step.get('name', 'æœªçŸ¥æ­¥éª¤')
            step_desc = step.get('description', '')
            
            enhanced = f"**ä»»åŠ¡**: {instruction}\n\n"
            enhanced += f"**è¯¦ç»†è¯´æ˜**: æ‰§è¡Œ'{step_name}'æ­¥éª¤"
            if step_desc:
                enhanced += f"ï¼Œå…·ä½“è¦æ±‚ï¼š{step_desc}"
            enhanced += f"\n\n**æ‰§è¡Œæ ‡å‡†**: è¯·ç¡®ä¿ä»»åŠ¡å®Œæˆè´¨é‡ç¬¦åˆé¢„æœŸï¼Œå¹¶æä¾›æ¸…æ™°çš„æ‰§è¡Œç»“æœåé¦ˆã€‚"
            
            return enhanced
        
        return instruction
    
    def _add_dependency_awareness(self, instruction: str, analysis: Dict[str, Any]) -> str:
        """æ·»åŠ ä¾èµ–å…³ç³»æ„ŸçŸ¥"""
        dep_info = analysis['dependency_info']
        
        if dep_info['has_dependencies']:
            enhanced = f"{instruction}\n\n"
            enhanced += f"**ğŸ”— ä¾èµ–å…³ç³»æç¤º**: æ­¤ä»»åŠ¡ä¾èµ–äºå…¶ä»–æ­¥éª¤çš„å®ŒæˆçŠ¶æ€"
            
            if dep_info['blocking_dependencies']:
                enhanced += f"ï¼Œæ³¨æ„æ£€æŸ¥å‰ç½®æ¡ä»¶æ˜¯å¦æ»¡è¶³"
            
            enhanced += f"ã€‚è¯·ç¡®ä¿æŒ‰ç…§ä¾èµ–é¡ºåºæ‰§è¡Œã€‚"
            return enhanced
        
        return instruction
    
    def _assess_instruction_complexity(self, instruction: str) -> float:
        """è¯„ä¼°æŒ‡ä»¤å¤æ‚åº¦ (0.0-1.0)"""
        complexity_factors = 0.0
        
        # é•¿åº¦å› ç´ 
        if len(instruction) > 200:
            complexity_factors += 0.3
        elif len(instruction) > 100:
            complexity_factors += 0.2
        
        # æŠ€æœ¯æœ¯è¯­å› ç´ 
        tech_terms = ['API', 'database', 'config', 'install', 'deploy', 'test']
        tech_count = sum(1 for term in tech_terms if term.lower() in instruction.lower())
        complexity_factors += min(tech_count * 0.1, 0.3)
        
        # æ¡ä»¶è¯­å¥å› ç´ 
        conditions = ['if', 'when', 'unless', 'should', 'might']
        condition_count = sum(1 for cond in conditions if cond in instruction.lower())
        complexity_factors += min(condition_count * 0.1, 0.2)
        
        return min(complexity_factors, 1.0)
    
    def _assess_step_complexity(self, step: Dict[str, Any]) -> float:
        """è¯„ä¼°æ­¥éª¤å¤æ‚åº¦ (0.0-1.0)"""
        complexity = 0.0
        
        # æ­¥éª¤åç§°å¤æ‚åº¦
        step_name = step.get('name', '').lower()
        complex_words = ['configure', 'integrate', 'implement', 'deploy', 'optimize']
        if any(word in step_name for word in complex_words):
            complexity += 0.3
        
        # æ­¥éª¤æè¿°å¤æ‚åº¦
        description = step.get('description', '')
        if len(description) > 100:
            complexity += 0.2
        
        # é¢„æœŸè¾“å‡ºå¤æ‚åº¦
        expected_output = step.get('expected_output', '')
        if expected_output:
            complexity += 0.2
        
        # ä¾èµ–å…³ç³»å¤æ‚åº¦
        dependencies = step.get('dependencies', [])
        if len(dependencies) > 2:
            complexity += 0.3
        
        return min(complexity, 1.0)
    
    def _get_historical_errors(self, context: Dict[str, Any]) -> List[str]:
        """è·å–å†å²é”™è¯¯ä¿¡æ¯"""
        errors = []
        summary = context.get('summary', '')
        if 'é”™è¯¯' in summary or 'å¤±è´¥' in summary:
            errors.append('execution_error')
        return errors
    
    def _get_recent_failures(self, global_state: 'WorkflowState') -> List[str]:
        """è·å–è¿‘æœŸå¤±è´¥ä¿¡æ¯"""
        failures = []
        state_content = global_state.get_global_state()
        if 'å¤±è´¥' in state_content or 'é”™è¯¯' in state_content:
            failures.append('state_failure')
        return failures
    
    def _analyze_dependencies(self, step: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä¾èµ–å…³ç³»"""
        dependencies = step.get('dependencies', [])
        
        return {
            'has_dependencies': len(dependencies) > 0,
            'dependency_count': len(dependencies),
            'blocking_dependencies': len(dependencies) > 2,
        }
    
    def _calculate_optimization_confidence(self, analysis: Dict[str, Any], 
                                         optimization_types: List[InstructionOptimizationType]) -> float:
        """è®¡ç®—ä¼˜åŒ–ç½®ä¿¡åº¦"""
        if not optimization_types:
            return 0.0
        
        confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
        
        # åŸºäºåˆ†æç»“æœè°ƒæ•´ç½®ä¿¡åº¦
        if analysis['state_richness'] > 100:
            confidence += 0.2
        if analysis['context_richness'] > 200:
            confidence += 0.1
        if analysis['instruction_complexity'] < 0.5:
            confidence += 0.1
        
        # åŸºäºä¼˜åŒ–ç±»å‹æ•°é‡è°ƒæ•´
        confidence += min(len(optimization_types) * 0.05, 0.2)
        
        return min(confidence, 1.0)
    
    def _predict_improvement(self, analysis: Dict[str, Any], 
                           optimization_types: List[InstructionOptimizationType]) -> float:
        """é¢„æµ‹æ”¹è¿›ç¨‹åº¦"""
        if not optimization_types:
            return 0.0
        
        improvement = 0.3  # åŸºç¡€æ”¹è¿›
        
        # æ ¹æ®ä¼˜åŒ–ç±»å‹é¢„æµ‹æ”¹è¿›
        type_improvements = {
            InstructionOptimizationType.CONTEXT_ENHANCEMENT: 0.2,
            InstructionOptimizationType.ERROR_PREVENTION: 0.3,
            InstructionOptimizationType.EFFICIENCY_IMPROVEMENT: 0.15,
            InstructionOptimizationType.CLARITY_OPTIMIZATION: 0.1,
            InstructionOptimizationType.DEPENDENCY_AWARENESS: 0.1,
        }
        
        for opt_type in optimization_types:
            improvement += type_improvements.get(opt_type, 0.05)
        
        return min(improvement, 1.0)
    
    def _assess_optimization_risk(self, original: str, optimized: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°ä¼˜åŒ–é£é™©"""
        risk_factors = []
        risk_score = 0.0
        
        # é•¿åº¦å˜åŒ–é£é™©
        length_ratio = len(optimized) / len(original) if len(original) > 0 else 1.0
        if length_ratio > 3.0:
            risk_factors.append("æŒ‡ä»¤é•¿åº¦æ˜¾è‘—å¢åŠ ")
            risk_score += 0.2
        
        # å¤æ‚åº¦é£é™©
        if analysis['instruction_complexity'] > 0.7:
            risk_factors.append("åŸå§‹æŒ‡ä»¤å·²è¾ƒå¤æ‚")
            risk_score += 0.1
        
        # ç­–ç•¥é£é™©
        if self.strategy == OptimizationStrategy.AGGRESSIVE:
            risk_score += 0.1
        
        return {
            'risk_score': min(risk_score, 1.0),
            'risk_factors': risk_factors,
            'recommendation': 'proceed' if risk_score < 0.3 else 'caution' if risk_score < 0.6 else 'avoid'
        }
    
    def _generate_optimization_reasoning(self, optimization_types: List[InstructionOptimizationType], 
                                       analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼˜åŒ–ç†ç”±"""
        if not optimization_types:
            return "æ— éœ€ä¼˜åŒ–æˆ–æ— æ³•ç¡®å®šä¼˜åŒ–æ–¹æ¡ˆ"
        
        reasons = []
        
        type_reasons = {
            InstructionOptimizationType.CONTEXT_ENHANCEMENT: "ä¸°å¯Œçš„çŠ¶æ€ä¿¡æ¯å¯ç”¨äºå¢å¼ºä¸Šä¸‹æ–‡",
            InstructionOptimizationType.ERROR_PREVENTION: "å†å²é”™è¯¯æ¨¡å¼æç¤ºéœ€è¦é¢„é˜²æªæ–½",
            InstructionOptimizationType.EFFICIENCY_IMPROVEMENT: "å¯ä»¥é€šè¿‡ä¼˜åŒ–æå‡æ‰§è¡Œæ•ˆç‡",
            InstructionOptimizationType.CLARITY_OPTIMIZATION: "æŒ‡ä»¤è¿‡äºç®€æ´ï¼Œéœ€è¦æ¾„æ¸…",
            InstructionOptimizationType.DEPENDENCY_AWARENESS: "å­˜åœ¨ä¾èµ–å…³ç³»éœ€è¦æ˜ç¡®",
        }
        
        for opt_type in optimization_types:
            if opt_type in type_reasons:
                reasons.append(type_reasons[opt_type])
        
        return "ï¼›".join(reasons) + "ã€‚"
    
    def _get_applied_enhancements(self, optimization_types: List[InstructionOptimizationType]) -> List[str]:
        """è·å–åº”ç”¨çš„å¢å¼ºåŠŸèƒ½åˆ—è¡¨"""
        enhancements = []
        
        enhancement_names = {
            InstructionOptimizationType.CONTEXT_ENHANCEMENT: "ä¸Šä¸‹æ–‡ä¿¡æ¯å¢å¼º",
            InstructionOptimizationType.ERROR_PREVENTION: "é”™è¯¯é¢„é˜²æç¤º",
            InstructionOptimizationType.EFFICIENCY_IMPROVEMENT: "æ•ˆç‡æå‡å»ºè®®",
            InstructionOptimizationType.CLARITY_OPTIMIZATION: "æ¸…æ™°åº¦ä¼˜åŒ–",
            InstructionOptimizationType.DEPENDENCY_AWARENESS: "ä¾èµ–å…³ç³»æç¤º",
        }
        
        for opt_type in optimization_types:
            if opt_type in enhancement_names:
                enhancements.append(enhancement_names[opt_type])
        
        return enhancements
    
    def _update_optimization_stats(self, result: InstructionOptimizationResult) -> None:
        """æ›´æ–°ä¼˜åŒ–ç»Ÿè®¡"""
        # å¦‚æœæœ‰ä¼˜åŒ–ç±»å‹ï¼Œè®¤ä¸ºæ˜¯æˆåŠŸçš„ä¼˜åŒ–
        if result.optimization_types:
            self.optimization_stats['successful_optimizations'] += 1
        
        # æ›´æ–°ä¼˜åŒ–ç±»å‹ä½¿ç”¨ç»Ÿè®¡
        for opt_type in result.optimization_types:
            type_name = opt_type.value
            self.optimization_stats['optimization_types_used'][type_name] = \
                self.optimization_stats['optimization_types_used'].get(type_name, 0) + 1
        
        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        total_opts = self.optimization_stats['total_optimizations']
        current_avg_conf = self.optimization_stats['average_confidence']
        self.optimization_stats['average_confidence'] = \
            ((current_avg_conf * (total_opts - 1)) + result.confidence_score) / total_opts
        
        # æ›´æ–°å¹³å‡æ”¹è¿›åº¦
        current_avg_imp = self.optimization_stats['average_improvement']
        self.optimization_stats['average_improvement'] = \
            ((current_avg_imp * (total_opts - 1)) + result.predicted_improvement) / total_opts
    
    def get_optimization_statistics(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.optimization_stats['total_optimizations']
        successful = self.optimization_stats['successful_optimizations']
        
        return {
            'total_optimizations': total,
            'successful_optimizations': successful,
            'success_rate': successful / total if total > 0 else 0.0,
            'optimization_types_used': self.optimization_stats['optimization_types_used'].copy(),
            'average_confidence': self.optimization_stats['average_confidence'],
            'average_improvement': self.optimization_stats['average_improvement']
        }
    
    def reset_optimization_statistics(self) -> None:
        """é‡ç½®ä¼˜åŒ–ç»Ÿè®¡"""
        self.optimization_stats = {
            'total_optimizations': 0,
            'successful_optimizations': 0,
            'optimization_types_used': {},
            'average_confidence': 0.0,
            'average_improvement': 0.0
        }
        
        self.logger.info("æŒ‡ä»¤ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")


class StateCondition:
    """çŠ¶æ€æ¡ä»¶ç±» - è¡¨ç¤ºä¸€ä¸ªå¯è¯„ä¼°çš„çŠ¶æ€æ¡ä»¶"""
    
    def __init__(self, state_path: str, operator: ConditionOperator, 
                 expected_value: Any, description: str = ""):
        """
        åˆå§‹åŒ–çŠ¶æ€æ¡ä»¶
        
        Args:
            state_path: çŠ¶æ€è·¯å¾„ï¼Œå¦‚ 'data.user_approval' æˆ–ç›´æ¥çš„çŠ¶æ€é”®
            operator: æ¡ä»¶æ“ä½œç¬¦
            expected_value: é¢„æœŸå€¼
            description: æ¡ä»¶æè¿°
        """
        self.state_path = state_path
        self.operator = operator
        self.expected_value = expected_value
        self.description = description
    
    def evaluate(self, global_state: 'WorkflowState') -> Tuple[bool, Dict[str, Any]]:
        """
        è¯„ä¼°æ¡ä»¶
        
        Args:
            global_state: å…¨å±€å·¥ä½œæµçŠ¶æ€
            
        Returns:
            (æ˜¯å¦æ»¡è¶³æ¡ä»¶, è¯„ä¼°è¯¦æƒ…)
        """
        try:
            # è·å–çŠ¶æ€å€¼
            state_value = self._extract_state_value(global_state)
            
            # æ‰§è¡Œæ¡ä»¶è¯„ä¼°
            result = self._evaluate_condition(state_value)
            
            evaluation_details = {
                'state_path': self.state_path,
                'operator': self.operator.value,
                'expected_value': self.expected_value,
                'actual_value': state_value,
                'result': result,
                'description': self.description
            }
            
            return result, evaluation_details
            
        except Exception as e:
            logger.error(f"çŠ¶æ€æ¡ä»¶è¯„ä¼°å¤±è´¥: {e}")
            return False, {
                'state_path': self.state_path,
                'operator': self.operator.value,
                'error': str(e),
                'result': False
            }
    
    def _extract_state_value(self, global_state: 'WorkflowState') -> Any:
        """ä»å…¨å±€çŠ¶æ€ä¸­æå–å€¼"""
        state_content = global_state.get_global_state()
        
        if not state_content:
            return None
        
        # å¦‚æœæ˜¯ç®€å•çš„é”®æŸ¥æ‰¾
        if '.' not in self.state_path:
            # å°è¯•ç›´æ¥åŒ¹é…çŠ¶æ€å†…å®¹ä¸­çš„é”®å€¼å¯¹
            import re
            patterns = [
                rf'{re.escape(self.state_path)}\s*[:=]\s*([^\n,;]+)',  # key: value æˆ– key = value
                rf'\[{re.escape(self.state_path)}\]\s*([^\n,;]+)',    # [key] value
                rf'{re.escape(self.state_path)}\s*:\s*([^\n,;]+)'     # key: value
            ]
            
            for pattern in patterns:
                match = re.search(pattern, state_content, re.IGNORECASE)
                if match:
                    value_str = match.group(1).strip().strip('"\'')
                    return self._parse_value(value_str)
        
        # å¤æ‚è·¯å¾„è§£æï¼ˆå¦‚ data.user.approvalï¼‰
        path_parts = self.state_path.split('.')
        
        # å°è¯•ä»çŠ¶æ€å†…å®¹ä¸­è§£æåµŒå¥—ç»“æ„
        import json
        try:
            # å°è¯•è§£æä¸ºJSON
            state_data = json.loads(state_content)
            value = state_data
            for part in path_parts:
                value = value.get(part) if isinstance(value, dict) else None
                if value is None:
                    break
            return value
        except:
            pass
        
        # å›é€€ï¼šåœ¨çŠ¶æ€å†…å®¹ä¸­æŸ¥æ‰¾æ–‡æœ¬æ¨¡å¼
        for part in path_parts:
            if part.lower() in state_content.lower():
                # ç®€åŒ–å¤„ç†ï¼šå¦‚æœè·¯å¾„éƒ¨åˆ†å‡ºç°åœ¨çŠ¶æ€ä¸­ï¼Œè¿”å›True
                return True
        
        return None
    
    def _parse_value(self, value_str: str) -> Any:
        """è§£æå­—ç¬¦ä¸²å€¼ä¸ºé€‚å½“çš„ç±»å‹"""
        if not value_str:
            return None
        
        value_lower = value_str.lower()
        
        # å¸ƒå°”å€¼
        if value_lower in ['true', 'yes', 'æ˜¯', 'å·²å®Œæˆ', 'completed', 'success']:
            return True
        elif value_lower in ['false', 'no', 'å¦', 'æœªå®Œæˆ', 'pending', 'failed']:
            return False
        
        # æ•°å­—
        try:
            if '.' in value_str:
                return float(value_str)
            else:
                return int(value_str)
        except ValueError:
            pass
        
        # å­—ç¬¦ä¸²ï¼ˆä¿æŒåŸæ ·ï¼‰
        return value_str
    
    def _evaluate_condition(self, actual_value: Any) -> bool:
        """è¯„ä¼°å…·ä½“çš„æ¡ä»¶"""
        if actual_value is None:
            return self.operator in [ConditionOperator.IS_EMPTY, ConditionOperator.NOT_EQUALS]
        
        if self.operator == ConditionOperator.EQUALS:
            return actual_value == self.expected_value
        elif self.operator == ConditionOperator.NOT_EQUALS:
            return actual_value != self.expected_value
        elif self.operator == ConditionOperator.GREATER_THAN:
            return self._safe_compare(actual_value, self.expected_value, lambda a, b: a > b)
        elif self.operator == ConditionOperator.LESS_THAN:
            return self._safe_compare(actual_value, self.expected_value, lambda a, b: a < b)
        elif self.operator == ConditionOperator.GREATER_EQUAL:
            return self._safe_compare(actual_value, self.expected_value, lambda a, b: a >= b)
        elif self.operator == ConditionOperator.LESS_EQUAL:
            return self._safe_compare(actual_value, self.expected_value, lambda a, b: a <= b)
        elif self.operator == ConditionOperator.CONTAINS:
            return self._safe_contains(actual_value, self.expected_value)
        elif self.operator == ConditionOperator.NOT_CONTAINS:
            return not self._safe_contains(actual_value, self.expected_value)
        elif self.operator == ConditionOperator.STARTS_WITH:
            return str(actual_value).startswith(str(self.expected_value))
        elif self.operator == ConditionOperator.ENDS_WITH:
            return str(actual_value).endswith(str(self.expected_value))
        elif self.operator == ConditionOperator.IN:
            return actual_value in self.expected_value if hasattr(self.expected_value, '__contains__') else False
        elif self.operator == ConditionOperator.NOT_IN:
            return actual_value not in self.expected_value if hasattr(self.expected_value, '__contains__') else True
        elif self.operator == ConditionOperator.IS_EMPTY:
            return not actual_value or (isinstance(actual_value, str) and not actual_value.strip())
        elif self.operator == ConditionOperator.IS_NOT_EMPTY:
            return bool(actual_value) and not (isinstance(actual_value, str) and not actual_value.strip())
        elif self.operator == ConditionOperator.REGEX_MATCH:
            import re
            try:
                return bool(re.search(str(self.expected_value), str(actual_value)))
            except:
                return False
        
        return False
    
    def _safe_compare(self, a: Any, b: Any, comparison_func) -> bool:
        """å®‰å…¨çš„æ•°å€¼æ¯”è¾ƒ"""
        try:
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—è¿›è¡Œæ¯”è¾ƒ
            if isinstance(a, str) and isinstance(b, str):
                try:
                    a_num = float(a)
                    b_num = float(b)
                    return comparison_func(a_num, b_num)
                except ValueError:
                    pass
            
            return comparison_func(a, b)
        except (TypeError, ValueError):
            return False
    
    def _safe_contains(self, container: Any, item: Any) -> bool:
        """å®‰å…¨çš„åŒ…å«æ£€æŸ¥"""
        try:
            if hasattr(container, '__contains__'):
                return item in container
            else:
                return str(item) in str(container)
        except:
            return False


class DecisionNode:
    """å†³ç­–èŠ‚ç‚¹ç±» - åŸºäºçŠ¶æ€è¿›è¡Œæ¡ä»¶å†³ç­–"""
    
    def __init__(self, node_id: str, node_type: DecisionNodeType, 
                 description: str = ""):
        """
        åˆå§‹åŒ–å†³ç­–èŠ‚ç‚¹
        
        Args:
            node_id: èŠ‚ç‚¹ID
            node_type: èŠ‚ç‚¹ç±»å‹
            description: èŠ‚ç‚¹æè¿°
        """
        self.node_id = node_id
        self.node_type = node_type
        self.description = description
        self.conditions: List[StateCondition] = []
        self.decision_paths: Dict[str, str] = {}  # æ¡ä»¶ç»“æœ -> ä¸‹ä¸€æ­¥ID
        self.default_path: Optional[str] = None
        self.logic_operator = "AND"  # AND æˆ– OR
    
    def add_condition(self, condition: StateCondition) -> None:
        """æ·»åŠ æ¡ä»¶"""
        self.conditions.append(condition)
    
    def add_decision_path(self, condition_result: str, next_step_id: str) -> None:
        """æ·»åŠ å†³ç­–è·¯å¾„"""
        self.decision_paths[condition_result] = next_step_id
    
    def set_default_path(self, next_step_id: str) -> None:
        """è®¾ç½®é»˜è®¤è·¯å¾„"""
        self.default_path = next_step_id
    
    def set_logic_operator(self, operator: str) -> None:
        """è®¾ç½®é€»è¾‘æ“ä½œç¬¦ï¼ˆAND/ORï¼‰"""
        if operator.upper() in ["AND", "OR"]:
            self.logic_operator = operator.upper()
    
    def evaluate_decision(self, global_state: 'WorkflowState') -> DecisionResult:
        """
        è¯„ä¼°å†³ç­–
        
        Args:
            global_state: å…¨å±€å·¥ä½œæµçŠ¶æ€
            
        Returns:
            å†³ç­–ç»“æœ
        """
        try:
            evaluated_conditions = []
            state_variables_used = []
            
            # è¯„ä¼°æ‰€æœ‰æ¡ä»¶
            condition_results = []
            for condition in self.conditions:
                result, details = condition.evaluate(global_state)
                condition_results.append(result)
                evaluated_conditions.append(details)
                state_variables_used.append(condition.state_path)
            
            # æ ¹æ®é€»è¾‘æ“ä½œç¬¦ç»„åˆç»“æœ
            if self.logic_operator == "AND":
                overall_result = all(condition_results) if condition_results else False
            else:  # OR
                overall_result = any(condition_results) if condition_results else False
            
            # ç¡®å®šä¸‹ä¸€æ­¥
            next_step_id = None
            decision_reason = ""
            confidence = 0.0
            
            if self.node_type == DecisionNodeType.CONDITIONAL:
                if overall_result:
                    next_step_id = self.decision_paths.get("true", self.default_path)
                    decision_reason = f"æ¡ä»¶è¯„ä¼°ä¸ºçœŸï¼Œæ‰§è¡ŒçœŸåˆ†æ”¯"
                    confidence = 0.9
                else:
                    next_step_id = self.decision_paths.get("false", self.default_path)
                    decision_reason = f"æ¡ä»¶è¯„ä¼°ä¸ºå‡ï¼Œæ‰§è¡Œå‡åˆ†æ”¯"
                    confidence = 0.9
            
            elif self.node_type == DecisionNodeType.VALIDATION:
                if overall_result:
                    next_step_id = self.decision_paths.get("valid", self.default_path)
                    decision_reason = f"éªŒè¯é€šè¿‡ï¼Œç»§ç»­æ‰§è¡Œ"
                    confidence = 0.95
                else:
                    next_step_id = self.decision_paths.get("invalid", self.default_path)
                    decision_reason = f"éªŒè¯å¤±è´¥ï¼Œæ‰§è¡Œé”™è¯¯å¤„ç†"
                    confidence = 0.95
            
            elif self.node_type == DecisionNodeType.SWITCH:
                # å¯¹äºswitchç±»å‹ï¼ŒæŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸ºtrueçš„æ¡ä»¶å¯¹åº”çš„è·¯å¾„
                for i, result in enumerate(condition_results):
                    if result:
                        condition_key = f"case_{i}"
                        next_step_id = self.decision_paths.get(condition_key, self.default_path)
                        decision_reason = f"åŒ¹é…æ¡ä»¶ {i+1}ï¼Œæ‰§è¡Œå¯¹åº”åˆ†æ”¯"
                        confidence = 0.85
                        break
                
                if next_step_id is None:
                    next_step_id = self.default_path
                    decision_reason = f"æ— åŒ¹é…æ¡ä»¶ï¼Œæ‰§è¡Œé»˜è®¤åˆ†æ”¯"
                    confidence = 0.8
            
            else:
                # å…¶ä»–ç±»å‹ä½¿ç”¨åŸºæœ¬çš„æ¡ä»¶é€»è¾‘
                next_step_id = self.decision_paths.get("true" if overall_result else "false", self.default_path)
                decision_reason = f"åŸºäº{self.node_type.value}ç±»å‹çš„å†³ç­–ç»“æœ"
                confidence = 0.8
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            if next_step_id is None:
                next_step_id = self.default_path
                decision_reason += " (ä½¿ç”¨é»˜è®¤è·¯å¾„)"
                confidence = max(0.5, confidence - 0.2)
            
            return DecisionResult(
                next_step_id=next_step_id,
                decision_made=next_step_id is not None,
                decision_reason=decision_reason,
                evaluated_conditions=evaluated_conditions,
                state_variables_used=state_variables_used,
                confidence=confidence,
                additional_actions=[]
            )
            
        except Exception as e:
            logger.error(f"å†³ç­–èŠ‚ç‚¹è¯„ä¼°å¤±è´¥: {e}")
            return DecisionResult(
                next_step_id=self.default_path,
                decision_made=False,
                decision_reason=f"å†³ç­–è¯„ä¼°å‡ºé”™: {str(e)}",
                evaluated_conditions=[],
                state_variables_used=[],
                confidence=0.0,
                additional_actions=["æ£€æŸ¥å†³ç­–èŠ‚ç‚¹é…ç½®", "éªŒè¯çŠ¶æ€æ•°æ®æ ¼å¼"]
            )


class StateAwareDecisionManager:
    """çŠ¶æ€æ„ŸçŸ¥å†³ç­–ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å†³ç­–ç®¡ç†å™¨"""
        self.decision_nodes: Dict[str, DecisionNode] = {}
        self.decision_statistics = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'failed_decisions': 0,
            'average_confidence': 0.0,
            'decision_types_used': {},
            'most_used_variables': {}
        }
    
    def register_decision_node(self, node: DecisionNode) -> None:
        """æ³¨å†Œå†³ç­–èŠ‚ç‚¹"""
        self.decision_nodes[node.node_id] = node
        logger.info(f"å†³ç­–èŠ‚ç‚¹å·²æ³¨å†Œ: {node.node_id} ({node.node_type.value})")
    
    def create_conditional_node(self, node_id: str, condition: StateCondition, 
                              true_step: str, false_step: str, description: str = "") -> DecisionNode:
        """åˆ›å»ºæ¡ä»¶å†³ç­–èŠ‚ç‚¹çš„å¿«æ·æ–¹æ³•"""
        node = DecisionNode(node_id, DecisionNodeType.CONDITIONAL, description)
        node.add_condition(condition)
        node.add_decision_path("true", true_step)
        node.add_decision_path("false", false_step)
        self.register_decision_node(node)
        return node
    
    def create_validation_node(self, node_id: str, condition: StateCondition,
                             valid_step: str, invalid_step: str, description: str = "") -> DecisionNode:
        """åˆ›å»ºéªŒè¯å†³ç­–èŠ‚ç‚¹çš„å¿«æ·æ–¹æ³•"""
        node = DecisionNode(node_id, DecisionNodeType.VALIDATION, description)
        node.add_condition(condition)
        node.add_decision_path("valid", valid_step)
        node.add_decision_path("invalid", invalid_step)
        self.register_decision_node(node)
        return node
    
    def evaluate_decision(self, node_id: str, global_state: 'WorkflowState') -> DecisionResult:
        """
        è¯„ä¼°æŒ‡å®šå†³ç­–èŠ‚ç‚¹
        
        Args:
            node_id: å†³ç­–èŠ‚ç‚¹ID
            global_state: å…¨å±€å·¥ä½œæµçŠ¶æ€
            
        Returns:
            å†³ç­–ç»“æœ
        """
        if node_id not in self.decision_nodes:
            logger.error(f"å†³ç­–èŠ‚ç‚¹ä¸å­˜åœ¨: {node_id}")
            return DecisionResult(
                next_step_id=None,
                decision_made=False,
                decision_reason=f"å†³ç­–èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨",
                evaluated_conditions=[],
                state_variables_used=[],
                confidence=0.0,
                additional_actions=["æ£€æŸ¥å†³ç­–èŠ‚ç‚¹é…ç½®"]
            )
        
        node = self.decision_nodes[node_id]
        result = node.evaluate_decision(global_state)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._update_decision_statistics(node, result)
        
        logger.info(f"å†³ç­–èŠ‚ç‚¹ {node_id} è¯„ä¼°å®Œæˆ: {result.next_step_id} (ç½®ä¿¡åº¦: {result.confidence:.2f})")
        
        return result
    
    def list_decision_nodes(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å†³ç­–èŠ‚ç‚¹çš„ä¿¡æ¯"""
        nodes_info = []
        for node_id, node in self.decision_nodes.items():
            nodes_info.append({
                'node_id': node_id,
                'node_type': node.node_type.value,
                'description': node.description,
                'condition_count': len(node.conditions),
                'decision_paths': node.decision_paths,
                'default_path': node.default_path,
                'logic_operator': node.logic_operator
            })
        return nodes_info
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """è·å–å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        return self.decision_statistics.copy()
    
    def reset_decision_statistics(self) -> None:
        """é‡ç½®å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        self.decision_statistics = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'failed_decisions': 0,
            'average_confidence': 0.0,
            'decision_types_used': {},
            'most_used_variables': {}
        }
        logger.info("å†³ç­–ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def _update_decision_statistics(self, node: DecisionNode, result: DecisionResult) -> None:
        """æ›´æ–°å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        self.decision_statistics['total_decisions'] += 1
        
        if result.decision_made:
            self.decision_statistics['successful_decisions'] += 1
        else:
            self.decision_statistics['failed_decisions'] += 1
        
        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        total = self.decision_statistics['total_decisions']
        current_avg = self.decision_statistics['average_confidence']
        new_avg = (current_avg * (total - 1) + result.confidence) / total
        self.decision_statistics['average_confidence'] = new_avg
        
        # æ›´æ–°èŠ‚ç‚¹ç±»å‹ä½¿ç”¨ç»Ÿè®¡
        node_type = node.node_type.value
        if node_type not in self.decision_statistics['decision_types_used']:
            self.decision_statistics['decision_types_used'][node_type] = 0
        self.decision_statistics['decision_types_used'][node_type] += 1
        
        # æ›´æ–°å˜é‡ä½¿ç”¨ç»Ÿè®¡
        for var in result.state_variables_used:
            if var not in self.decision_statistics['most_used_variables']:
                self.decision_statistics['most_used_variables'][var] = 0
            self.decision_statistics['most_used_variables'][var] += 1


class WorkflowErrorType(Enum):
    """å·¥ä½œæµé”™è¯¯ç±»å‹æšä¸¾"""
    API_ERROR = "api_error"                       # APIè°ƒç”¨é”™è¯¯
    TIMEOUT_ERROR = "timeout_error"               # è¶…æ—¶é”™è¯¯
    VALIDATION_ERROR = "validation_error"         # éªŒè¯é”™è¯¯
    FILE_ERROR = "file_error"                     # æ–‡ä»¶æ“ä½œé”™è¯¯
    DATABASE_ERROR = "database_error"             # æ•°æ®åº“é”™è¯¯
    NETWORK_ERROR = "network_error"               # ç½‘ç»œé”™è¯¯
    AUTHENTICATION_ERROR = "authentication_error" # è®¤è¯é”™è¯¯
    PERMISSION_ERROR = "permission_error"         # æƒé™é”™è¯¯
    CONFIGURATION_ERROR = "configuration_error"   # é…ç½®é”™è¯¯
    AGENT_EXECUTION_ERROR = "agent_execution_error" # ä»£ç†æ‰§è¡Œé”™è¯¯
    UNKNOWN_ERROR = "unknown_error"               # æœªçŸ¥é”™è¯¯


class WorkflowErrorContext:
    """å·¥ä½œæµé”™è¯¯ä¸Šä¸‹æ–‡"""
    
    def __init__(self, error: Exception, error_type: WorkflowErrorType, step: Dict[str, Any], 
                 global_state: 'WorkflowState', execution_context: Dict[str, Any] = None):
        self.error = error
        self.error_type = error_type
        self.step = step
        self.global_state = global_state
        self.execution_context = execution_context or {}
        self.timestamp = dt.now()
        
        # æå–é”™è¯¯è¯¦ç»†ä¿¡æ¯
        self.error_message = str(error)
        self.error_class = error.__class__.__name__
        self.step_id = step.get('id', 'unknown')
        self.step_name = step.get('name', 'Unknown Step')
        self.agent_name = step.get('agent_name', 'unknown')
        
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'error_type': self.error_type.value,
            'error_class': self.error_class,
            'error_message': self.error_message,
            'step_id': self.step_id,
            'step_name': self.step_name,
            'agent_name': self.agent_name,
            'timestamp': self.timestamp.isoformat(),
            'global_state_summary': self.global_state.get_state_summary() if self.global_state else 'N/A',
            'execution_context': self.execution_context
        }


class StateAwareErrorHandler(ABC):
    """çŠ¶æ€æ„ŸçŸ¥é”™è¯¯å¤„ç†å™¨çš„æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def can_handle(self, error_context: WorkflowErrorContext) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†æŒ‡å®šçš„é”™è¯¯ä¸Šä¸‹æ–‡
        
        Args:
            error_context: é”™è¯¯ä¸Šä¸‹æ–‡
            
        Returns:
            bool: æ˜¯å¦èƒ½å¤„ç†
        """
        pass
    
    @abstractmethod
    def handle_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """
        å¤„ç†é”™è¯¯
        
        Args:
            error_context: é”™è¯¯ä¸Šä¸‹æ–‡
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…å«recovery_action, new_state, retry_possibleç­‰
        """
        pass
    
    @abstractmethod
    def get_priority(self) -> int:
        """
        è·å–å¤„ç†å™¨ä¼˜å…ˆçº§
        
        Returns:
            int: ä¼˜å…ˆçº§æ•°å­—ï¼Œæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
        """
        pass


class GenericErrorHandler(StateAwareErrorHandler):
    """é€šç”¨é”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.handled_errors = []
        self.recovery_strategies = {
            WorkflowErrorType.API_ERROR: self._handle_api_error,
            WorkflowErrorType.TIMEOUT_ERROR: self._handle_timeout_error,
            WorkflowErrorType.VALIDATION_ERROR: self._handle_validation_error,
            WorkflowErrorType.FILE_ERROR: self._handle_file_error,
            WorkflowErrorType.DATABASE_ERROR: self._handle_database_error,
            WorkflowErrorType.NETWORK_ERROR: self._handle_network_error,
            WorkflowErrorType.AUTHENTICATION_ERROR: self._handle_auth_error,
            WorkflowErrorType.PERMISSION_ERROR: self._handle_permission_error,
            WorkflowErrorType.CONFIGURATION_ERROR: self._handle_config_error,
            WorkflowErrorType.AGENT_EXECUTION_ERROR: self._handle_agent_error,
            WorkflowErrorType.UNKNOWN_ERROR: self._handle_unknown_error
        }
    
    def can_handle(self, error_context: WorkflowErrorContext) -> bool:
        """é€šç”¨å¤„ç†å™¨å¯ä»¥å¤„ç†æ‰€æœ‰ç±»å‹çš„é”™è¯¯"""
        return True
    
    def get_priority(self) -> int:
        """é€šç”¨å¤„ç†å™¨ä¼˜å…ˆçº§æœ€ä½"""
        return 1000
    
    def handle_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†é”™è¯¯"""
        # è®°å½•é”™è¯¯
        self.handled_errors.append(error_context)
        
        # æ ¹æ®é”™è¯¯ç±»å‹é€‰æ‹©å¤„ç†ç­–ç•¥
        handler_func = self.recovery_strategies.get(
            error_context.error_type, 
            self._handle_unknown_error
        )
        
        try:
            result = handler_func(error_context)
            
            # æ ‡è®°é”™è¯¯å·²è¢«å¤„ç†
            result['handled'] = True
            result['error_type'] = error_context.error_type.value
            result['handler'] = self.__class__.__name__
            result['message'] = f"é”™è¯¯å·²è¢« {self.__class__.__name__} å¤„ç†: {error_context.error_type.value}"
            
            # æ›´æ–°å…¨å±€çŠ¶æ€
            if result.get('new_state'):
                error_context.global_state.set_global_state(
                    result['new_state'], 
                    f"error_handler_{error_context.error_type.value}"
                )
            
            return result
            
        except Exception as handler_error:
            logger.error(f"é”™è¯¯å¤„ç†å™¨è‡ªèº«å‘ç”Ÿé”™è¯¯: {handler_error}")
            return self._create_fallback_result(error_context, handler_error)
    
    def _handle_api_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†APIé”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        # åˆ†æAPIé”™è¯¯
        error_msg = error_context.error_message.lower()
        if 'timeout' in error_msg or 'connection' in error_msg:
            recovery_action = 'retry_with_backoff'
            new_state = f"{current_state}\\n[é”™è¯¯æ¢å¤] APIè¿æ¥é—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚"
        elif 'unauthorized' in error_msg or '401' in error_msg:
            recovery_action = 'refresh_auth'
            new_state = f"{current_state}\\n[é”™è¯¯æ¢å¤] APIè®¤è¯å¤±è´¥ï¼Œéœ€è¦åˆ·æ–°è®¤è¯ä»¤ç‰Œã€‚"
        elif 'rate limit' in error_msg or '429' in error_msg:
            recovery_action = 'wait_and_retry'
            new_state = f"{current_state}\\n[é”™è¯¯æ¢å¤] APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œéœ€è¦ç­‰å¾…åé‡è¯•ã€‚"
        else:
            recovery_action = 'check_api_params'
            new_state = f"{current_state}\\n[é”™è¯¯æ¢å¤] APIè°ƒç”¨å‚æ•°å¯èƒ½æœ‰è¯¯ï¼Œéœ€è¦æ£€æŸ¥è¯·æ±‚å‚æ•°ã€‚"
        
        return {
            'recovery_action': recovery_action,
            'new_state': new_state,
            'retry_possible': True,
            'suggested_delay': 5.0,
            'error_analysis': f"APIé”™è¯¯åˆ†æ: {error_context.error_message}"
        }
    
    def _handle_timeout_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†è¶…æ—¶é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'retry_with_longer_timeout',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] æ“ä½œè¶…æ—¶ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´åé‡è¯•ã€‚",
            'retry_possible': True,
            'suggested_delay': 10.0,
            'timeout_multiplier': 2.0,
            'error_analysis': f"è¶…æ—¶é”™è¯¯: {error_context.step_name}æ‰§è¡Œè¶…æ—¶"
        }
    
    def _handle_validation_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†éªŒè¯é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'fix_input_validation',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] è¾“å…¥éªŒè¯å¤±è´¥: {error_context.error_message}ã€‚éœ€è¦æ£€æŸ¥è¾“å…¥å‚æ•°æ ¼å¼ã€‚",
            'retry_possible': True,
            'suggested_delay': 0.0,
            'error_analysis': f"éªŒè¯é”™è¯¯: è¾“å…¥å‚æ•°ä¸ç¬¦åˆè¦æ±‚"
        }
    
    def _handle_file_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†æ–‡ä»¶é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        error_msg = error_context.error_message.lower()
        
        if 'not found' in error_msg or 'no such file' in error_msg:
            recovery_action = 'create_missing_file'
            analysis = "æ–‡ä»¶ä¸å­˜åœ¨"
        elif 'permission denied' in error_msg:
            recovery_action = 'fix_file_permissions'
            analysis = "æ–‡ä»¶æƒé™ä¸è¶³"
        elif 'disk full' in error_msg or 'no space' in error_msg:
            recovery_action = 'clean_disk_space'
            analysis = "ç£ç›˜ç©ºé—´ä¸è¶³"
        else:
            recovery_action = 'check_file_system'
            analysis = "æ–‡ä»¶ç³»ç»Ÿé”™è¯¯"
        
        return {
            'recovery_action': recovery_action,
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] æ–‡ä»¶æ“ä½œå¤±è´¥: {analysis}ã€‚{error_context.error_message}",
            'retry_possible': True,
            'suggested_delay': 2.0,
            'error_analysis': f"æ–‡ä»¶é”™è¯¯: {analysis}"
        }
    
    def _handle_database_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†æ•°æ®åº“é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'check_database_connection',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] æ•°æ®åº“æ“ä½œå¤±è´¥: {error_context.error_message}ã€‚æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œæƒé™ã€‚",
            'retry_possible': True,
            'suggested_delay': 3.0,
            'error_analysis': f"æ•°æ®åº“é”™è¯¯: è¿æ¥æˆ–æŸ¥è¯¢å¤±è´¥"
        }
    
    def _handle_network_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†ç½‘ç»œé”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'retry_with_backoff',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œçŠ¶æ€åé‡è¯•ã€‚",
            'retry_possible': True,
            'suggested_delay': 8.0,
            'error_analysis': f"ç½‘ç»œé”™è¯¯: {error_context.error_message}"
        }
    
    def _handle_auth_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†è®¤è¯é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'refresh_credentials',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] è®¤è¯å¤±è´¥ï¼Œéœ€è¦åˆ·æ–°æˆ–é‡æ–°è·å–è®¤è¯å‡­æ®ã€‚",
            'retry_possible': True,
            'suggested_delay': 1.0,
            'error_analysis': f"è®¤è¯é”™è¯¯: å‡­æ®æ— æ•ˆæˆ–è¿‡æœŸ"
        }
    
    def _handle_permission_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†æƒé™é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'escalate_permissions',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] æƒé™ä¸è¶³ï¼Œéœ€è¦æå‡æƒé™æˆ–è”ç³»ç®¡ç†å‘˜ã€‚",
            'retry_possible': False,
            'suggested_delay': 0.0,
            'error_analysis': f"æƒé™é”™è¯¯: æ“ä½œè¢«æ‹’ç»"
        }
    
    def _handle_config_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†é…ç½®é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'fix_configuration',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] é…ç½®é”™è¯¯: {error_context.error_message}ã€‚éœ€è¦æ£€æŸ¥å’Œä¿®æ­£é…ç½®æ–‡ä»¶ã€‚",
            'retry_possible': True,
            'suggested_delay': 1.0,
            'error_analysis': f"é…ç½®é”™è¯¯: é…ç½®å‚æ•°æ— æ•ˆ"
        }
    
    def _handle_agent_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†ä»£ç†æ‰§è¡Œé”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'retry_with_different_agent',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] ä»£ç†æ‰§è¡Œå¤±è´¥: {error_context.agent_name}æ— æ³•å®Œæˆä»»åŠ¡ã€‚è€ƒè™‘ä½¿ç”¨å¤‡ç”¨ä»£ç†æˆ–è°ƒæ•´ä»»åŠ¡å‚æ•°ã€‚",
            'retry_possible': True,
            'suggested_delay': 2.0,
            'error_analysis': f"ä»£ç†é”™è¯¯: {error_context.agent_name}æ‰§è¡Œå¤±è´¥"
        }
    
    def _handle_unknown_error(self, error_context: WorkflowErrorContext) -> Dict[str, Any]:
        """å¤„ç†æœªçŸ¥é”™è¯¯"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'manual_intervention',
            'new_state': f"{current_state}\\n[é”™è¯¯æ¢å¤] æœªçŸ¥é”™è¯¯: {error_context.error_message}ã€‚éœ€è¦äººå·¥å¹²é¢„è¿›è¡Œè¯Šæ–­ã€‚",
            'retry_possible': False,
            'suggested_delay': 0.0,
            'error_analysis': f"æœªçŸ¥é”™è¯¯: {error_context.error_class}"
        }
    
    def _create_fallback_result(self, error_context: WorkflowErrorContext, handler_error: Exception) -> Dict[str, Any]:
        """åˆ›å»ºå›é€€ç»“æœ"""
        current_state = error_context.global_state.get_global_state()
        
        return {
            'recovery_action': 'error_handler_failed',
            'new_state': f"{current_state}\\n[ç³»ç»Ÿé”™è¯¯] é”™è¯¯å¤„ç†å™¨å¤±è´¥: {str(handler_error)}ã€‚åŸå§‹é”™è¯¯: {error_context.error_message}",
            'retry_possible': False,
            'suggested_delay': 0.0,
            'error_analysis': f"é”™è¯¯å¤„ç†å™¨æ•…éšœ: {str(handler_error)}"
        }
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """è·å–é”™è¯¯å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        if not self.handled_errors:
            return {'total_errors': 0}
        
        error_types = {}
        for error_ctx in self.handled_errors:
            error_type = error_ctx.error_type.value
            error_types[error_type] = error_types.get(error_type, 0) + 1
        
        return {
            'total_errors': len(self.handled_errors),
            'error_types': error_types,
            'recent_errors': [ctx.to_dict() for ctx in self.handled_errors[-5:]]  # æœ€è¿‘5ä¸ªé”™è¯¯
        }


class WorkflowErrorDispatcher:
    """å·¥ä½œæµé”™è¯¯åˆ†å‘å™¨"""
    
    def __init__(self):
        self.error_handlers: List[StateAwareErrorHandler] = []
        self.error_type_mapping = {
            # Exceptionç±»ååˆ°WorkflowErrorTypeçš„æ˜ å°„
            'ConnectionError': WorkflowErrorType.NETWORK_ERROR,
            'TimeoutError': WorkflowErrorType.TIMEOUT_ERROR,
            'Timeout': WorkflowErrorType.TIMEOUT_ERROR,
            'HTTPError': WorkflowErrorType.API_ERROR,
            'RequestException': WorkflowErrorType.API_ERROR,
            'FileNotFoundError': WorkflowErrorType.FILE_ERROR,
            'PermissionError': WorkflowErrorType.PERMISSION_ERROR,
            'ValidationError': WorkflowErrorType.VALIDATION_ERROR,
            'ValueError': WorkflowErrorType.VALIDATION_ERROR,
            'AuthenticationError': WorkflowErrorType.AUTHENTICATION_ERROR,
            'DatabaseError': WorkflowErrorType.DATABASE_ERROR,
            'ConfigurationError': WorkflowErrorType.CONFIGURATION_ERROR,
        }
        
        # æ³¨å†Œé»˜è®¤çš„é€šç”¨é”™è¯¯å¤„ç†å™¨
        self.register_handler(GenericErrorHandler())
    
    def register_handler(self, handler: StateAwareErrorHandler) -> None:
        """æ³¨å†Œé”™è¯¯å¤„ç†å™¨"""
        self.error_handlers.append(handler)
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        self.error_handlers.sort(key=lambda h: h.get_priority())
    
    def classify_error(self, error: Exception) -> WorkflowErrorType:
        """åˆ†ç±»é”™è¯¯ç±»å‹"""
        error_class_name = error.__class__.__name__
        
        # é¦–å…ˆå°è¯•ç›´æ¥åŒ¹é…
        if error_class_name in self.error_type_mapping:
            return self.error_type_mapping[error_class_name]
        
        # åŸºäºé”™è¯¯æ¶ˆæ¯è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        error_msg = str(error).lower()
        
        if any(keyword in error_msg for keyword in ['timeout', 'timed out']):
            return WorkflowErrorType.TIMEOUT_ERROR
        elif any(keyword in error_msg for keyword in ['connection', 'network', 'unreachable']):
            return WorkflowErrorType.NETWORK_ERROR
        elif any(keyword in error_msg for keyword in ['unauthorized', 'authentication', 'login']):
            return WorkflowErrorType.AUTHENTICATION_ERROR
        elif any(keyword in error_msg for keyword in ['permission denied', 'forbidden', 'access denied']):
            return WorkflowErrorType.PERMISSION_ERROR
        elif any(keyword in error_msg for keyword in ['file not found', 'no such file']):
            return WorkflowErrorType.FILE_ERROR
        elif any(keyword in error_msg for keyword in ['database', 'sql', 'query']):
            return WorkflowErrorType.DATABASE_ERROR
        elif any(keyword in error_msg for keyword in ['api', 'http', 'rest']):
            return WorkflowErrorType.API_ERROR
        elif any(keyword in error_msg for keyword in ['config', 'configuration', 'setting']):
            return WorkflowErrorType.CONFIGURATION_ERROR
        elif any(keyword in error_msg for keyword in ['validation', 'invalid', 'format']):
            return WorkflowErrorType.VALIDATION_ERROR
        else:
            return WorkflowErrorType.UNKNOWN_ERROR
    
    def dispatch_error(self, error: Exception, step: Dict[str, Any], 
                      global_state: 'WorkflowState', execution_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ†å‘é”™è¯¯åˆ°é€‚å½“çš„å¤„ç†å™¨"""
        # åˆ†ç±»é”™è¯¯
        error_type = self.classify_error(error)
        
        # åˆ›å»ºé”™è¯¯ä¸Šä¸‹æ–‡
        error_context = WorkflowErrorContext(
            error=error,
            error_type=error_type,
            step=step,
            global_state=global_state,
            execution_context=execution_context
        )
        
        # å¯»æ‰¾èƒ½å¤„ç†æ­¤é”™è¯¯çš„å¤„ç†å™¨
        for handler in self.error_handlers:
            if handler.can_handle(error_context):
                try:
                    result = handler.handle_error(error_context)
                    logger.info(f"é”™è¯¯å·²è¢« {handler.__class__.__name__} å¤„ç†: {error_type.value}")
                    return result
                except Exception as handler_error:
                    logger.error(f"é”™è¯¯å¤„ç†å™¨ {handler.__class__.__name__} æ‰§è¡Œå¤±è´¥: {handler_error}")
                    continue
        
        # å¦‚æœæ²¡æœ‰å¤„ç†å™¨èƒ½å¤„ç†ï¼Œè¿”å›é»˜è®¤ç»“æœ
        logger.error(f"æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„é”™è¯¯å¤„ç†å™¨å¤„ç†é”™è¯¯: {error_type.value}")
        return {
            'handled': False,
            'error_type': error_type.value,
            'handler': 'no_handler',
            'message': f"æ— æ³•å¤„ç†çš„é”™è¯¯: {error_type.value}",
            'recovery_action': 'no_handler_available',
            'new_state': f"{global_state.get_global_state()}\\n[ç³»ç»Ÿé”™è¯¯] æ— æ³•å¤„ç†çš„é”™è¯¯: {str(error)}",
            'retry_possible': False,
            'suggested_delay': 0.0,
            'error_analysis': f"æ— å¤„ç†å™¨: {error.__class__.__name__}"
        }


class FallbackStrategy(Enum):
    """å›é€€ç­–ç•¥æšä¸¾"""
    RETRY_SIMPLIFIED = "retry_simplified"          # ä½¿ç”¨ç®€åŒ–æç¤ºé‡è¯•
    TEMPLATE_BASED = "template_based"              # ä½¿ç”¨æ¨¡æ¿åŒ–é»˜è®¤çŠ¶æ€
    RULE_BASED = "rule_based"                      # ä½¿ç”¨åŸºäºè§„åˆ™çš„é€»è¾‘
    NOTIFY_OPERATOR = "notify_operator"            # é€šçŸ¥äººå·¥æ“ä½œå‘˜
    MINIMAL_STATE = "minimal_state"                # ç”Ÿæˆæœ€å°çŠ¶æ€æè¿°


class FallbackStateGenerator:
    """å›é€€çŠ¶æ€ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.FallbackStateGenerator")
        
        # é¢„å®šä¹‰çš„çŠ¶æ€æ¨¡æ¿
        self.success_templates = [
            "æ­¥éª¤ '{step_name}' æ‰§è¡Œå®Œæˆ",
            "ä»»åŠ¡å¤„ç†æˆåŠŸï¼Œå·²å®Œæˆç›¸å…³æ“ä½œ",
            "ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå½“å‰æ“ä½œå·²å®Œæˆ"
        ]
        
        self.error_templates = [
            "æ­¥éª¤ '{step_name}' æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜",
            "å¤„ç†ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯ï¼Œéœ€è¦å…³æ³¨",
            "ç³»ç»Ÿé‡åˆ°å¼‚å¸¸æƒ…å†µï¼Œæ­£åœ¨å¤„ç†ä¸­"
        ]
        
        self.progress_templates = [
            "æ­£åœ¨æ‰§è¡Œæ­¥éª¤ '{step_name}'",
            "ä»»åŠ¡è¿›è¡Œä¸­ï¼Œç³»ç»Ÿæ­£åœ¨å¤„ç†ç›¸å…³æ“ä½œ",
            "å·¥ä½œæµæ­£åœ¨è¿›è¡Œï¼Œå½“å‰æ­¥éª¤å¤„ç†ä¸­"
        ]
        
        self.minimal_templates = [
            "ç³»ç»ŸçŠ¶æ€æ›´æ–°",
            "å·¥ä½œæµç¨‹è¿›è¡Œä¸­",
            "ä»»åŠ¡å¤„ç†çŠ¶æ€æ›´æ–°"
        ]
    
    def generate_fallback_state(self, strategy: FallbackStrategy, 
                               current_state: 'WorkflowState', 
                               context: Dict[str, Any],
                               failure_reason: str = "") -> str:
        """
        æ ¹æ®æŒ‡å®šç­–ç•¥ç”Ÿæˆå›é€€çŠ¶æ€
        
        Args:
            strategy: å›é€€ç­–ç•¥
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            failure_reason: å¤±è´¥åŸå› 
            
        Returns:
            ç”Ÿæˆçš„å›é€€çŠ¶æ€æè¿°
        """
        try:
            self.logger.info(f"ä½¿ç”¨å›é€€ç­–ç•¥ç”ŸæˆçŠ¶æ€: {strategy.value}")
            
            if strategy == FallbackStrategy.TEMPLATE_BASED:
                return self._generate_template_based_state(context)
            elif strategy == FallbackStrategy.RULE_BASED:
                return self._generate_rule_based_state(current_state, context)
            elif strategy == FallbackStrategy.MINIMAL_STATE:
                return self._generate_minimal_state(context)
            elif strategy == FallbackStrategy.NOTIFY_OPERATOR:
                return self._generate_notification_state(failure_reason)
            else:
                # é»˜è®¤ä½¿ç”¨æœ€å°çŠ¶æ€
                return self._generate_minimal_state(context)
                
        except Exception as e:
            self.logger.error(f"å›é€€çŠ¶æ€ç”Ÿæˆå¤±è´¥: {e}")
            return "ç³»ç»ŸçŠ¶æ€æ›´æ–°"  # æœ€åçš„ä¿åº•çŠ¶æ€
    
    def _generate_template_based_state(self, context: Dict[str, Any]) -> str:
        """åŸºäºæ¨¡æ¿ç”ŸæˆçŠ¶æ€"""
        step_info = context.get('step_info', {})
        step_name = step_info.get('description', step_info.get('name', 'æœªçŸ¥æ­¥éª¤'))
        step_status = context.get('step_status', 'unknown')
        execution_result = context.get('execution_result', {})
        error_info = context.get('error_info')
        
        # æ ¹æ®æ‰§è¡ŒçŠ¶æ€é€‰æ‹©æ¨¡æ¿ç±»å‹
        if error_info or (execution_result and not execution_result.get('success', True)):
            template = random.choice(self.error_templates)
        elif step_status == 'completed':
            template = random.choice(self.success_templates)
        else:
            template = random.choice(self.progress_templates)
        
        # æ›¿æ¢å˜é‡
        try:
            return template.format(step_name=step_name)
        except:
            return template.replace("{step_name}", step_name)
    
    def _generate_rule_based_state(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> str:
        """åŸºäºè§„åˆ™ç”ŸæˆçŠ¶æ€"""
        parts = []
        
        # è·å–æ­¥éª¤ä¿¡æ¯
        step_info = context.get('step_info', {})
        step_name = step_info.get('description', 'å½“å‰æ­¥éª¤')
        step_status = context.get('step_status')
        
        # æ£€æŸ¥é”™è¯¯æƒ…å†µ
        error_info = context.get('error_info')
        if error_info:
            parts.append(f"{step_name}æ‰§è¡Œé‡åˆ°é—®é¢˜")
            if "ç½‘ç»œ" in str(error_info).lower():
                parts.append("ç½‘ç»œè¿æ¥å¼‚å¸¸")
            elif "æƒé™" in str(error_info).lower():
                parts.append("æƒé™éªŒè¯å¤±è´¥")
            else:
                parts.append("éœ€è¦è¿›ä¸€æ­¥å¤„ç†")
        else:
            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            execution_result = context.get('execution_result', {})
            if execution_result.get('success'):
                parts.append(f"{step_name}æ‰§è¡ŒæˆåŠŸ")
                
                # æ·»åŠ è¾“å‡ºä¿¡æ¯
                output = execution_result.get('output')
                if output:
                    output_str = str(output)[:50]
                    if "å®Œæˆ" in output_str or "æˆåŠŸ" in output_str:
                        parts.append("æ“ä½œé¡ºåˆ©å®Œæˆ")
                    elif len(output_str) > 10:
                        parts.append("å·²ç”Ÿæˆå¤„ç†ç»“æœ")
            else:
                parts.append(f"{step_name}æ­£åœ¨æ‰§è¡Œ")
        
        return "ï¼Œ".join(parts) if parts else "å·¥ä½œæµçŠ¶æ€æ›´æ–°"
    
    def _generate_minimal_state(self, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆæœ€å°çŠ¶æ€æè¿°"""
        timestamp = dt.now().strftime("%H:%M")
        template = random.choice(self.minimal_templates)
        return f"{template} ({timestamp})"
    
    def _generate_notification_state(self, failure_reason: str) -> str:
        """ç”Ÿæˆé€šçŸ¥æ“ä½œå‘˜çš„çŠ¶æ€"""
        return f"AIçŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥ - åŸå› : {failure_reason[:50]}..."


class AICallCacheEntry(NamedTuple):
    """AIè°ƒç”¨ç¼“å­˜æ¡ç›®"""
    response: str                    # LLMå“åº”
    timestamp: dt                   # åˆ›å»ºæ—¶é—´
    context_hash: str               # ä¸Šä¸‹æ–‡å“ˆå¸Œ
    confidence_score: float         # ç½®ä¿¡åº¦è¯„åˆ†
    usage_count: int                # ä½¿ç”¨æ¬¡æ•°
    
class LRUCache:
    """LRUç¼“å­˜å®ç°ï¼Œç”¨äºAIè°ƒç”¨ç»“æœç¼“å­˜"""
    
    def __init__(self, max_size: int = 100):
        """
        åˆå§‹åŒ–LRUç¼“å­˜
        
        Args:
            max_size: ç¼“å­˜æœ€å¤§å®¹é‡
        """
        self.max_size = max_size
        self.cache = OrderedDict()
        self._lock = threading.RLock()
        self._stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'total_requests': 0
        }
        
    def get(self, key: str) -> Optional[AICallCacheEntry]:
        """è·å–ç¼“å­˜é¡¹"""
        with self._lock:
            self._stats['total_requests'] += 1
            
            if key in self.cache:
                # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
                entry = self.cache.pop(key)
                # å¢åŠ ä½¿ç”¨æ¬¡æ•°
                updated_entry = entry._replace(usage_count=entry.usage_count + 1)
                self.cache[key] = updated_entry
                self._stats['hits'] += 1
                return updated_entry
            else:
                self._stats['misses'] += 1
                return None
    
    def put(self, key: str, entry: AICallCacheEntry) -> None:
        """æ·»åŠ ç¼“å­˜é¡¹"""
        with self._lock:
            if key in self.cache:
                # æ›´æ–°ç°æœ‰é¡¹
                self.cache.pop(key)
            elif len(self.cache) >= self.max_size:
                # ç§»é™¤æœ€å°‘ä½¿ç”¨çš„é¡¹
                self.cache.popitem(last=False)
                self._stats['evictions'] += 1
            
            self.cache[key] = entry
    
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self.cache.clear()
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            hit_rate = (self._stats['hits'] / max(self._stats['total_requests'], 1)) * 100
            return {
                **self._stats,
                'hit_rate_percent': hit_rate,
                'cache_size': len(self.cache),
                'max_size': self.max_size
            }
    
    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            self._stats = {
                'hits': 0,
                'misses': 0,
                'evictions': 0,
                'total_requests': 0
            }

class ContextHasher:
    """ä¸Šä¸‹æ–‡å“ˆå¸Œç”Ÿæˆå™¨"""
    
    @staticmethod
    def hash_context(current_state: 'WorkflowState', context: Dict[str, Any], 
                    include_timestamp: bool = False) -> str:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡çš„å“ˆå¸Œå€¼
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            include_timestamp: æ˜¯å¦åŒ…å«æ—¶é—´æˆ³ï¼ˆå½±å“ç¼“å­˜æœ‰æ•ˆæ€§ï¼‰
            
        Returns:
            ä¸Šä¸‹æ–‡å“ˆå¸Œå­—ç¬¦ä¸²
        """
        import hashlib
        
        # æ”¶é›†å…³é”®ä¸Šä¸‹æ–‡ä¿¡æ¯
        hash_components = []
        
        # 1. å½“å‰å…¨å±€çŠ¶æ€
        if current_state:
            global_state = current_state.get_global_state()
            hash_components.append(f"global_state:{global_state}")
            
            # æ·»åŠ æœ€è¿‘çš„çŠ¶æ€å†å²ï¼ˆé™åˆ¶æ•°é‡é¿å…å“ˆå¸Œè¿‡é•¿ï¼‰
            recent_history = current_state.get_state_history(limit=3)
            for i, entry in enumerate(recent_history):
                hash_components.append(f"history_{i}:{entry.state_snapshot[:100]}")
        
        # 2. æ­¥éª¤ä¿¡æ¯
        step_info = context.get('step_info', {})
        if step_info:
            hash_components.append(f"step_action:{step_info.get('action', '')}")
            hash_components.append(f"step_type:{step_info.get('type', '')}")
            hash_components.append(f"step_id:{step_info.get('step_id', '')}")
        
        # 3. æ‰§è¡Œç»“æœï¼ˆå…³é”®éƒ¨åˆ†ï¼‰
        execution_result = context.get('execution_result', '')
        if execution_result:
            # æˆªå–å‰200ä¸ªå­—ç¬¦é¿å…å“ˆå¸Œè¿‡é•¿
            result_summary = str(execution_result)[:200]
            hash_components.append(f"exec_result:{result_summary}")
        
        # 4. æ­¥éª¤çŠ¶æ€
        step_status = context.get('step_status', '')
        hash_components.append(f"step_status:{step_status}")
        
        # 5. é”™è¯¯ä¿¡æ¯
        error_info = context.get('error_info')
        if error_info:
            error_summary = str(error_info)[:100]
            hash_components.append(f"error:{error_summary}")
        
        # 6. æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
        if include_timestamp:
            timestamp = context.get('timestamp', dt.now().isoformat())
            hash_components.append(f"timestamp:{timestamp}")
        
        # ç”Ÿæˆå“ˆå¸Œ
        combined_string = "|".join(hash_components)
        return hashlib.md5(combined_string.encode('utf-8')).hexdigest()

class AICallConditionChecker:
    """AIè°ƒç”¨æ¡ä»¶æ£€æŸ¥å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¡ä»¶æ£€æŸ¥å™¨"""
        self._significance_threshold = 0.3  # æ˜¾è‘—æ€§é˜ˆå€¼
        self._time_threshold = 300  # æ—¶é—´é˜ˆå€¼ï¼ˆç§’ï¼‰
        
    def should_make_ai_call(self, current_state: 'WorkflowState', 
                           context: Dict[str, Any]) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›è¡ŒAIè°ƒç”¨
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            (should_call, reason) å…ƒç»„
        """
        # 1. æ£€æŸ¥é¦–æ¬¡åˆå§‹åŒ–ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if self._is_initialization(current_state):
            return True, "å·¥ä½œæµåˆå§‹åŒ–ï¼Œéœ€è¦è®¾ç½®åˆå§‹çŠ¶æ€"
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤§å˜åŒ–
        has_significant_change, change_reason = self._has_significant_change(context)
        if has_significant_change:
            return True, f"æ£€æµ‹åˆ°é‡å¤§å˜åŒ–: {change_reason}"
        
        # 3. æ£€æŸ¥é”™è¯¯çŠ¶æ€
        if self._has_error_condition(context):
            return True, "æ£€æµ‹åˆ°é”™è¯¯çŠ¶æ€ï¼Œéœ€è¦AIåˆ†æ"
        
        # 4. æ£€æŸ¥çŠ¶æ€è½¬æ¢
        if self._is_state_transition(context):
            return True, "æ£€æµ‹åˆ°çŠ¶æ€è½¬æ¢ï¼Œéœ€è¦AIæ›´æ–°"
        
        # 5. æ£€æŸ¥æ—¶é—´é—´éš”
        if self._should_update_by_time(current_state):
            return True, "åŸºäºæ—¶é—´é—´éš”çš„å®šæœŸæ›´æ–°"
        
        return False, "æ— éœ€AIè°ƒç”¨ï¼šå˜åŒ–ä¸æ˜¾è‘—ä¸”æ— ç‰¹æ®Šæ¡ä»¶"
    
    def _has_significant_change(self, context: Dict[str, Any]) -> Tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—å˜åŒ–"""
        # æ£€æŸ¥æ‰§è¡Œç»“æœå˜åŒ–
        execution_result = context.get('execution_result', '')
        if execution_result:
            result_str = str(execution_result)
            # æ£€æŸ¥ç»“æœé•¿åº¦ï¼ˆæ›´é•¿å¯èƒ½æ„å‘³ç€æ›´å¤šä¿¡æ¯ï¼‰
            if len(result_str) > 100:
                return True, "æ‰§è¡Œç»“æœä¿¡æ¯ä¸°å¯Œ"
        
        # æ£€æŸ¥æ­¥éª¤ç±»å‹
        step_info = context.get('step_info', {})
        step_type = step_info.get('type', '').lower()
        
        # é‡è¦æ­¥éª¤ç±»å‹æ€»æ˜¯è§¦å‘AIè°ƒç”¨
        important_types = ['critical', 'important', 'decision', 'approval', 'validation']
        if any(important_type in step_type for important_type in important_types):
            return True, f"é‡è¦æ­¥éª¤ç±»å‹: {step_type}"
        
        return False, "æ— æ˜¾è‘—å˜åŒ–"
    
    def _has_error_condition(self, context: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æ¡ä»¶"""
        # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
        error_info = context.get('error_info')
        if error_info:
            return True
        
        # æ£€æŸ¥æ‰§è¡ŒçŠ¶æ€
        step_status = context.get('step_status', '').lower()
        if 'fail' in step_status or 'error' in step_status:
            return True
        
        # æ£€æŸ¥æ‰§è¡Œç»“æœä¸­çš„å¤±è´¥æ ‡è¯†
        execution_result = context.get('execution_result', '')
        if execution_result:
            result_str = str(execution_result).lower()
            error_keywords = ['error', 'failed', 'exception', 'timeout', 'denied']
            if any(keyword in result_str for keyword in error_keywords):
                return True
        
        return False
    
    def _is_state_transition(self, context: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçŠ¶æ€è½¬æ¢"""
        step_status = context.get('step_status', '').lower()
        transition_statuses = ['completed', 'success', 'finished', 'done']
        return any(status in step_status for status in transition_statuses)
    
    def _should_update_by_time(self, current_state: 'WorkflowState') -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”åŸºäºæ—¶é—´è¿›è¡Œæ›´æ–°"""
        if not current_state:
            return True
        
        history = current_state.get_state_history(limit=1)
        if not history:
            return True
        
        last_update = history[0].timestamp
        time_since_last = (dt.now() - last_update).total_seconds()
        
        return time_since_last > self._time_threshold
    
    def _is_initialization(self, current_state: 'WorkflowState') -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºåˆå§‹åŒ–çŠ¶æ€"""
        if not current_state:
            return True
        
        global_state = current_state.get_global_state()
        return not global_state.strip() or current_state.get_state_history_count() == 0
    
    def set_significance_threshold(self, threshold: float) -> None:
        """è®¾ç½®æ˜¾è‘—æ€§é˜ˆå€¼"""
        self._significance_threshold = max(0.0, min(1.0, threshold))
    
    def set_time_threshold(self, seconds: int) -> None:
        """è®¾ç½®æ—¶é—´é˜ˆå€¼"""
        self._time_threshold = max(60, seconds)  # æœ€å°1åˆ†é’Ÿ
    
    def get_configuration(self) -> Dict[str, Any]:
        """è·å–é…ç½®ä¿¡æ¯"""
        return {
            'significance_threshold': self._significance_threshold,
            'time_threshold_seconds': self._time_threshold
        }

class AIStateUpdater(ABC):
    """AIçŠ¶æ€æ›´æ–°å™¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    def update_state(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> Optional[str]:
        """
        åŸºäºå½“å‰çŠ¶æ€å’Œä¸Šä¸‹æ–‡æ›´æ–°å…¨å±€çŠ¶æ€
        
        Args:
            current_state: å½“å‰çš„WorkflowStateå®ä¾‹
            context: åŒ…å«æ­¥éª¤ä¿¡æ¯ã€æ‰§è¡Œç»“æœç­‰çš„ä¸Šä¸‹æ–‡å­—å…¸
            
        Returns:
            æ–°çš„çŠ¶æ€å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸éœ€è¦æ›´æ–°åˆ™è¿”å›None
        """
        pass
    
    @abstractmethod
    def should_update(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°çŠ¶æ€
        
        Args:
            current_state: å½“å‰çš„WorkflowStateå®ä¾‹
            context: åŒ…å«æ­¥éª¤ä¿¡æ¯ã€æ‰§è¡Œç»“æœç­‰çš„ä¸Šä¸‹æ–‡å­—å…¸
            
        Returns:
            æ˜¯å¦éœ€è¦æ›´æ–°çŠ¶æ€
        """
        pass

class AIStateUpdaterService(AIStateUpdater):
    """åŸºäºDeepSeekçš„AIçŠ¶æ€æ›´æ–°å™¨æœåŠ¡å®ç°"""
    
    def __init__(self, llm: ChatOpenAI, max_retries: int = None, retry_delay: float = None,
                 enable_sentiment_analysis: bool = None, enable_intent_recognition: bool = None,
                 fallback_strategies: List[FallbackStrategy] = None, enable_notifications: bool = None,
                 enable_caching: bool = None, cache_size: int = None, 
                 enable_conditional_logic: bool = None):
        """
        åˆå§‹åŒ–AIçŠ¶æ€æ›´æ–°å™¨æœåŠ¡ï¼ˆæ”¯æŒé…ç½®ç³»ç»Ÿï¼‰
        
        Args:
            llm: DeepSeek LLMå®ä¾‹ (llm_deepseek)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            retry_delay: é‡è¯•å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            enable_sentiment_analysis: æ˜¯å¦å¯ç”¨æƒ…æ„Ÿåˆ†æï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            enable_intent_recognition: æ˜¯å¦å¯ç”¨æ„å›¾è¯†åˆ«ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            fallback_strategies: å›é€€ç­–ç•¥åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            enable_notifications: æ˜¯å¦å¯ç”¨å¤±è´¥é€šçŸ¥ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            enable_caching: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            cache_size: ç¼“å­˜å¤§å°ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            enable_conditional_logic: æ˜¯å¦å¯ç”¨æ¡ä»¶é€»è¾‘ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        """
        self.llm = llm
        self._logger = logging.getLogger(f"{__name__}.AIStateUpdaterService")
        
        # åŠ è½½é…ç½®ç³»ç»Ÿå‚æ•°
        if CONFIG_SYSTEM_AVAILABLE:
            try:
                config = get_config()
                ai_config = config.ai_updater
                
                # ä½¿ç”¨é…ç½®ç³»ç»Ÿçš„å‚æ•°ï¼ˆå¦‚æœæ²¡æœ‰æ˜¾å¼æŒ‡å®šï¼‰
                self.max_retries = max_retries if max_retries is not None else ai_config.max_retries
                self.retry_delay = retry_delay if retry_delay is not None else ai_config.timeout_seconds / 10.0  # ç®€å•è®¡ç®—
                self.enable_notifications = enable_notifications if enable_notifications is not None else False  # é»˜è®¤å…³é—­é€šçŸ¥
                enable_caching = enable_caching if enable_caching is not None else ai_config.enable_caching
                cache_size = cache_size if cache_size is not None else ai_config.cache_ttl_minutes * 2  # ç®€å•è®¡ç®—
                enable_conditional_logic = enable_conditional_logic if enable_conditional_logic is not None else True
                enable_sentiment_analysis = enable_sentiment_analysis if enable_sentiment_analysis is not None else True
                enable_intent_recognition = enable_intent_recognition if enable_intent_recognition is not None else True
                
                self._logger.info(f"ä½¿ç”¨é…ç½®ç³»ç»Ÿå‚æ•°: é‡è¯•æ¬¡æ•°={self.max_retries}, ç¼“å­˜={enable_caching}, æ¨¡å‹={ai_config.model_name}")
            except Exception as e:
                self._logger.warning(f"åŠ è½½AIé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {e}")
                # ä½¿ç”¨é»˜è®¤å€¼
                self.max_retries = max_retries if max_retries is not None else 3
                self.retry_delay = retry_delay if retry_delay is not None else 1.0
                self.enable_notifications = enable_notifications if enable_notifications is not None else False
                enable_caching = enable_caching if enable_caching is not None else True
                cache_size = cache_size if cache_size is not None else 100
                enable_conditional_logic = enable_conditional_logic if enable_conditional_logic is not None else True
                enable_sentiment_analysis = enable_sentiment_analysis if enable_sentiment_analysis is not None else True
                enable_intent_recognition = enable_intent_recognition if enable_intent_recognition is not None else True
        else:
            # é…ç½®ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é»˜è®¤å€¼
            self.max_retries = max_retries if max_retries is not None else 3
            self.retry_delay = retry_delay if retry_delay is not None else 1.0
            self.enable_notifications = enable_notifications if enable_notifications is not None else False
            enable_caching = enable_caching if enable_caching is not None else True
            cache_size = cache_size if cache_size is not None else 100
            enable_conditional_logic = enable_conditional_logic if enable_conditional_logic is not None else True
            enable_sentiment_analysis = enable_sentiment_analysis if enable_sentiment_analysis is not None else True
            enable_intent_recognition = enable_intent_recognition if enable_intent_recognition is not None else True
        
        # åˆå§‹åŒ–æ¨¡æ¿ç®¡ç†å™¨
        self.template_manager = PromptTemplateManager()
        
        # åˆå§‹åŒ–å“åº”è§£æå™¨
        self.response_parser = ResponseParser(
            enable_sentiment_analysis=enable_sentiment_analysis,
            enable_intent_recognition=enable_intent_recognition
        )
        
        # åˆå§‹åŒ–å›é€€çŠ¶æ€ç”Ÿæˆå™¨
        self.fallback_generator = FallbackStateGenerator()
        
        # é…ç½®å›é€€ç­–ç•¥ï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼‰
        self.fallback_strategies = fallback_strategies or [
            FallbackStrategy.RETRY_SIMPLIFIED,
            FallbackStrategy.TEMPLATE_BASED,
            FallbackStrategy.RULE_BASED,
            FallbackStrategy.MINIMAL_STATE
        ]
        
        # ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘é…ç½®
        self.enable_caching = enable_caching
        self.enable_conditional_logic = enable_conditional_logic
        
        # åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
        if self.enable_caching:
            self.cache = LRUCache(max_size=cache_size)
            self.context_hasher = ContextHasher()
            self._logger.info(f"AIè°ƒç”¨ç¼“å­˜å·²å¯ç”¨ï¼Œç¼“å­˜å¤§å°: {cache_size}")
        else:
            self.cache = None
            self.context_hasher = None
            self._logger.info("AIè°ƒç”¨ç¼“å­˜å·²ç¦ç”¨")
        
        # åˆå§‹åŒ–æ¡ä»¶æ£€æŸ¥å™¨
        if self.enable_conditional_logic:
            self.condition_checker = AICallConditionChecker()
            self._logger.info("AIè°ƒç”¨æ¡ä»¶é€»è¾‘å·²å¯ç”¨")
        else:
            self.condition_checker = None
            self._logger.info("AIè°ƒç”¨æ¡ä»¶é€»è¾‘å·²ç¦ç”¨")
        
        # å­˜å‚¨æœ€åä¸€æ¬¡è§£æä¿¡æ¯å’Œå¤±è´¥è®°å½•
        self._last_parsed_info = None
        self._parsed_info_lock = threading.Lock()
        self._failure_count = 0
        self._last_failure_reason = ""
        
        # éªŒè¯LLMè¿æ¥
        self._validate_llm_connection()
        
        model_name = getattr(llm, 'model_name', getattr(llm, 'model', 'unknown'))
        self._logger.info(f"AIStateUpdaterServiceåˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {model_name}, æœ€å¤§é‡è¯•: {self.max_retries}, "
                         f"æ¨¡æ¿æ•°: {len(self.template_manager.list_templates())}, å“åº”è§£æå™¨: å·²å¯ç”¨, "
                         f"å›é€€ç­–ç•¥: {len(self.fallback_strategies)}ä¸ª, é€šçŸ¥: {'å¯ç”¨' if self.enable_notifications else 'ç¦ç”¨'}, "
                         f"ç¼“å­˜: {'å¯ç”¨' if self.enable_caching else 'ç¦ç”¨'}, "
                         f"æ¡ä»¶é€»è¾‘: {'å¯ç”¨' if self.enable_conditional_logic else 'ç¦ç”¨'}")
    
    def _validate_llm_connection(self) -> None:
        """éªŒè¯LLMè¿æ¥æ˜¯å¦æ­£å¸¸"""
        try:
            test_message = [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"), HumanMessage(content="è¯·å›å¤'è¿æ¥æ­£å¸¸'")]
            response = self.llm.invoke(test_message)
            if response and response.content:
                self._logger.info("LLMè¿æ¥éªŒè¯æˆåŠŸ")
            else:
                raise ValueError("LLMå“åº”ä¸ºç©º")
        except Exception as e:
            self._logger.error(f"LLMè¿æ¥éªŒè¯å¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°DeepSeekæœåŠ¡: {e}")
    
    def should_update(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°çŠ¶æ€
        
        ç®€å•ç­–ç•¥ï¼š
        1. å¦‚æœæ­¥éª¤æ‰§è¡Œå®Œæˆï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰åˆ™æ›´æ–°
        2. å¦‚æœçŠ¶æ€ä¸ºç©ºåˆ™æ›´æ–°
        3. å¦‚æœä¸Šä¸‹æ–‡åŒ…å«é‡è¦å˜åŒ–åˆ™æ›´æ–°
        """
        try:
            # æ£€æŸ¥åŸºæœ¬æ¡ä»¶
            if not current_state.is_state_update_enabled():
                self._logger.debug("çŠ¶æ€æ›´æ–°è¢«ç¦ç”¨ï¼Œè·³è¿‡æ›´æ–°åˆ¤æ–­")
                return False
            
            # å¦‚æœå½“å‰çŠ¶æ€ä¸ºç©ºï¼Œåº”è¯¥æ›´æ–°
            current_global_state = current_state.get_global_state()
            if not current_global_state.strip():
                self._logger.debug("å½“å‰çŠ¶æ€ä¸ºç©ºï¼Œéœ€è¦æ›´æ–°")
                return True
            
            # æ£€æŸ¥ä¸Šä¸‹æ–‡ä¸­çš„é‡è¦ä¿¡æ¯
            step_status = context.get('step_status')
            if step_status in ['completed', 'failed']:
                self._logger.debug(f"æ­¥éª¤çŠ¶æ€ä¸º{step_status}ï¼Œéœ€è¦æ›´æ–°")
                return True
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ‰§è¡Œç»“æœ
            if context.get('execution_result') is not None:
                self._logger.debug("å­˜åœ¨æ‰§è¡Œç»“æœï¼Œéœ€è¦æ›´æ–°")
                return True
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if context.get('error_info'):
                self._logger.debug("å­˜åœ¨é”™è¯¯ä¿¡æ¯ï¼Œéœ€è¦æ›´æ–°")
                return True
            
            self._logger.debug("æ— éœ€æ›´æ–°çŠ¶æ€")
            return False
            
        except Exception as e:
            self._logger.error(f"çŠ¶æ€æ›´æ–°åˆ¤æ–­å¤±è´¥: {e}")
            return False
    
    def update_state(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> Optional[str]:
        """
        ä½¿ç”¨DeepSeekå’ŒåŠ¨æ€æ¨¡æ¿ç”Ÿæˆæ–°çš„çŠ¶æ€æè¿°ï¼Œé›†æˆç¼“å­˜å’Œæ¡ä»¶é€»è¾‘
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            æ–°çš„çŠ¶æ€æè¿°å­—ç¬¦ä¸²ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        # 1. åŸºæœ¬å¯ç”¨æ€§æ£€æŸ¥
        if not self.should_update(current_state, context):
            return None
        
        # 2. æ¡ä»¶é€»è¾‘æ£€æŸ¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_conditional_logic and self.condition_checker:
            should_call, reason = self.condition_checker.should_make_ai_call(current_state, context)
            if not should_call:
                self._logger.debug(f"æ¡ä»¶é€»è¾‘æ£€æŸ¥å†³å®šè·³è¿‡AIè°ƒç”¨: {reason}")
                return None
            else:
                self._logger.debug(f"æ¡ä»¶é€»è¾‘æ£€æŸ¥å†³å®šè¿›è¡ŒAIè°ƒç”¨: {reason}")
        
        # 3. ç¼“å­˜æ£€æŸ¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        cache_key = None
        if self.enable_caching and self.cache and self.context_hasher:
            cache_key = self.context_hasher.hash_context(current_state, context)
            cached_entry = self.cache.get(cache_key)
            if cached_entry:
                self._logger.info(f"ä½¿ç”¨ç¼“å­˜å“åº” [ç¼“å­˜å‘½ä¸­, ä½¿ç”¨æ¬¡æ•°: {cached_entry.usage_count}]")
                return cached_entry.response
        
        # æ£€æµ‹åœºæ™¯ç±»å‹
        scenario = self._detect_scenario(current_state, context)
        self._logger.debug(f"æ£€æµ‹åˆ°åœºæ™¯ç±»å‹: {scenario.value}")
        
        for attempt in range(self.max_retries + 1):
            try:
                # å‡†å¤‡æ¨¡æ¿å˜é‡
                variables = self._prepare_template_variables(current_state, context)
                
                # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæç¤º
                system_message, user_message = self.template_manager.render_template(scenario, variables)
                
                # è°ƒç”¨DeepSeekç”ŸæˆçŠ¶æ€æè¿°
                messages = [
                    SystemMessage(content=system_message),
                    HumanMessage(content=user_message)
                ]
                
                self._logger.debug(f"ç¬¬{attempt + 1}æ¬¡å°è¯•è°ƒç”¨DeepSeekæ›´æ–°çŠ¶æ€ [åœºæ™¯: {scenario.value}]")
                response = self.llm.invoke(messages)
                
                if response and response.content:
                    new_state = response.content.strip()
                    
                    # é¦–å…ˆè§£æå“åº”ä»¥è·å–è¯¦ç»†ä¿¡æ¯
                    parsed_info = self.response_parser.parse_response(new_state, context)
                    self._store_parsed_info(parsed_info)
                    
                    # éªŒè¯ç”Ÿæˆçš„çŠ¶æ€æè¿°
                    if self._validate_generated_state(new_state, context):
                        self._logger.info(f"æˆåŠŸç”Ÿæˆæ–°çŠ¶æ€æè¿° [åœºæ™¯: {scenario.value}, å°è¯•æ¬¡æ•°: {attempt + 1}, "
                                        f"ç½®ä¿¡åº¦: {parsed_info.confidence_score:.2f}, è´¨é‡: {parsed_info.quality_metrics.get('overall_quality', 'unknown')}]")
                        
                        # ç¼“å­˜æˆåŠŸçš„å“åº”ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if self.enable_caching and self.cache and cache_key:
                            cache_entry = AICallCacheEntry(
                                response=new_state,
                                timestamp=dt.now(),
                                context_hash=cache_key,
                                confidence_score=parsed_info.confidence_score,
                                usage_count=1
                            )
                            self.cache.put(cache_key, cache_entry)
                            self._logger.debug(f"å“åº”å·²ç¼“å­˜ [key: {cache_key[:8]}...]")
                        
                        return new_state
                    else:
                        self._logger.warning(f"ç”Ÿæˆçš„çŠ¶æ€æè¿°éªŒè¯å¤±è´¥ (å°è¯•æ¬¡æ•°: {attempt + 1})")
                        
                else:
                    self._logger.warning(f"DeepSeekè¿”å›ç©ºå“åº” (å°è¯•æ¬¡æ•°: {attempt + 1})")
                    
            except Exception as e:
                self._logger.error(f"DeepSeekè°ƒç”¨å¤±è´¥ (å°è¯•æ¬¡æ•°: {attempt + 1}): {e}")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < self.max_retries:
                    time.sleep(self.retry_delay * (attempt + 1))  # æŒ‡æ•°é€€é¿
        
        # æ‰€æœ‰LLMé‡è¯•å¤±è´¥ï¼Œå¯åŠ¨å¤šå±‚å›é€€æœºåˆ¶
        self._failure_count += 1
        self._last_failure_reason = f"LLMè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries + 1}æ¬¡"
        self._logger.error(f"æ‰€æœ‰LLMé‡è¯•å°è¯•å¤±è´¥ï¼Œå¯åŠ¨å›é€€æœºåˆ¶ (å¤±è´¥æ¬¡æ•°: {self._failure_count})")
        
        # æ‰§è¡Œå›é€€ç­–ç•¥
        fallback_state = self._execute_fallback_strategies(current_state, context)
        if fallback_state:
            self._logger.info(f"å›é€€æœºåˆ¶æˆåŠŸç”ŸæˆçŠ¶æ€: {fallback_state[:50]}...")
            return fallback_state
        
        self._logger.error("æ‰€æœ‰å›é€€ç­–ç•¥å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆçŠ¶æ€æ›´æ–°")
        return None
    
    def _get_system_message(self) -> str:
        """è·å–çŠ¶æ€æ›´æ–°çš„ç³»ç»Ÿæç¤ºæ¶ˆæ¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å·¥ä½œæµçŠ¶æ€ç®¡ç†ä¸“å®¶ï¼Œè´Ÿè´£æ ¹æ®å·¥ä½œæµæ‰§è¡Œæƒ…å†µç”Ÿæˆç®€æ´å‡†ç¡®çš„çŠ¶æ€æè¿°ã€‚

è¦æ±‚ï¼š
1. çŠ¶æ€æè¿°åº”è¯¥æ˜¯è‡ªç„¶è¯­è¨€ï¼Œç®€æ´æ˜äº†ï¼ˆ1-3å¥è¯ï¼‰
2. é‡ç‚¹æè¿°å½“å‰å·¥ä½œæµçš„æ ¸å¿ƒè¿›å±•å’ŒçŠ¶æ€
3. å¦‚æœæœ‰é”™è¯¯ï¼Œç®€è¦è¯´æ˜é—®é¢˜æ‰€åœ¨
4. å¦‚æœæˆåŠŸå®Œæˆï¼Œæè¿°å®ç°çš„ä¸»è¦åŠŸèƒ½
5. é¿å…æŠ€æœ¯ç»†èŠ‚ï¼Œå…³æ³¨ä¸šåŠ¡å±‚é¢çš„çŠ¶æ€
6. çŠ¶æ€æè¿°åº”è¯¥è¿è´¯ï¼Œä½“ç°å·¥ä½œæµçš„æ¼”è¿›è¿‡ç¨‹

ç¤ºä¾‹ï¼š
- "å¼€å§‹åˆ›å»ºè®¡ç®—å™¨åº”ç”¨ï¼Œæ­£åœ¨è®¾è®¡åŸºç¡€æ¶æ„"
- "è®¡ç®—å™¨æ ¸å¿ƒåŠŸèƒ½å®ç°å®Œæˆï¼ŒåŒ…å«åŠ å‡ä¹˜é™¤è¿ç®—"
- "æµ‹è¯•é˜¶æ®µå‘ç°é™¤é›¶é”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤å¼‚å¸¸å¤„ç†"
- "è®¡ç®—å™¨åº”ç”¨å¼€å‘å®Œæˆï¼Œæ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡"
"""
    
    def _build_state_update_prompt(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> str:
        """æ„å»ºçŠ¶æ€æ›´æ–°æç¤º"""
        # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯
        current_global_state = current_state.get_global_state()
        state_history = current_state.get_state_history(limit=3)  # è·å–æœ€è¿‘3æ¡å†å²
        
        # ä»ä¸Šä¸‹æ–‡æå–å…³é”®ä¿¡æ¯
        step_info = context.get('step_info', {})
        execution_result = context.get('execution_result')
        step_status = context.get('step_status', 'unknown')
        error_info = context.get('error_info')
        
        # æ„å»ºæç¤º
        prompt_parts = [
            "è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æ›´æ–°å·¥ä½œæµçŠ¶æ€æè¿°ï¼š",
            "",
            "## å½“å‰çŠ¶æ€",
            f"å½“å‰çŠ¶æ€: {current_global_state if current_global_state else 'æ— '}",
            "",
            "## æœ€è¿‘çŠ¶æ€å†å²"
        ]
        
        if state_history:
            for i, entry in enumerate(reversed(state_history), 1):
                prompt_parts.append(f"{i}. {entry.state_snapshot} (æ—¶é—´: {entry.timestamp.strftime('%H:%M:%S')})")
        else:
            prompt_parts.append("æ— å†å²è®°å½•")
        
        prompt_parts.extend([
            "",
            "## å½“å‰æ­¥éª¤ä¿¡æ¯",
            f"æ­¥éª¤çŠ¶æ€: {step_status}",
            f"æ­¥éª¤æè¿°: {step_info.get('description', 'æœªçŸ¥')}",
            f"æ­¥éª¤ç±»å‹: {step_info.get('type', 'æœªçŸ¥')}",
            ""
        ])
        
        # æ·»åŠ æ‰§è¡Œç»“æœä¿¡æ¯
        if execution_result:
            prompt_parts.extend([
                "## æ‰§è¡Œç»“æœ",
                f"æ‰§è¡ŒæˆåŠŸ: {'æ˜¯' if execution_result.get('success', False) else 'å¦'}"
            ])
            
            if execution_result.get('output'):
                output_preview = str(execution_result['output'])[:200]
                prompt_parts.append(f"è¾“å‡ºé¢„è§ˆ: {output_preview}...")
        
        # æ·»åŠ é”™è¯¯ä¿¡æ¯
        if error_info:
            prompt_parts.extend([
                "",
                "## é”™è¯¯ä¿¡æ¯",
                f"é”™è¯¯è¯¦æƒ…: {error_info}"
            ])
        
        prompt_parts.extend([
            "",
            "è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„çŠ¶æ€æè¿°ï¼ˆ1-3å¥è¯ï¼‰ï¼Œåæ˜ å½“å‰å·¥ä½œæµçš„å®é™…è¿›å±•å’ŒçŠ¶æ€ã€‚"
        ])
        
        return "\n".join(prompt_parts)
    
    def _detect_scenario(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> PromptScenario:
        """
        æ£€æµ‹å½“å‰åœºæ™¯ç±»å‹
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            æ£€æµ‹åˆ°çš„åœºæ™¯ç±»å‹
        """
        # è·å–åŸºæœ¬ä¿¡æ¯
        current_global_state = current_state.get_global_state()
        step_status = context.get('step_status', '').lower()
        error_info = context.get('error_info')
        execution_result = context.get('execution_result')
        step_info = context.get('step_info', {})
        
        # 1. åˆå§‹åŒ–åœºæ™¯ï¼šå¦‚æœå½“å‰çŠ¶æ€ä¸ºç©ºä¸”æ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œ
        if not current_global_state.strip() and current_state.get_state_history_count() == 0:
            return PromptScenario.INITIALIZATION
        
        # 2. é”™è¯¯å¤„ç†åœºæ™¯ï¼šå¦‚æœæœ‰é”™è¯¯ä¿¡æ¯æˆ–æ‰§è¡Œå¤±è´¥
        execution_failed = False
        if isinstance(execution_result, dict):
            execution_failed = not execution_result.get('success', True)
        elif isinstance(execution_result, str):
            execution_failed = execution_result.lower() in ['failed', 'error', 'failure']
        
        if error_info or execution_failed:
            return PromptScenario.ERROR_HANDLING
        
        # 3. æˆåŠŸå®Œæˆåœºæ™¯ï¼šå¦‚æœæ­¥éª¤æˆåŠŸå®Œæˆ
        if step_status in ['completed', 'success']:
            return PromptScenario.SUCCESS_COMPLETION
        
        # 4. çŠ¶æ€è½¬æ¢åœºæ™¯ï¼šå¦‚æœå†å²è®°å½•è¡¨æ˜æœ‰é‡è¦è½¬æ¢
        history_count = current_state.get_state_history_count()
        if history_count > 1 and step_info.get('type') in ['control', 'decision', 'transition']:
            return PromptScenario.STATE_TRANSITION
        
        # 5. æ€»ç»“åœºæ™¯ï¼šå¦‚æœæ˜¯æœ€åä¸€æ­¥æˆ–åŒ…å«æ€»ç»“ä¿¡æ¯
        if (step_info.get('type') == 'summary' or 
            context.get('is_final_step', False) or 
            'complete' in step_status or 
            'finish' in step_status):
            return PromptScenario.SUMMARY
        
        # 6. é»˜è®¤ä¸ºè¿›åº¦æ›´æ–°åœºæ™¯
        return PromptScenario.PROGRESS_UPDATE
    
    def _prepare_template_variables(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‡†å¤‡æ¨¡æ¿å˜é‡
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            æ¨¡æ¿å˜é‡å­—å…¸
        """
        # è·å–åŸºæœ¬çŠ¶æ€ä¿¡æ¯
        current_global_state = current_state.get_global_state()
        state_history = current_state.get_state_history(limit=3)
        
        # è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
        step_info = context.get('step_info', {})
        execution_result = context.get('execution_result')
        error_info = context.get('error_info')
        main_instruction = context.get('main_instruction', '')
        
        # æ„å»ºçŠ¶æ€å†å²æ‘˜è¦
        state_history_text = ""
        if state_history:
            history_items = []
            for i, entry in enumerate(reversed(state_history), 1):
                timestamp_str = entry.timestamp.strftime('%H:%M:%S')
                history_items.append(f"{i}. {entry.state_snapshot} (æ—¶é—´: {timestamp_str})")
            state_history_text = "\n".join(history_items)
        else:
            state_history_text = "æ— å†å²è®°å½•"
        
        # å¤„ç†æ‰§è¡Œè¾“å‡º - æ”¯æŒå­—ç¬¦ä¸²å’Œå­—å…¸ä¸¤ç§æ ¼å¼
        execution_output = ""
        execution_success = False
        if execution_result:
            if isinstance(execution_result, dict):
                if execution_result.get('output'):
                    output_str = str(execution_result['output'])
                    # é™åˆ¶è¾“å‡ºé•¿åº¦ä»¥é¿å…æç¤ºè¿‡é•¿
                    execution_output = output_str[:300] + ("..." if len(output_str) > 300 else "")
                elif execution_result.get('success'):
                    execution_output = "æ‰§è¡ŒæˆåŠŸï¼Œæ— ç‰¹å®šè¾“å‡º"
                else:
                    execution_output = "æ‰§è¡Œå¤±è´¥"
                execution_success = execution_result.get('success', False)
            elif isinstance(execution_result, str):
                execution_output = execution_result[:300] + ("..." if len(execution_result) > 300 else "")
                execution_success = execution_result.lower() not in ['failed', 'error', 'failure']
            else:
                execution_output = str(execution_result)
                execution_success = True
        else:
            execution_output = "æ— æ‰§è¡Œä¿¡æ¯"
            execution_success = False
        
        # å‡†å¤‡å˜é‡å­—å…¸
        variables = {
            # çŠ¶æ€ç›¸å…³
            'current_state': current_global_state or "å·¥ä½œæµåˆšå¼€å§‹",
            'previous_state': state_history[0].state_snapshot if state_history else "æ— å‰ç½®çŠ¶æ€",
            'state_history': state_history_text,
            
            # æ­¥éª¤ç›¸å…³
            'step_description': step_info.get('description', 'æœªçŸ¥æ­¥éª¤'),
            'step_type': step_info.get('type', 'æœªçŸ¥ç±»å‹'),
            'step_status': context.get('step_status', 'æœªçŸ¥'),
            
            # æ‰§è¡Œç›¸å…³
            'execution_success': str(execution_success),
            'execution_output': execution_output,
            'error_message': str(error_info) if error_info else 'æ— é”™è¯¯ä¿¡æ¯',
            
            # å·¥ä½œæµç›¸å…³
            'main_instruction': main_instruction,
            'workflow_progress': f"å·²æ‰§è¡Œ{current_state.get_state_history_count()}ä¸ªçŠ¶æ€æ›´æ–°"
        }
        
        return variables
    
    def _validate_generated_state(self, state: str, context: Optional[Dict[str, Any]] = None) -> bool:
        """éªŒè¯ç”Ÿæˆçš„çŠ¶æ€æè¿°æ˜¯å¦æœ‰æ•ˆï¼ˆä½¿ç”¨æ™ºèƒ½è§£æå™¨ï¼‰"""
        if not state or not isinstance(state, str):
            self._logger.warning("çŠ¶æ€æè¿°ä¸ºç©ºæˆ–éå­—ç¬¦ä¸²ç±»å‹")
            return False
        
        try:
            # ä½¿ç”¨ResponseParserè¿›è¡Œæ™ºèƒ½è§£æ
            parsed_info = self.response_parser.parse_response(state, context)
            
            # éªŒè¯è§£æç»“æœ
            is_valid, issues = self.response_parser.validate_parsed_info(parsed_info, min_confidence=0.3)
            
            if not is_valid:
                self._logger.warning(f"çŠ¶æ€æè¿°éªŒè¯å¤±è´¥: {'; '.join(issues)}")
                
                # å¦‚æœè§£æå¤±è´¥ï¼Œæä¾›æ”¹è¿›å»ºè®®
                suggestions = self.response_parser.suggest_improvements(parsed_info)
                if suggestions:
                    self._logger.info(f"æ”¹è¿›å»ºè®®: {'; '.join(suggestions)}")
                
                return False
            
            # è®°å½•è§£æç»“æœçš„è¯¦ç»†ä¿¡æ¯
            self._logger.debug(f"çŠ¶æ€è§£ææˆåŠŸ - ç½®ä¿¡åº¦: {parsed_info.confidence_score:.2f}, "
                             f"è´¨é‡: {parsed_info.quality_metrics.get('overall_quality', 'unknown')}, "
                             f"æƒ…æ„Ÿ: {parsed_info.sentiment}, æ„å›¾: {parsed_info.intent}")
            
            return True
            
        except Exception as e:
            self._logger.error(f"çŠ¶æ€éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            return False
    
    def get_last_parsed_info(self) -> Optional[ParsedStateInfo]:
        """è·å–æœ€åä¸€æ¬¡è§£æçš„çŠ¶æ€ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•å’Œç›‘æ§ï¼‰"""
        # è¿™é‡Œå¯ä»¥å­˜å‚¨æœ€åä¸€æ¬¡è§£æçš„ç»“æœï¼Œä¾›å¤–éƒ¨æŸ¥è¯¢
        # ç®€å•å®ç°ä¸­ç›´æ¥è¿”å›Noneï¼Œå®é™…å¯ä»¥æ·»åŠ ç¼“å­˜æœºåˆ¶
        return getattr(self, '_last_parsed_info', None)
    
    def _store_parsed_info(self, parsed_info: ParsedStateInfo) -> None:
        """å­˜å‚¨è§£æä¿¡æ¯ä¾›åç»­æŸ¥è¯¢"""
        with self._parsed_info_lock:
            self._last_parsed_info = parsed_info
    
    def _execute_fallback_strategies(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> Optional[str]:
        """
        æ‰§è¡Œå¤šå±‚å›é€€ç­–ç•¥
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ç”Ÿæˆçš„å›é€€çŠ¶æ€æè¿°ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        self._logger.info(f"å¼€å§‹æ‰§è¡Œå›é€€ç­–ç•¥ï¼Œå…±{len(self.fallback_strategies)}ä¸ªç­–ç•¥")
        
        for i, strategy in enumerate(self.fallback_strategies, 1):
            try:
                self._logger.debug(f"æ‰§è¡Œç¬¬{i}ä¸ªå›é€€ç­–ç•¥: {strategy.value}")
                
                if strategy == FallbackStrategy.RETRY_SIMPLIFIED:
                    # ç¬¬1å±‚ï¼šä½¿ç”¨ç®€åŒ–æç¤ºé‡è¯•
                    fallback_state = self._retry_with_simplified_prompt(current_state, context)
                elif strategy == FallbackStrategy.TEMPLATE_BASED:
                    # ç¬¬2å±‚ï¼šä½¿ç”¨æ¨¡æ¿åŒ–é»˜è®¤çŠ¶æ€
                    fallback_state = self.fallback_generator.generate_fallback_state(
                        strategy, current_state, context, self._last_failure_reason
                    )
                elif strategy == FallbackStrategy.RULE_BASED:
                    # ç¬¬3å±‚ï¼šä½¿ç”¨åŸºäºè§„åˆ™çš„é€»è¾‘
                    fallback_state = self.fallback_generator.generate_fallback_state(
                        strategy, current_state, context, self._last_failure_reason
                    )
                elif strategy == FallbackStrategy.MINIMAL_STATE:
                    # ç¬¬4å±‚ï¼šç”Ÿæˆæœ€å°çŠ¶æ€æè¿°
                    fallback_state = self.fallback_generator.generate_fallback_state(
                        strategy, current_state, context, self._last_failure_reason
                    )
                elif strategy == FallbackStrategy.NOTIFY_OPERATOR:
                    # ç¬¬5å±‚ï¼šé€šçŸ¥æ“ä½œå‘˜
                    fallback_state = self.fallback_generator.generate_fallback_state(
                        strategy, current_state, context, self._last_failure_reason
                    )
                    if self.enable_notifications:
                        self._send_failure_notification(context)
                else:
                    self._logger.warning(f"æœªçŸ¥çš„å›é€€ç­–ç•¥: {strategy}")
                    continue
                
                if fallback_state:
                    self._logger.info(f"å›é€€ç­–ç•¥ {strategy.value} æˆåŠŸç”ŸæˆçŠ¶æ€")
                    return fallback_state
                else:
                    self._logger.warning(f"å›é€€ç­–ç•¥ {strategy.value} å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥")
                    
            except Exception as e:
                self._logger.error(f"å›é€€ç­–ç•¥ {strategy.value} æ‰§è¡Œå¼‚å¸¸: {e}")
                continue
        
        self._logger.error("æ‰€æœ‰å›é€€ç­–ç•¥éƒ½å¤±è´¥äº†")
        return None
    
    def _retry_with_simplified_prompt(self, current_state: 'WorkflowState', context: Dict[str, Any]) -> Optional[str]:
        """
        ä½¿ç”¨ç®€åŒ–æç¤ºé‡è¯•LLMè°ƒç”¨
        
        Args:
            current_state: å½“å‰å·¥ä½œæµçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ç”Ÿæˆçš„çŠ¶æ€æè¿°ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            self._logger.debug("å°è¯•ä½¿ç”¨ç®€åŒ–æç¤ºé‡è¯•LLMè°ƒç”¨")
            
            # æ„å»ºç®€åŒ–çš„æç¤º
            step_info = context.get('step_info', {})
            step_name = step_info.get('description', 'å½“å‰æ­¥éª¤')
            step_status = context.get('step_status', 'unknown')
            error_info = context.get('error_info')
            
            if error_info:
                simple_prompt = f"æ­¥éª¤ '{step_name}' æ‰§è¡Œé‡åˆ°é—®é¢˜ï¼Œè¯·ç”¨ä¸€å¥è¯æè¿°å½“å‰çŠ¶æ€"
            elif step_status == 'completed':
                simple_prompt = f"æ­¥éª¤ '{step_name}' æ‰§è¡Œå®Œæˆï¼Œè¯·ç”¨ä¸€å¥è¯æè¿°å½“å‰çŠ¶æ€"
            else:
                simple_prompt = f"æ­¥éª¤ '{step_name}' æ­£åœ¨è¿›è¡Œï¼Œè¯·ç”¨ä¸€å¥è¯æè¿°å½“å‰çŠ¶æ€"
            
            # è°ƒç”¨LLM
            messages = [
                SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªçŠ¶æ€æè¿°ä¸“å®¶ï¼Œè¯·ç”¨ç®€æ´çš„ä¸­æ–‡å›å¤ã€‚"),
                HumanMessage(content=simple_prompt)
            ]
            
            response = self.llm.invoke(messages)
            
            if response and response.content:
                simplified_state = response.content.strip()
                if len(simplified_state) >= 5:  # åŸºæœ¬é•¿åº¦æ£€æŸ¥
                    self._logger.info("ç®€åŒ–æç¤ºé‡è¯•æˆåŠŸ")
                    return simplified_state
            
            self._logger.warning("ç®€åŒ–æç¤ºé‡è¯•å¤±è´¥æˆ–å“åº”è¿‡çŸ­")
            return None
            
        except Exception as e:
            self._logger.error(f"ç®€åŒ–æç¤ºé‡è¯•å¼‚å¸¸: {e}")
            return None
    
    def _send_failure_notification(self, context: Dict[str, Any]) -> None:
        """
        å‘é€å¤±è´¥é€šçŸ¥
        
        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        try:
            self._logger.warning(f"AIçŠ¶æ€æ›´æ–°å¤±è´¥é€šçŸ¥: å¤±è´¥æ¬¡æ•° {self._failure_count}, åŸå› : {self._last_failure_reason}")
            
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºå‘é€é‚®ä»¶ã€æ¶ˆæ¯é˜Ÿåˆ—æˆ–å…¶ä»–é€šçŸ¥æ–¹å¼
            # ç›®å‰åªè®°å½•æ—¥å¿—
            
            step_info = context.get('step_info', {})
            notification_details = {
                'timestamp': dt.now().isoformat(),
                'failure_count': self._failure_count,
                'failure_reason': self._last_failure_reason,
                'step_name': step_info.get('description', 'unknown'),
                'step_status': context.get('step_status', 'unknown')
            }
            
            self._logger.error(f"çŠ¶æ€æ›´æ–°å¤±è´¥é€šçŸ¥è¯¦æƒ…: {notification_details}")
            
        except Exception as e:
            self._logger.error(f"å‘é€å¤±è´¥é€šçŸ¥æ—¶å‡ºé”™: {e}")
    
    def get_fallback_statistics(self) -> Dict[str, Any]:
        """
        è·å–å›é€€æœºåˆ¶ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«å›é€€ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return {
            'failure_count': self._failure_count,
            'last_failure_reason': self._last_failure_reason,
            'fallback_strategies': [strategy.value for strategy in self.fallback_strategies],
            'notifications_enabled': self.enable_notifications
        }
    
    def reset_fallback_statistics(self) -> None:
        """é‡ç½®å›é€€ç»Ÿè®¡ä¿¡æ¯"""
        self._failure_count = 0
        self._last_failure_reason = ""
        self._logger.info("å›é€€ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")

    def get_fallback_statistics(self) -> Dict[str, Any]:
        """è·å–å›é€€ç»Ÿè®¡ä¿¡æ¯"""
        return getattr(self, '_fallback_stats', {
            'total_fallbacks': 0,
            'strategies_used': {},
            'success_rate': 0.0,
            'last_failure_time': None
        })
    
    def reset_fallback_statistics(self) -> None:
        """é‡ç½®å›é€€ç»Ÿè®¡ä¿¡æ¯"""
        self._fallback_stats = {
            'total_fallbacks': 0,
            'strategies_used': {},
            'success_rate': 0.0,
            'last_failure_time': None
        }
    
    def _update_fallback_statistics(self, strategy: FallbackStrategy, success: bool) -> None:
        """æ›´æ–°å›é€€ç»Ÿè®¡ä¿¡æ¯"""
        if not hasattr(self, '_fallback_stats'):
            self.reset_fallback_statistics()
        
        self._fallback_stats['total_fallbacks'] += 1
        
        strategy_name = strategy.value
        if strategy_name not in self._fallback_stats['strategies_used']:
            self._fallback_stats['strategies_used'][strategy_name] = {'count': 0, 'success': 0}
        
        self._fallback_stats['strategies_used'][strategy_name]['count'] += 1
        if success:
            self._fallback_stats['strategies_used'][strategy_name]['success'] += 1
        
        # è®¡ç®—æˆåŠŸç‡
        total_attempts = sum(s['count'] for s in self._fallback_stats['strategies_used'].values())
        total_successes = sum(s['success'] for s in self._fallback_stats['strategies_used'].values())
        self._fallback_stats['success_rate'] = total_successes / total_attempts if total_attempts > 0 else 0.0
        
        if not success:
            from datetime import datetime
            self._fallback_stats['last_failure_time'] = datetime.now().isoformat()
    
    # === ç¼“å­˜å’Œæ¡ä»¶é€»è¾‘ç®¡ç†æ–¹æ³• ===
    
    def get_cache_statistics(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.enable_caching or not self.cache:
            return {'enabled': False, 'message': 'ç¼“å­˜æœªå¯ç”¨'}
        
        return {
            'enabled': True,
            **self.cache.get_stats()
        }
    
    def clear_cache(self) -> bool:
        """æ¸…ç©ºç¼“å­˜"""
        if not self.enable_caching or not self.cache:
            return False
        
        self.cache.clear()
        self._logger.info("AIè°ƒç”¨ç¼“å­˜å·²æ¸…ç©º")
        return True
    
    def reset_cache_statistics(self) -> bool:
        """é‡ç½®ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.enable_caching or not self.cache:
            return False
        
        self.cache.reset_stats()
        self._logger.info("ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
        return True
    
    def get_condition_checker_config(self) -> Dict[str, Any]:
        """è·å–æ¡ä»¶æ£€æŸ¥å™¨é…ç½®"""
        if not self.enable_conditional_logic or not self.condition_checker:
            return {'enabled': False, 'message': 'æ¡ä»¶é€»è¾‘æœªå¯ç”¨'}
        
        return {
            'enabled': True,
            **self.condition_checker.get_configuration()
        }
    
    def update_condition_checker_config(self, 
                                       significance_threshold: Optional[float] = None,
                                       time_threshold_seconds: Optional[int] = None) -> bool:
        """æ›´æ–°æ¡ä»¶æ£€æŸ¥å™¨é…ç½®"""
        if not self.enable_conditional_logic or not self.condition_checker:
            return False
        
        if significance_threshold is not None:
            self.condition_checker.set_significance_threshold(significance_threshold)
            self._logger.info(f"æ˜¾è‘—æ€§é˜ˆå€¼å·²æ›´æ–°ä¸º: {significance_threshold}")
        
        if time_threshold_seconds is not None:
            self.condition_checker.set_time_threshold(time_threshold_seconds)
            self._logger.info(f"æ—¶é—´é˜ˆå€¼å·²æ›´æ–°ä¸º: {time_threshold_seconds}ç§’")
        
        return True
    
    def get_performance_statistics(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆæ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'ai_updater_service': {
                'llm_model': getattr(self.llm, 'model_name', getattr(self.llm, 'model', 'unknown')),
                'max_retries': self.max_retries,
                'retry_delay': self.retry_delay,
                'template_count': len(self.template_manager.list_templates()),
                'fallback_strategies_count': len(self.fallback_strategies)
            },
            'caching': self.get_cache_statistics(),
            'conditional_logic': self.get_condition_checker_config(),
            'fallback_stats': self.get_fallback_statistics()
        }
        
        return stats

class RegisteredAgent:
    """å­˜å‚¨å·²æ³¨å†Œçš„ Agent ä¿¡æ¯"""
    def __init__(self, name: str, instance: Agent, description: str):
        self.name = name
        self.instance = instance
        self.description = description

class WorkflowState:
    """å·¥ä½œæµçŠ¶æ€ç®¡ç†"""
    def __init__(self):
        # === ç°æœ‰å­—æ®µä¿æŒä¸å˜ ===
        self.current_step_index = 0
        self.loop_counters = {}      # {"loop_to_step3": 2}
        self.fix_counter = 0         # ä¿®å¤ä»»åŠ¡è®¡æ•°
        self.loop_targets = []       # å¾ªç¯ç›®æ ‡å†å²
        self.max_loops = 5           # æœ€å¤§å¾ªç¯æ¬¡æ•°é™åˆ¶
        self.context_variables = {}  # ä¸Šä¸‹æ–‡å˜é‡
        self.branch_history = []     # åˆ†æ”¯å†å²
        
        # === åŠ è½½é…ç½®ç³»ç»Ÿå‚æ•° ===
        if CONFIG_SYSTEM_AVAILABLE:
            try:
                config = get_config()
                state_config = config.state_history
                self._max_history_size = state_config.max_length
                self._auto_cleanup_enabled = state_config.auto_cleanup
                self._cleanup_interval_hours = state_config.cleanup_interval_hours
                self._compression_enabled = state_config.enable_compression
                self._compression_threshold = state_config.compression_threshold
                logger.info(f"ä½¿ç”¨é…ç½®ç³»ç»Ÿå‚æ•°: å†å²é•¿åº¦={self._max_history_size}, è‡ªåŠ¨æ¸…ç†={self._auto_cleanup_enabled}")
            except Exception as e:
                logger.warning(f"åŠ è½½é…ç½®ç³»ç»Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {e}")
                self._max_history_size = 50
                self._auto_cleanup_enabled = True
                self._cleanup_interval_hours = 24
                self._compression_enabled = False
                self._compression_threshold = 1000
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self._max_history_size = 50
            self._auto_cleanup_enabled = True
            self._cleanup_interval_hours = 24
            self._compression_enabled = False
            self._compression_threshold = 1000
        
        # === æ–°å¢ï¼šå…¨å±€çŠ¶æ€ç®¡ç† ===
        self._global_state = ""                    # å½“å‰è‡ªç„¶è¯­è¨€çŠ¶æ€
        self._state_update_enabled = True         # æ˜¯å¦å¯ç”¨çŠ¶æ€æ›´æ–°
        self._state_history = deque(maxlen=self._max_history_size)    # çŠ¶æ€å†å²ï¼Œä½¿ç”¨é…ç½®çš„é•¿åº¦
        
        # === æ—¥å¿—è®°å½•å™¨ ===
        self._logger = logging.getLogger(f"{__name__}.WorkflowState")
        
        # === å¹¶å‘ä¿æŠ¤ ===
        self._state_lock = threading.RLock()  # å¯é‡å…¥é”ï¼Œæ”¯æŒåŒä¸€çº¿ç¨‹å¤šæ¬¡è·å–
        
        # === æ€§èƒ½ç›‘æ§é›†æˆ ===
        self._performance_monitor = None
        if PERFORMANCE_MONITOR_AVAILABLE:
            try:
                self._performance_monitor = get_performance_monitor()
                self._logger.debug("æ€§èƒ½ç›‘æ§ç³»ç»Ÿå·²é›†æˆåˆ°WorkflowState")
            except Exception as e:
                self._logger.warning(f"æ€§èƒ½ç›‘æ§ç³»ç»Ÿé›†æˆå¤±è´¥: {e}")
        
        self._logger.debug(f"WorkflowStateåˆå§‹åŒ–å®Œæˆ - å…¨å±€çŠ¶æ€ç®¡ç†å·²å¯ç”¨ï¼Œå†å²é•¿åº¦={self._max_history_size}ï¼Œå¹¶å‘ä¿æŠ¤å·²æ¿€æ´»")

    def should_break_loop(self, target_step_id):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡ºå¾ªç¯ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰"""
        loop_key = f"loop_to_{target_step_id}"
        return self.loop_counters.get(loop_key, 0) >= self.max_loops
    
    def increment_loop_counter(self, target_step_id):
        """å¢åŠ å¾ªç¯è®¡æ•°å™¨"""
        loop_key = f"loop_to_{target_step_id}"
        self.loop_counters[loop_key] = self.loop_counters.get(loop_key, 0) + 1
    
    def reset_step_status_from(self, start_index, plan):
        """é‡ç½®ä»æŒ‡å®šç´¢å¼•å¼€å§‹çš„æ­¥éª¤çŠ¶æ€"""
        for i in range(start_index, len(plan)):
            if plan[i].get('status') in ['completed', 'failed']:
                plan[i]['status'] = 'pending'
    
    # === å…¨å±€çŠ¶æ€ç®¡ç†æ–¹æ³• ===
    
    def get_global_state(self) -> str:
        """è·å–å½“å‰å…¨å±€çŠ¶æ€"""
        with self._state_lock:
            return self._global_state
    
    def set_global_state(self, new_state: str, source: Optional[str] = None) -> None:
        """è®¾ç½®å…¨å±€çŠ¶æ€ï¼ˆå—æ›´æ–°å¼€å…³æ§åˆ¶ï¼‰"""
        with self._state_lock:
            if not self._state_update_enabled:
                self._logger.debug("çŠ¶æ€æ›´æ–°è¢«ç¦ç”¨ï¼Œè·³è¿‡çŠ¶æ€è®¾ç½®")
                return
            
            if not isinstance(new_state, str):
                raise TypeError("å…¨å±€çŠ¶æ€å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹")
            
            
            # å¦‚æœçŠ¶æ€å®é™…å‘ç”Ÿäº†å˜åŒ–ï¼Œè®°å½•åˆ°å†å²
            new_state = new_state.strip()
            if new_state != self._global_state:
                # ä¿å­˜å½“å‰çŠ¶æ€åˆ°å†å²ï¼ˆä¸å¯å˜å‰¯æœ¬ï¼‰
                if self._global_state:  # åªæœ‰åœ¨å½“å‰çŠ¶æ€éç©ºæ—¶æ‰ä¿å­˜
                    history_entry = StateHistoryEntry(
                        timestamp=dt.now(),
                        state_snapshot=copy.deepcopy(self._global_state),
                        source=source
                    )
                    self._state_history.append(history_entry)
                    self._logger.debug(f"çŠ¶æ€å†å²å·²æ›´æ–°ï¼Œå†å²è®°å½•æ•°é‡: {len(self._state_history)}")
                
                # æ›´æ–°å½“å‰çŠ¶æ€
                self._global_state = new_state
                self._logger.info(f"å…¨å±€çŠ¶æ€å·²æ›´æ–° (æ¥æº: {source or 'unknown'}) - æ–°çŠ¶æ€é•¿åº¦: {len(new_state)}")
            else:
                self._logger.debug("çŠ¶æ€æœªå‘ç”Ÿå˜åŒ–ï¼Œè·³è¿‡æ›´æ–°")
    
    def is_state_update_enabled(self) -> bool:
        """æ£€æŸ¥çŠ¶æ€æ›´æ–°æ˜¯å¦å¯ç”¨"""
        return self._state_update_enabled
    
    def enable_state_updates(self) -> None:
        """å¯ç”¨çŠ¶æ€æ›´æ–°"""
        with self._state_lock:
            self._state_update_enabled = True
            self._logger.info("çŠ¶æ€æ›´æ–°å·²å¯ç”¨")
    
    def disable_state_updates(self) -> None:
        """ç¦ç”¨çŠ¶æ€æ›´æ–°"""
        with self._state_lock:
            self._state_update_enabled = False
            self._logger.info("çŠ¶æ€æ›´æ–°å·²ç¦ç”¨")
    
    def clear_global_state(self) -> None:
        """æ¸…ç©ºå…¨å±€çŠ¶æ€"""
        with self._state_lock:
            if self._state_update_enabled:
                self._global_state = ""
                self._logger.info("å…¨å±€çŠ¶æ€å·²æ¸…ç©º")
            else:
                self._logger.debug("çŠ¶æ€æ›´æ–°è¢«ç¦ç”¨ï¼Œè·³è¿‡çŠ¶æ€æ¸…ç©º")
    
    # === çŠ¶æ€å†å²ç®¡ç†æ–¹æ³• ===
    
    def get_state_history(self, limit: Optional[int] = None) -> List[StateHistoryEntry]:
        """è·å–çŠ¶æ€å†å²è®°å½•"""
        with self._state_lock:
            history_list = list(self._state_history)
            if limit is not None and limit > 0:
                return history_list[-limit:]
            return history_list
    
    def get_state_history_count(self) -> int:
        """è·å–çŠ¶æ€å†å²è®°å½•æ•°é‡"""
        with self._state_lock:
            return len(self._state_history)
    
    def clear_state_history(self) -> None:
        """æ¸…ç©ºçŠ¶æ€å†å²"""
        with self._state_lock:
            if self._state_update_enabled:
                old_count = len(self._state_history)
                self._state_history.clear()
                self._logger.info(f"çŠ¶æ€å†å²å·²æ¸…ç©º (æ¸…ç©ºå‰è®°å½•æ•°: {old_count})")
            else:
                self._logger.debug("çŠ¶æ€æ›´æ–°è¢«ç¦ç”¨ï¼Œè·³è¿‡å†å²æ¸…ç©º")
    
    def get_state_summary(self) -> str:
        """è·å–çŠ¶æ€æ‘˜è¦ï¼ŒåŒ…å«å½“å‰çŠ¶æ€å’Œå†å²æ¦‚è§ˆ"""
        with self._state_lock:
            current = self._global_state if self._global_state else "æ— å½“å‰çŠ¶æ€"
            history_count = len(self._state_history)
            
            if history_count == 0:
                return f"å½“å‰çŠ¶æ€: {current}\nå†å²è®°å½•: æ— "
            
            latest_history = self._state_history[-1] if self._state_history else None
            latest_time = latest_history.timestamp.strftime("%H:%M:%S") if latest_history else "æœªçŸ¥"
            
            return f"""å½“å‰çŠ¶æ€: {current}
å†å²è®°å½•: {history_count}æ¡ (æœ€æ–°æ›´æ–°: {latest_time})"""
    
    def set_max_history_size(self, max_size: int) -> None:
        """è®¾ç½®æœ€å¤§å†å²è®°å½•æ•°é‡"""
        if max_size <= 0:
            raise ValueError("æœ€å¤§å†å²è®°å½•æ•°é‡å¿…é¡»å¤§äº0")
        
        with self._state_lock:
            old_size = self._max_history_size
            old_count = len(self._state_history)
            self._max_history_size = max_size
            
            # å¦‚æœéœ€è¦ï¼Œæˆªæ–­ç°æœ‰å†å²
            if len(self._state_history) > max_size:
                # ä¿ç•™æœ€æ–°çš„è®°å½•
                new_history = deque(list(self._state_history)[-max_size:], maxlen=max_size)
                self._state_history = new_history
                self._logger.info(f"å†å²è®°å½•å·²æˆªæ–­ - æ—§é™åˆ¶: {old_size}, æ–°é™åˆ¶: {max_size}, è®°å½•æ•°å˜åŒ–: {old_count} -> {len(self._state_history)}")
            else:
                self._logger.info(f"å†å²è®°å½•å¤§å°é™åˆ¶å·²æ›´æ–° - æ—§é™åˆ¶: {old_size}, æ–°é™åˆ¶: {max_size}, å½“å‰è®°å½•æ•°: {len(self._state_history)}")
    
    # === AIçŠ¶æ€æ›´æ–°å™¨é›†æˆæ–¹æ³• ===
    
    def __init_ai_updater(self) -> None:
        """åˆå§‹åŒ–AIçŠ¶æ€æ›´æ–°å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if not hasattr(self, '_ai_updater') or self._ai_updater is None:
            try:
                self._ai_updater = AIStateUpdaterService(llm_deepseek)
                
                # å¦‚æœå¯ç”¨äº†æ–°çš„å“åº”è§£æå™¨ï¼Œå°†å…¶ä¼ é€’ç»™AIçŠ¶æ€æ›´æ–°å™¨
                if (hasattr(self, 'enable_response_analysis') and 
                    self.enable_response_analysis and 
                    hasattr(self, 'response_parser') and 
                    self.response_parser is not None):
                    # æ›¿æ¢AIçŠ¶æ€æ›´æ–°å™¨çš„è§£æå™¨ä¸ºæ–°çš„å¤šæ–¹æ¡ˆè§£æå™¨
                    self._ai_updater.response_parser = self.response_parser
                    self._logger.info("AIçŠ¶æ€æ›´æ–°å™¨å·²åŒæ­¥ä½¿ç”¨æ–°çš„å¤šæ–¹æ¡ˆå“åº”è§£æå™¨")
                
                self._logger.info("AIçŠ¶æ€æ›´æ–°å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self._logger.error(f"AIçŠ¶æ€æ›´æ–°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self._ai_updater = None
    
    def update_state_with_ai(self, context: Dict[str, Any]) -> bool:
        """
        ä½¿ç”¨AIæ›´æ–°çŠ¶æ€
        
        Args:
            context: åŒ…å«æ­¥éª¤ä¿¡æ¯ã€æ‰§è¡Œç»“æœç­‰çš„ä¸Šä¸‹æ–‡å­—å…¸
                    æ”¯æŒçš„å­—æ®µï¼š
                    - step_info: æ­¥éª¤ä¿¡æ¯å­—å…¸
                    - execution_result: æ‰§è¡Œç»“æœ
                    - step_status: æ­¥éª¤çŠ¶æ€ ('completed', 'failed', etc.)
                    - error_info: é”™è¯¯ä¿¡æ¯
        
        Returns:
            æ˜¯å¦æˆåŠŸæ›´æ–°çŠ¶æ€
        """
        try:
            # æ‡’åŠ è½½AIæ›´æ–°å™¨
            self.__init_ai_updater()
            
            if self._ai_updater is None:
                self._logger.warning("AIçŠ¶æ€æ›´æ–°å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡AIçŠ¶æ€æ›´æ–°")
                return False
            
            # ä½¿ç”¨AIç”Ÿæˆæ–°çŠ¶æ€
            new_state = self._ai_updater.update_state(self, context)
            
            if new_state:
                # æ›´æ–°çŠ¶æ€ï¼Œæ ‡è®°æ¥æºä¸ºAI
                self.set_global_state(new_state, source="AI_DeepSeek")
                self._logger.info("AIçŠ¶æ€æ›´æ–°æˆåŠŸ")
                return True
            else:
                self._logger.debug("AIåˆ¤æ–­æ— éœ€æ›´æ–°çŠ¶æ€æˆ–æ›´æ–°å¤±è´¥")
                return False
                
        except Exception as e:
            self._logger.error(f"AIçŠ¶æ€æ›´æ–°è¿‡ç¨‹å‡ºé”™: {e}")
            return False
    
    def set_ai_updater(self, updater: AIStateUpdater) -> None:
        """
        è®¾ç½®è‡ªå®šä¹‰AIçŠ¶æ€æ›´æ–°å™¨
        
        Args:
            updater: å®ç°AIStateUpdateræ¥å£çš„æ›´æ–°å™¨å®ä¾‹
        """
        with self._state_lock:
            if not isinstance(updater, AIStateUpdater):
                raise TypeError("æ›´æ–°å™¨å¿…é¡»å®ç°AIStateUpdateræ¥å£")
            
            self._ai_updater = updater
            self._logger.info(f"è‡ªå®šä¹‰AIçŠ¶æ€æ›´æ–°å™¨è®¾ç½®æˆåŠŸ: {type(updater).__name__}")
    
    def get_ai_updater_status(self) -> Dict[str, Any]:
        """
        è·å–AIçŠ¶æ€æ›´æ–°å™¨çŠ¶æ€ä¿¡æ¯
        
        Returns:
            åŒ…å«çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
        """
        try:
            self.__init_ai_updater()
            
            if self._ai_updater is None:
                return {
                    "available": False,
                    "error": "AIçŠ¶æ€æ›´æ–°å™¨ä¸å¯ç”¨",
                    "type": None
                }
            
            return {
                "available": True,
                "type": type(self._ai_updater).__name__,
                "model": getattr(self._ai_updater.llm, 'model', 'Unknown') if hasattr(self._ai_updater, 'llm') else 'Unknown',
                "max_retries": getattr(self._ai_updater, 'max_retries', 'Unknown'),
                "state_update_enabled": self.is_state_update_enabled()
            }
            
        except Exception as e:
            return {
                "available": False,
                "error": str(e),
                "type": None
            }

    def __getstate__(self):
        """è‡ªå®šä¹‰åºåˆ—åŒ–çŠ¶æ€ï¼Œæ’é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
        state = self.__dict__.copy()
        # ç§»é™¤çº¿ç¨‹é”ï¼Œå®ƒä¸èƒ½è¢«åºåˆ—åŒ– - ä½¿ç”¨æ­£ç¡®çš„å±æ€§å
        state.pop('_state_lock', None)
        return state
    
    def __setstate__(self, state):
        """è‡ªå®šä¹‰ååºåˆ—åŒ–çŠ¶æ€ï¼Œé‡æ–°åˆ›å»ºçº¿ç¨‹é”"""
        self.__dict__.update(state)
        # é‡æ–°åˆ›å»ºçº¿ç¨‹é” - ä½¿ç”¨æ­£ç¡®çš„å±æ€§å
        self._state_lock = threading.RLock()
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯"""
        import sys
        import pickle
        
        try:
            # è®¡ç®—å¯¹è±¡å¤§å°
            global_state_size = sys.getsizeof(self._global_state)
            history_size = sys.getsizeof(self._state_history)
            
            # è®¡ç®—åºåˆ—åŒ–å¤§å°
            serialized_data = pickle.dumps(self)
            serialized_size = len(serialized_data)
            
            # è®¡ç®—å†å²è®°å½•ç»Ÿè®¡
            history_count = len(self._state_history)
            avg_state_size = 0
            if history_count > 0:
                total_state_size = sum(sys.getsizeof(entry.state_snapshot) for entry in self._state_history)
                avg_state_size = total_state_size / history_count
            
            return {
                'global_state_size_bytes': global_state_size,
                'history_total_size_bytes': history_size,
                'serialized_size_bytes': serialized_size,
                'history_count': history_count,
                'average_state_size_bytes': avg_state_size,
                'memory_efficiency': history_count / (serialized_size / 1024) if serialized_size > 0 else 0,
                'compression_ratio': (global_state_size + history_size) / serialized_size if serialized_size > 0 else 1.0
            }
        except Exception as e:
            logger.error(f"è·å–å†…å­˜ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                'error': str(e),
                'global_state_size_bytes': sys.getsizeof(self._global_state),
                'history_count': len(self._state_history),
                'status': 'partial_data'
            }
    
    def compress_history(self, compression_level: int = 6) -> bool:
        """å‹ç¼©å†å²è®°å½•ä»¥èŠ‚çœå†…å­˜"""
        try:
            import gzip
            
            if not self._state_history:
                return True
                
            with self._state_lock:
                # åˆ›å»ºæ–°çš„å‹ç¼©å†å²è®°å½•åˆ—è¡¨
                compressed_history = deque(maxlen=self._max_history_size)
                compressed_count = 0
                
                for entry in self._state_history:
                    if isinstance(entry.state_snapshot, str) and not entry.state_snapshot.startswith("__COMPRESSED__"):
                        # å‹ç¼©å­—ç¬¦ä¸²çŠ¶æ€
                        original_data = entry.state_snapshot.encode('utf-8')
                        compressed_data = gzip.compress(original_data, compresslevel=compression_level)
                        
                        # åªæœ‰åœ¨å‹ç¼©èƒ½æ˜¾è‘—å‡å°‘å¤§å°æ—¶æ‰ä½¿ç”¨å‹ç¼©
                        if len(compressed_data) < len(original_data) * 0.8:
                            # åˆ›å»ºæ–°çš„å‹ç¼©æ¡ç›®
                            compressed_snapshot = f"__COMPRESSED__{compressed_data.hex()}"
                            compressed_entry = StateHistoryEntry(
                                timestamp=entry.timestamp,
                                state_snapshot=compressed_snapshot,
                                source=entry.source
                            )
                            compressed_history.append(compressed_entry)
                            compressed_count += 1
                        else:
                            # å‹ç¼©æ•ˆæœä¸æ˜¾è‘—ï¼Œä¿æŒåŸæ ·
                            compressed_history.append(entry)
                    else:
                        # å·²ç»å‹ç¼©æˆ–éå­—ç¬¦ä¸²ï¼Œä¿æŒåŸæ ·
                        compressed_history.append(entry)
                
                # æ›¿æ¢åŸå†å²è®°å½•
                self._state_history = compressed_history
                logger.info(f"å†å²è®°å½•å‹ç¼©å®Œæˆï¼Œå‹ç¼©äº† {compressed_count}/{len(self._state_history)} æ¡è®°å½•")
                return True
                
        except Exception as e:
            logger.error(f"å†å²è®°å½•å‹ç¼©å¤±è´¥: {e}")
            return False
    
    def decompress_history_entry(self, state_snapshot: str) -> str:
        """è§£å‹ç¼©å•ä¸ªå†å²è®°å½•æ¡ç›®"""
        try:
            if state_snapshot.startswith("__COMPRESSED__"):
                import gzip
                
                # æå–å‹ç¼©æ•°æ®
                compressed_hex = state_snapshot[14:]  # ç§»é™¤ "__COMPRESSED__" å‰ç¼€
                compressed_data = bytes.fromhex(compressed_hex)
                
                # è§£å‹ç¼©
                decompressed_data = gzip.decompress(compressed_data)
                return decompressed_data.decode('utf-8')
            else:
                # æœªå‹ç¼©çš„æ•°æ®ï¼Œç›´æ¥è¿”å›
                return state_snapshot
        except Exception as e:
            logger.error(f"è§£å‹ç¼©å†å²è®°å½•å¤±è´¥: {e}")
            return state_snapshot  # è¿”å›åŸå§‹æ•°æ®ä½œä¸ºfallback
    
    def get_decompressed_history(self, limit: Optional[int] = None) -> List[StateHistoryEntry]:
        """è·å–è§£å‹ç¼©åçš„å†å²è®°å½•"""
        with self._state_lock:
            history = list(self._state_history)[:limit] if limit else list(self._state_history)
            
            # è§£å‹ç¼©çŠ¶æ€å¿«ç…§
            decompressed_history = []
            for entry in history:
                decompressed_snapshot = self.decompress_history_entry(entry.state_snapshot)
                decompressed_entry = StateHistoryEntry(
                    timestamp=entry.timestamp,
                    state_snapshot=decompressed_snapshot,
                    source=entry.source
                )
                decompressed_history.append(decompressed_entry)
            
            return decompressed_history
    
    def optimize_memory(self, enable_compression: bool = True, compression_level: int = 6) -> Dict[str, Any]:
        """æ‰§è¡Œå†…å­˜ä¼˜åŒ–"""
        optimization_results = {
            'initial_usage': self.get_memory_usage(),
            'optimizations_applied': [],
            'final_usage': {},
            'success': False
        }
        
        try:
            # 1. å†å²è®°å½•å‹ç¼©
            if enable_compression:
                if self.compress_history(compression_level):
                    optimization_results['optimizations_applied'].append('history_compression')
                    logger.info("å†å²è®°å½•å‹ç¼©ä¼˜åŒ–å·²åº”ç”¨")
                
            # 2. æ¸…ç†ç©ºå­—ç¬¦ä¸²çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            cleaned_count = 0
            with self._state_lock:
                original_count = len(self._state_history)
                self._state_history = deque(
                    [entry for entry in self._state_history if entry.state_snapshot.strip()],
                    maxlen=self._max_history_size
                )
                cleaned_count = original_count - len(self._state_history)
            
            if cleaned_count > 0:
                optimization_results['optimizations_applied'].append(f'cleaned_{cleaned_count}_empty_entries')
                logger.info(f"æ¸…ç†äº† {cleaned_count} ä¸ªç©ºå†å²è®°å½•æ¡ç›®")
            
            # 3. è·å–ä¼˜åŒ–åçš„å†…å­˜ä½¿ç”¨æƒ…å†µ
            optimization_results['final_usage'] = self.get_memory_usage()
            optimization_results['success'] = True
            
            # è®¡ç®—ä¼˜åŒ–æ•ˆæœ
            initial_size = optimization_results['initial_usage'].get('serialized_size_bytes', 0)
            final_size = optimization_results['final_usage'].get('serialized_size_bytes', 0)
            
            if initial_size > 0:
                space_saved = initial_size - final_size
                percentage_saved = (space_saved / initial_size) * 100
                optimization_results['space_saved_bytes'] = space_saved
                optimization_results['percentage_saved'] = percentage_saved
                
                logger.info(f"å†…å­˜ä¼˜åŒ–å®Œæˆï¼ŒèŠ‚çœäº† {space_saved} å­—èŠ‚ ({percentage_saved:.2f}%)")
            
        except Exception as e:
            logger.error(f"å†…å­˜ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            optimization_results['error'] = str(e)
        
        return optimization_results

class MultiStepAgent_v2(Agent):
    """
    æ–°ç‰ˆå¤šæ­¥éª¤æ™ºèƒ½ä½“ï¼šä¸ä¾èµ– workflow engineã€state managerã€agent registryã€‚
    åªå®ç° execute_multi_stepï¼Œè®¡åˆ’å’ŒçŠ¶æ€å­˜å‚¨åœ¨ StatefulExecutor çš„å˜é‡ä¸­ï¼Œæˆå‘˜ Agent é€šè¿‡å˜é‡æ³¨å†Œã€‚
    """

    def __init__(
        self,
        llm: BaseChatModel,
        registered_agents: Optional[List[RegisteredAgent]] = None,
        max_retries: int = 3,
        thinker_system_message: Optional[str] = None,
        thinker_chat_system_message: Optional[str] = None,
        planning_prompt_template: Optional[str] = None,  # æ–°å¢å‚æ•°
        use_autonomous_planning: bool = True,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨è‡ªä¸»è§„åˆ’æ¨¡å¼
    ):
        team_system_message=thinker_system_message
        if team_system_message is None:
            team_system_message=team_manager_system_message_no_share_state
        
        super().__init__(
            llm=llm,
            stateful=True,
            thinker_system_message=team_system_message,
            thinker_chat_system_message=thinker_chat_system_message,
            max_retries=max_retries,
        )
        self.device = StatefulExecutor()
        self.registered_agents = registered_agents if registered_agents is not None else []
        self.max_retries = max_retries
        self.thinker_chat_system_message = thinker_chat_system_message
        # æ³¨å†Œæˆå‘˜ Agent åˆ° StatefulExecutor çš„å˜é‡ç©ºé—´
        for spec in self.registered_agents:
            self.device.set_variable(spec.name, spec.instance)
        # åˆå§‹åŒ– current_plan
        self.device.set_variable("current_plan", [])
        # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€ (æ–¹æ¡ˆ2)
        self.workflow_state = WorkflowState()
        self.original_goal = ""
        self.use_autonomous_planning = use_autonomous_planning
        
        # åˆå§‹åŒ–é”™è¯¯å¤„ç†æœºåˆ¶
        self.error_dispatcher = WorkflowErrorDispatcher()
        # æ³¨å†Œé€šç”¨é”™è¯¯å¤„ç†å™¨
        self.error_dispatcher.register_handler(GenericErrorHandler())
        
        # é”™è¯¯å¤„ç†ç»Ÿè®¡
        self.error_statistics = {
            'total_errors': 0,
            'handled_errors': 0,
            'unhandled_errors': 0,
            'error_types': {},
            'recovery_success_rate': 0.0
        }
        
        # åˆå§‹åŒ–æŒ‡ä»¤ä¼˜åŒ–ç³»ç»Ÿ
        self.instruction_optimizer = StateAwareInstructionOptimizer(
            strategy=OptimizationStrategy.MODERATE
        )
        self.optimization_enabled = True  # é»˜è®¤å¯ç”¨æŒ‡ä»¤ä¼˜åŒ–
        
        # åˆå§‹åŒ–å†³ç­–ç®¡ç†ç³»ç»Ÿ
        self.decision_manager = StateAwareDecisionManager()
        logger.info("çŠ¶æ€æ„ŸçŸ¥å†³ç­–ç®¡ç†å™¨å·²åˆå§‹åŒ–")
        
        # è®¾ç½®é»˜è®¤çš„è®¡åˆ’ç”Ÿæˆæç¤ºè¯æ¨¡æ¿
        if planning_prompt_template:
            # ç”¨æˆ·æä¾›äº†è‡ªå®šä¹‰æ¨¡æ¿ï¼Œä½¿ç”¨ç¿»è¯‘æ¨¡å¼
            self.planning_prompt_template = planning_prompt_template
            self.use_autonomous_planning = False
        elif use_autonomous_planning:
            # ä½¿ç”¨è‡ªä¸»è§„åˆ’æ¨¡å¼çš„é»˜è®¤æ¨¡æ¿
            self.planning_prompt_template = """
# ä»»åŠ¡èƒŒæ™¯
ä½ æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“å›¢é˜Ÿçš„åè°ƒè€…ï¼Œè´Ÿè´£å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„æ­¥éª¤ï¼Œå¹¶ä¸ºæ¯ä¸ªæ­¥éª¤åˆ†é…åˆé€‚çš„æ‰§è¡Œè€…ã€‚

# å¯ç”¨æ™ºèƒ½ä½“åˆ—è¡¨
{available_agents_str}

# ä¸»ä»»åŠ¡
{main_instruction}

# ä¸‰é˜¶æ®µæ‰§è¡Œè®¡åˆ’æ¡†æ¶
è¯·å°†ä»»åŠ¡åˆ†è§£ä¸ºä¸‰ä¸ªå…³é”®é˜¶æ®µï¼š

1. ä¿¡æ¯æ”¶é›†é˜¶æ®µ: æ˜ç¡®ä¸ºè¾¾æˆç›®æ ‡éœ€è¦æ”¶é›†å“ªäº›ä¿¡æ¯ï¼Œæ¯æ¡ä¿¡æ¯ä¸ºä»€ä¹ˆå¿…è¦
2. æ‰§è¡Œé˜¶æ®µ: å…·ä½“çš„å®ç°æ­¥éª¤ï¼Œæ¯ä¸€æ­¥å¦‚ä½•åˆ©ç”¨æ”¶é›†çš„ä¿¡æ¯
3. éªŒè¯ä¸ä¿®å¤é˜¶æ®µ: å¦‚ä½•éªŒè¯ç»“æœï¼Œä»¥åŠåœ¨å¤±è´¥æ—¶éœ€è¦æ”¶é›†ä»€ä¹ˆé¢å¤–ä¿¡æ¯æ¥ä¿®å¤é—®é¢˜

# è¾“å‡ºè¦æ±‚
è¯·å°†ä¸»ä»»åŠ¡åˆ†è§£ä¸ºæœ‰åºçš„æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤å¿…é¡»æŒ‡å®šä»¥ä¸‹ä¿¡æ¯:
1. id: æ­¥éª¤å”¯ä¸€æ ‡è¯†ç¬¦(å»ºè®®ä½¿ç”¨"info1", "exec2", "verify3"ç­‰å½¢å¼ï¼Œä»¥è¡¨æ˜æ‰€å±é˜¶æ®µ)
2. name: ç®€çŸ­çš„æ­¥éª¤åç§°
3. instruction: è¯¦ç»†çš„æ‰§è¡ŒæŒ‡ä»¤ï¼Œéœ€è¦æ¸…æ™°æ˜ç¡®
4. agent_name: æ‰§è¡Œè¯¥æ­¥éª¤çš„æ™ºèƒ½ä½“åç§°ï¼Œå¿…é¡»ä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©: {available_agent_names}
5. instruction_type: æŒ‡ä»¤ç±»å‹(execution/information) - è§ä¸‹æ–¹è¯´æ˜
6. phase: æ­¥éª¤æ‰€å±é˜¶æ®µ(information/execution/verification)
7. expected_output: é¢„æœŸè¾“å‡ºï¼Œæ˜ç¡®è¯¥æ­¥éª¤åº”è¯¥äº§ç”Ÿä»€ä¹ˆç»“æœ
8. prerequisites: æ‰§è¡Œæ­¤æ­¥éª¤éœ€è¦æ»¡è¶³çš„å…ˆå†³æ¡ä»¶(è‡ªç„¶è¯­è¨€æè¿°)ï¼Œå¦‚æ— è¦æ±‚åˆ™ä¸º"æ— "

# æ™ºèƒ½ä½“æ„æˆè¯´æ˜
æ¯ä¸ªæ™ºèƒ½ä½“ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
1. è®°å¿†ï¼šå­˜å‚¨å¯¹è¯å†å²ã€çŸ¥è¯†å’ŒçŠ¶æ€ä¿¡æ¯
2. æœ‰çŠ¶æ€çš„jupyter notebook kernelï¼šç”¨äºæ‰§è¡Œä»£ç å’Œä¸å¤–éƒ¨ç¯å¢ƒäº¤äº’

# æŒ‡ä»¤ç±»å‹è¯´æ˜
- execution: æ‰§è¡Œæ€§ä»»åŠ¡ï¼Œä¼šè°ƒç”¨jupyter notebookæ‰§è¡Œä»£ç å¯¹å¤–éƒ¨ä¸–ç•Œäº§ç”Ÿè¡Œä¸ºæˆ–è§‚å¯Ÿï¼ŒåŒæ—¶æ”¹å˜æ™ºèƒ½ä½“çš„è®°å¿†ï¼ˆå¦‚æ‰§è¡Œä»£ç ã€æ–‡ä»¶æ“ä½œã€æ•°æ®å†™å…¥ã€è§‚å¯Ÿå¤–éƒ¨ç¯å¢ƒç­‰ï¼‰
- information: ä¿¡æ¯æ€§ä»»åŠ¡ï¼Œåªæ˜¯å¯¹æ™ºèƒ½ä½“è®°å¿†çš„æŸ¥è¯¢æˆ–ä¿®æ”¹ï¼Œä¸ä¼šè°ƒç”¨jupyter notebookï¼ˆå¦‚æŸ¥è¯¢å†å²å¯¹è¯ã€å‘ŠçŸ¥çŠ¶æ€ç­‰ï¼‰

# è§„åˆ’è§„åˆ™
1. åˆ†æä»»åŠ¡ç‰¹ç‚¹ï¼Œåˆç†æ‹†åˆ†æ­¥éª¤
2. æ ¹æ®æ¯ä¸ªæ™ºèƒ½ä½“çš„ä¸“é•¿åˆ†é…ä»»åŠ¡
3. ç”¨è‡ªç„¶è¯­è¨€æè¿°æ¯ä¸ªæ­¥éª¤çš„å…ˆå†³æ¡ä»¶ï¼Œè€Œéç¡¬ç¼–ç ä¾èµ–å…³ç³»
4. ä¸ºæ¯ä¸ªæ­¥éª¤æä¾›è¶³å¤Ÿè¯¦ç»†çš„æŒ‡ä»¤
5. ä¿¡æ¯æ”¶é›†é˜¶æ®µåº”å½»åº•ï¼Œç¡®ä¿æ‰§è¡Œé˜¶æ®µæœ‰è¶³å¤Ÿè¾“å…¥æ•°æ®
6. æ‰§è¡Œé˜¶æ®µåº”æ˜ç¡®å¦‚ä½•ä½¿ç”¨å‰é¢æ­¥éª¤æ”¶é›†çš„ä¿¡æ¯
7. éªŒè¯é˜¶æ®µåº”å®šä¹‰æ˜ç¡®çš„æˆåŠŸæ ‡å‡†ï¼Œå¹¶é¢„è§å¯èƒ½çš„å¤±è´¥åœºæ™¯
"""
        else:
            # ä½¿ç”¨ç¿»è¯‘æ¨¡å¼çš„é»˜è®¤æ¨¡æ¿ (æ–¹æ¡ˆ2: åŠ¨æ€å†³ç­–æ§åˆ¶)
            self.planning_prompt_template = """
# ä»»åŠ¡èƒŒæ™¯
ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµç¿»è¯‘å™¨ï¼Œè´Ÿè´£å°†ç”¨æˆ·ç”¨è‡ªç„¶è¯­è¨€æè¿°çš„æ­¥éª¤ç¿»è¯‘æˆç®€å•çš„çº¿æ€§æ‰§è¡Œè®¡åˆ’ã€‚å¤æ‚çš„æ§åˆ¶æµé€»è¾‘ï¼ˆå¦‚å¾ªç¯ã€æ¡ä»¶åˆ†æ”¯ï¼‰å°†ç”±å†³ç­–è€…åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€å¤„ç†ã€‚

# é‡è¦åŸåˆ™
- **ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·å®šä¹‰çš„æ­¥éª¤è¿›è¡Œç¿»è¯‘ï¼Œä¸è¦æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹æ­¥éª¤æ•°é‡å’Œæ ¸å¿ƒå†…å®¹**
- **ä¿æŒç”¨æˆ·åŸå§‹æ­¥éª¤çš„é¡ºåºå’Œä¸»è¦æ„å›¾ä¸å˜**
- **å°†å¤æ‚çš„æ§åˆ¶æµï¼ˆå¦‚whileå¾ªç¯ã€ifæ¡ä»¶ï¼‰ç®€åŒ–ä¸ºåŸºæœ¬çš„çº¿æ€§æ­¥éª¤**
- **å¯¹äºç¼ºå¤±çš„å­—æ®µä¿¡æ¯ï¼Œå¯ä»¥åŸºäºä¸Šä¸‹æ–‡è¿›è¡Œåˆç†æ¨æµ‹å’Œè¡¥å……**

# å¯ç”¨æ™ºèƒ½ä½“åˆ—è¡¨
{available_agents_str}

# ç”¨æˆ·åŸå§‹æ­¥éª¤æè¿°
{main_instruction}

# ç¿»è¯‘è¦æ±‚
è¯·å°†ç”¨æˆ·æè¿°çš„å·¥ä½œæµç¿»è¯‘æˆç®€å•çš„çº¿æ€§æ­¥éª¤åºåˆ—ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«:
1. id: æ­¥éª¤å”¯ä¸€æ ‡è¯†ç¬¦(å»ºè®®ä½¿ç”¨"step1", "step2"ç­‰å½¢å¼ï¼ŒæŒ‰ç”¨æˆ·æ­¥éª¤é¡ºåº)
2. name: åŸºäºç”¨æˆ·æ­¥éª¤å†…å®¹çš„ç®€çŸ­åç§°
3. instruction: ç”¨æˆ·åŸå§‹æ­¥éª¤çš„è¯¦ç»†æè¿°ï¼Œä¿æŒåŸæ„ä¸å˜
4. agent_name: æœ€é€‚åˆæ‰§è¡Œè¯¥æ­¥éª¤çš„æ™ºèƒ½ä½“åç§°ï¼Œå¿…é¡»ä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©: {available_agent_names}
5. instruction_type: æŒ‡ä»¤ç±»å‹(execution/information) - è§ä¸‹æ–¹è¯´æ˜
6. phase: æ­¥éª¤ç±»å‹(information/execution/verification)
7. expected_output: åŸºäºæ­¥éª¤å†…å®¹æ¨æ–­çš„é¢„æœŸè¾“å‡º
8. prerequisites: æ‰§è¡Œæ­¤æ­¥éª¤éœ€è¦æ»¡è¶³çš„å…ˆå†³æ¡ä»¶(è‡ªç„¶è¯­è¨€æè¿°)ï¼Œå¦‚æ— è¦æ±‚åˆ™ä¸º"æ— "

# æ™ºèƒ½ä½“æ„æˆè¯´æ˜
æ¯ä¸ªæ™ºèƒ½ä½“ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
1. è®°å¿†ï¼šå­˜å‚¨å¯¹è¯å†å²ã€çŸ¥è¯†å’ŒçŠ¶æ€ä¿¡æ¯
2. æœ‰çŠ¶æ€çš„jupyter notebook kernelï¼šç”¨äºæ‰§è¡Œä»£ç å’Œä¸å¤–éƒ¨ç¯å¢ƒäº¤äº’

# æŒ‡ä»¤ç±»å‹è¯´æ˜
- execution: æ‰§è¡Œæ€§ä»»åŠ¡ï¼Œä¼šè°ƒç”¨jupyter notebookæ‰§è¡Œä»£ç å¯¹å¤–éƒ¨ä¸–ç•Œäº§ç”Ÿè¡Œä¸ºæˆ–è§‚å¯Ÿï¼ŒåŒæ—¶æ”¹å˜æ™ºèƒ½ä½“çš„è®°å¿†ï¼ˆå¦‚æ‰§è¡Œä»£ç ã€æ–‡ä»¶æ“ä½œã€æ•°æ®å†™å…¥ã€è§‚å¯Ÿå¤–éƒ¨ç¯å¢ƒç­‰ï¼‰
- information: ä¿¡æ¯æ€§ä»»åŠ¡ï¼Œåªæ˜¯å¯¹æ™ºèƒ½ä½“è®°å¿†çš„æŸ¥è¯¢æˆ–ä¿®æ”¹ï¼Œä¸ä¼šè°ƒç”¨jupyter notebookï¼ˆå¦‚æŸ¥è¯¢å†å²å¯¹è¯ã€å‘ŠçŸ¥çŠ¶æ€ç­‰ï¼‰

# æ§åˆ¶æµå¤„ç†åŸåˆ™
- **whileå¾ªç¯**: å°†å¾ªç¯ä½“å†…çš„æ­¥éª¤æå–ä¸ºæ™®é€šæ­¥éª¤ï¼Œå¾ªç¯æ§åˆ¶ç”±å†³ç­–è€…å¤„ç†
- **ifæ¡ä»¶**: å°†æ¡ä»¶åˆ¤æ–­å’Œåˆ†æ”¯æ“ä½œæå–ä¸ºæ™®é€šæ­¥éª¤ï¼Œæ¡ä»¶åˆ¤æ–­ç”±å†³ç­–è€…å¤„ç†
- **å¤æ‚é€»è¾‘**: åˆ†è§£ä¸ºåŸºæœ¬çš„æ‰§è¡Œæ­¥éª¤å’Œå†³ç­–æ­¥éª¤

# ç¿»è¯‘è§„åˆ™
1. **ä¸¥æ ¼éµå¾ªç”¨æˆ·æ­¥éª¤çš„æ•°é‡å’Œé¡ºåº**
2. **ä¸è¦åˆå¹¶ã€æ‹†åˆ†æˆ–é‡æ–°ç»„ç»‡ç”¨æˆ·çš„æ­¥éª¤**
3. **ä¿æŒæ¯ä¸ªæ­¥éª¤çš„æ ¸å¿ƒæ„å›¾å’Œä¸»è¦å†…å®¹**
4. æ ¹æ®æ­¥éª¤å†…å®¹é€‰æ‹©æœ€åˆé€‚çš„æ™ºèƒ½ä½“
5. æ ¹æ®æ­¥éª¤æ€§è´¨åˆ¤æ–­instruction_typeå’Œphase
6. ç”¨è‡ªç„¶è¯­è¨€æè¿°æ¯ä¸ªæ­¥éª¤çš„å…ˆå†³æ¡ä»¶ï¼Œè€Œéç¡¬ç¼–ç ä¾èµ–å…³ç³»
7. **å¯¹äºç¼ºå¤±å­—æ®µçš„æ¨æµ‹åŸåˆ™**ï¼š
   - agent_name: æ ¹æ®æ­¥éª¤å†…å®¹æ¨æµ‹æœ€é€‚åˆçš„æ™ºèƒ½ä½“
   - instruction_type: æ ¹æ®æ­¥éª¤æ€§è´¨æ¨æµ‹(éœ€è¦è°ƒç”¨jupyter notebookæ‰§è¡Œä»£ç ã€æ–‡ä»¶æ“ä½œã€æ•°æ®å†™å…¥ç­‰é€‰executionï¼Œä»…éœ€æŸ¥è¯¢æˆ–ä¿®æ”¹æ™ºèƒ½ä½“è®°å¿†é€‰information)
   - phase: æ ¹æ®æ­¥éª¤åœ¨æ•´ä½“æµç¨‹ä¸­çš„ä½œç”¨æ¨æµ‹(æ”¶é›†ä¿¡æ¯é€‰informationï¼Œå…·ä½“å®æ–½é€‰executionï¼Œæ£€æŸ¥éªŒè¯é€‰verification)
   - expected_output: æ ¹æ®æ­¥éª¤æè¿°æ¨æµ‹å¯èƒ½çš„è¾“å‡ºç»“æœ
   - prerequisites: æ ¹æ®æ­¥éª¤é—´çš„é€»è¾‘å…³ç³»æè¿°å…ˆå†³æ¡ä»¶
8. **å¯¹äºinstructionå­—æ®µçš„å¤„ç†**ï¼šä¿æŒç”¨æˆ·åŸå§‹æè¿°ï¼Œå¿…è¦æ—¶å¯é€‚å½“è¡¥å……æ‰§è¡Œç»†èŠ‚ä»¥ç¡®ä¿å¯æ“ä½œæ€§

# ç¤ºä¾‹ç¿»è¯‘

## ç”¨æˆ·è¾“å…¥ï¼š
```
1. è°ƒç”¨coderå®ç°è®¡ç®—å™¨
2. è°ƒç”¨coderä¿å­˜ä»£ç   
while true {{
    3. è°ƒç”¨testerè¿è¡Œæµ‹è¯•
    4. å¦‚æœè¿è¡Œæ­£ç¡®: ç»ˆæ­¢å·¥ä½œæµ
    5. å¦‚æœæŠ¥é”™: å‘ç»™coderä¿®å¤
}}
```

## ç¿»è¯‘è¾“å‡ºï¼š
```json
{{
  "steps": [
    {{
      "id": "step1",
      "name": "å®ç°è®¡ç®—å™¨",
      "instruction": "è°ƒç”¨coderå®ç°ä¸€ä¸ªç®€å•çš„è®¡ç®—å™¨ç±»ï¼Œè¦åŒ…å«å•å…ƒæµ‹è¯•",
      "agent_name": "coder",
      "instruction_type": "execution",
      "phase": "execution",
      "expected_output": "è®¡ç®—å™¨ç±»ä»£ç ",
      "prerequisites": "æ— "
    }},
    {{
      "id": "step2", 
      "name": "ä¿å­˜ä»£ç ",
      "instruction": "è°ƒç”¨coderæŠŠä»£ç ä¿å­˜åˆ°æ–‡ä»¶",
      "agent_name": "coder",
      "instruction_type": "execution",
      "phase": "execution",
      "expected_output": "ä»£ç æ–‡ä»¶",
      "prerequisites": "è®¡ç®—å™¨ä»£ç å·²å®ç°"
    }},
    {{
      "id": "step3",
      "name": "è¿è¡Œæµ‹è¯•",
      "instruction": "è°ƒç”¨testerè¿è¡Œæµ‹è¯•ï¼Œæ£€æŸ¥ä»£ç æ˜¯å¦æ­£ç¡®",
      "agent_name": "tester",
      "instruction_type": "execution", 
      "phase": "verification",
      "expected_output": "æµ‹è¯•ç»“æœ",
      "prerequisites": "ä»£ç æ–‡ä»¶å·²ä¿å­˜"
    }},
    {{
      "id": "step4",
      "name": "åˆ†ææµ‹è¯•ç»“æœå¹¶å†³ç­–",
      "instruction": "åˆ†ææµ‹è¯•ç»“æœï¼Œå¦‚æœæµ‹è¯•é€šè¿‡åˆ™å®Œæˆå·¥ä½œæµï¼Œå¦‚æœæµ‹è¯•å¤±è´¥åˆ™ç”Ÿæˆä¿®å¤ä»»åŠ¡å¹¶å¾ªç¯å›åˆ°æµ‹è¯•æ­¥éª¤",
      "agent_name": "tester",
      "instruction_type": "information",
      "phase": "verification", 
      "expected_output": "å†³ç­–ç»“æœ",
      "prerequisites": "æµ‹è¯•å·²å®Œæˆå¹¶æœ‰ç»“æœ"
    }}
  ]
}}
```
"""
        
        # åˆå§‹åŒ–å¤šæ–¹æ¡ˆå“åº”è§£æå™¨
        self._init_response_parser()

    def _init_response_parser(self, 
                             parser_method: Union[str, ParserMethod] = "rule",
                             parser_config: Optional[Dict[str, Any]] = None,
                             enable_response_analysis: bool = True,
                             enable_execution_monitoring: bool = True):
        """
        åˆå§‹åŒ–å¤šæ–¹æ¡ˆå“åº”è§£æå™¨
        
        Args:
            parser_method: è§£æå™¨æ–¹æ³• ("rule", "transformer", "deepseek", "embedding", "hybrid")
            parser_config: è§£æå™¨é…ç½®å‚æ•°
            enable_response_analysis: æ˜¯å¦å¯ç”¨å“åº”åˆ†æ
            enable_execution_monitoring: æ˜¯å¦å¯ç”¨æ‰§è¡Œç›‘æ§
        """
        # è§£æå™¨é…ç½®
        self.enable_response_analysis = enable_response_analysis
        self.enable_execution_monitoring = enable_execution_monitoring
        
        if not RESPONSE_PARSER_AVAILABLE:
            logger.warning("å¤šæ–¹æ¡ˆå“åº”è§£æå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
            self.response_parser = None
            self.parsed_responses_history = []
            return
        
        try:
            # åˆå§‹åŒ–è§£æå™¨
            if isinstance(parser_method, str):
                parser_method = ParserMethod(parser_method) if parser_method in ["rule", "transformer", "deepseek", "embedding", "hybrid"] else ParserMethod.RULE
            
            parser_config = parser_config or {}
            
            # æ ¹æ®æ–¹æ³•ç±»å‹åˆ›å»ºè§£æå™¨
            if parser_method == ParserMethod.RULE:
                self.response_parser = ParserFactory.create_rule_parser(**parser_config)
            elif parser_method == ParserMethod.TRANSFORMER:
                model_name = parser_config.get('model_name', 'hfl/chinese-bert-wwm-ext')
                # ä»parser_configä¸­ç§»é™¤model_nameä»¥é¿å…é‡å¤ä¼ é€’
                transformer_config = {k: v for k, v in parser_config.items() if k != 'model_name'}
                self.response_parser = ParserFactory.create_transformer_parser(model_name=model_name, **transformer_config)
            elif parser_method == ParserMethod.DEEPSEEK:
                api_key = parser_config.get('api_key') or parser_config.get('DEEPSEEK_API_KEY')
                if not api_key:
                    import os
                    api_key = os.getenv('DEEPSEEK_API_KEY')
                if api_key:
                    # ä»parser_configä¸­ç§»é™¤api_keyå’Œapi_baseä»¥é¿å…é‡å¤ä¼ é€’
                    deepseek_config = {k: v for k, v in parser_config.items() if k not in ['api_key', 'api_base', 'DEEPSEEK_API_KEY']}
                    api_base = parser_config.get('api_base')
                    self.response_parser = ParserFactory.create_deepseek_parser(api_key=api_key, api_base=api_base, **deepseek_config)
                else:
                    logger.warning("DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œé™çº§åˆ°è§„åˆ™è§£æå™¨")
                    self.response_parser = ParserFactory.create_rule_parser(**parser_config)
            elif parser_method == ParserMethod.EMBEDDING:
                model_name = parser_config.get('model_name', 'paraphrase-multilingual-MiniLM-L12-v2')
                # ä»parser_configä¸­ç§»é™¤model_nameä»¥é¿å…é‡å¤ä¼ é€’
                embedding_config = {k: v for k, v in parser_config.items() if k != 'model_name'}
                self.response_parser = ParserFactory.create_embedding_parser(model_name=model_name, **embedding_config)
            else:  # hybrid
                primary_method = parser_config.get('primary_method', ParserMethod.RULE)
                fallback_chain = parser_config.get('fallback_chain', [ParserMethod.RULE])
                filtered_config = {k: v for k, v in parser_config.items() if k not in ['primary_method', 'fallback_chain']}
                self.response_parser = ParserFactory.create_hybrid_parser(
                    primary_method=primary_method,
                    fallback_chain=fallback_chain,
                    **filtered_config
                )
                
            # åˆå§‹åŒ–è§£æå†å²
            self.parsed_responses_history = []
            
            # è§£æå™¨å‚æ•°
            self.confidence_threshold = parser_config.get('confidence_threshold', 0.6)
            self.auto_retry_on_low_confidence = parser_config.get('auto_retry', False)
            
            logger.info(f"å¤šæ–¹æ¡ˆå“åº”è§£æå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ–¹æ³•: {parser_method}")
            
        except Exception as e:
            logger.error(f"å“åº”è§£æå™¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œç¦ç”¨è§£æåŠŸèƒ½")
            self.response_parser = None
            self.parsed_responses_history = []

    def register_agent(self, name: str, instance: Agent):
        """æ³¨å†Œä¸€ä¸ªæ–°çš„ Agentã€‚"""
        # è·å–Agentçš„æè¿°ï¼Œå¦‚æœæ²¡æœ‰api_specificationå±æ€§åˆ™ä½¿ç”¨é»˜è®¤æè¿°
        description = getattr(instance, 'api_specification', f"{name}æ™ºèƒ½ä½“ï¼Œé€šç”¨ä»»åŠ¡æ‰§è¡Œè€…")
        spec = RegisteredAgent(name=name, instance=instance, description=description)
        self.registered_agents.append(spec)
        self.device.set_variable(spec.name, spec.instance)
        logger.debug(f"å·²æ³¨å†Œ Agent: {name}")
    


    def plan_execution(self, main_instruction: str) -> List[Dict[str, Any]]:
        """
        æ ¹æ®ä¸»æŒ‡ä»¤è§„åˆ’æ‰§è¡Œæ­¥éª¤ï¼Œæ”¯æŒè‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿ã€‚
        """
        
        # æ„å»ºå¯ç”¨ Agent çš„æè¿°å­—ç¬¦ä¸²
        available_agents_str = "\n".join(
            [f"- {spec.name}: {spec.description}" for spec in self.registered_agents]
        )
        if not available_agents_str:
            available_agents_str = "æ— å¯ç”¨ Agentã€‚è¯·ç¡®ä¿å·²æ³¨å†Œ Agentã€‚"
            
        # è·å–å¯ç”¨ Agent åç§°åˆ—è¡¨
        available_agent_names = [spec.name for spec in self.registered_agents] or ["æ— "]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¸€æ¬¡å¤±è´¥çš„éªŒè¯ç»“æœ
        previous_attempt_failed = False
        previous_verification = None
        previous_plan = None
        
        if hasattr(self, 'device'):
            try:
                previous_attempt_failed_var = self.device.get_variable("previous_attempt_failed")
                previous_attempt_failed = previous_attempt_failed_var if previous_attempt_failed_var is not None else False
            except:
                previous_attempt_failed = False
                
            try:
                previous_verification = self.device.get_variable("previous_verification")
            except:
                previous_verification = None
                
            try:
                previous_plan = self.device.get_variable("previous_plan")
            except:
                previous_plan = None

        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæç¤ºè¯
        planning_prompt = self.planning_prompt_template.format(
            available_agents_str=available_agents_str,
            main_instruction=main_instruction,
            available_agent_names=', '.join(available_agent_names)
        )

        # å¦‚æœæœ‰ä¸Šä¸€æ¬¡å¤±è´¥çš„éªŒè¯ç»“æœå’Œæ‰§è¡Œè®¡åˆ’ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
        if previous_attempt_failed and previous_verification:
            if previous_plan:
                planning_prompt += f"""

# ä¸Šä¸€æ¬¡æ‰§è¡Œçš„è®¡åˆ’
```json
{json.dumps(previous_plan, indent=2, ensure_ascii=False)}
```

âš ï¸ æ³¨æ„ï¼šä¸Šä¸€æ¬¡æ‰§è¡Œè®¡åˆ’æœªèƒ½è¾¾æˆç›®æ ‡ï¼Œè¯·ä»”ç»†åˆ†æä»¥ä¸‹éªŒè¯ç»“æœï¼Œå¹¶æ”¹è¿›æ‚¨çš„è®¡åˆ’ï¼š

# ä¸Šä¸€æ¬¡éªŒè¯å¤±è´¥çš„åŸå› 
{previous_verification}

# æ”¹è¿›å»ºè®®
- ç‰¹åˆ«å…³æ³¨ä¸Šä¸€æ¬¡å¤±è´¥çš„åŸå› ï¼Œç¡®ä¿æ–°è®¡åˆ’èƒ½è§£å†³è¿™äº›é—®é¢˜
- è€ƒè™‘æ·»åŠ æ›´å¤šçš„æ­¥éª¤æˆ–æ›´å¥å£®çš„éªŒè¯æ–¹æ³•
- ä¸ºå·²çŸ¥çš„å¤±è´¥ç‚¹è®¾è®¡ä¸“é—¨çš„ä¿®å¤ç­–ç•¥
"""

        # æ·»åŠ è¾“å‡ºæ ¼å¼è¦æ±‚
        first_agent_name = available_agent_names[0] if available_agent_names and available_agent_names[0] != "æ— " else "æ™ºèƒ½ä½“åç§°"
        planning_prompt += f"""

# è¾“å‡ºæ ¼å¼
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º:
```json
{{
  "steps": [
    {{
      "id": "step1",
      "name": "æ­¥éª¤åç§°",
      "instruction": "è¯¦ç»†çš„æ‰§è¡ŒæŒ‡ä»¤...",
      "agent_name": "{first_agent_name}",
      "instruction_type": "execution",
      "expected_output": "é¢„æœŸè¾“å‡º",
      "dependencies": []
    }}
  ]
}}
```

# é‡è¦æç¤º
- æ¯ä¸ªæ­¥éª¤éƒ½è¦æŒ‡å®šæŒ‡ä»¤ç±»å‹(instruction_type)
- ç¡®ä¿æ­¥éª¤ä¹‹é—´çš„æ•°æ®æµåŠ¨æ¸…æ™°ï¼Œåç»­æ­¥éª¤èƒ½å¤Ÿè·å–å’Œä½¿ç”¨å‰é¢æ­¥éª¤çš„è¾“å‡ºç»“æœ
- æ¯ä¸ªæ­¥éª¤éƒ½åº”æœ‰æ˜ç¡®çš„ç›®æ ‡å’Œå¯éªŒè¯çš„è¾“å‡º
- æ­¥éª¤ä¸­çš„instructionä¸è¦ä½¿ç”¨ä¸‰ä¸ªåŒå¼•å·åŒ…è£¹
"""

        # å°è¯•ä½¿ç”¨æ›´å…¼å®¹çš„response_formatï¼ˆç§»é™¤schemaå­—æ®µï¼‰
        response_format = {
            "type": "json_object"
        }

        try:
            # ä½¿ç”¨chat_syncå¹¶æ·»åŠ response_formatå‚æ•°
            result = self.chat_sync(planning_prompt, response_format=response_format)
            # ä»Resultå¯¹è±¡ä¸­æå–å†…å®¹
            if result.success:
                plan_result = result.return_value if result.return_value else result.stdout
            else:
                logger.warning(f"chat_syncè¿”å›å¤±è´¥: {result.stderr}")
                # å›é€€åˆ°æ— æ ¼å¼çº¦æŸæ–¹å¼
                result = self.chat_sync(planning_prompt)
                plan_result = result.return_value if result.return_value else result.stdout

            from autogen.code_utils import extract_code
            
            # åˆ¤æ–­æ˜¯å¦æ¥æ”¶åˆ°é”™è¯¯æ¶ˆæ¯
            if isinstance(plan_result, str) and "error" in plan_result:
                error_obj = json.loads(plan_result)
                logger.warning(f"LLMå“åº”åŒ…å«é”™è¯¯: {error_obj.get('error')}")
                # å›é€€åˆ°å†æ¬¡å°è¯•
                result = self.chat_sync(planning_prompt)
                plan_result = result.return_value if result.return_value else result.stdout
            
            # å°è¯•æå–å’Œè§£æJSON
            try:
                extracted_codes = extract_code(plan_result)
                if extracted_codes:
                    plan_data = json.loads(extracted_codes[0][1])
                else:
                    # ç›´æ¥å°è¯•è§£ææ•´ä¸ªå“åº”
                    plan_data = json.loads(plan_result)
            except:
                # å¦‚æœæå–å¤±è´¥ï¼Œå°è¯•ç›´æ¥è§£æ
                plan_data = json.loads(plan_result)
                
            # å¤„ç†ä¸¤ç§å¯èƒ½çš„æ ¼å¼ï¼šç›´æ¥æ­¥éª¤æ•°ç»„æˆ–åŒ…å«stepså­—æ®µçš„å¯¹è±¡
            if isinstance(plan_data, list):
                plan = plan_data  # ç›´æ¥æ˜¯æ­¥éª¤æ•°ç»„
                logger.debug(f"è§£æåˆ°æ­¥éª¤æ•°ç»„ï¼Œå…± {len(plan)} ä¸ªæ­¥éª¤")
            else:
                plan = plan_data.get("steps", [])  # ä»å¯¹è±¡ä¸­è·å–steps
                logger.debug(f"ä»å¯¹è±¡ä¸­è§£æåˆ°æ­¥éª¤ï¼Œå…± {len(plan)} ä¸ªæ­¥éª¤")
        except Exception as e:
            logger.warning(f"è®¡åˆ’ç”Ÿæˆç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥: {e}")
            # å›é€€åˆ°æ™®é€šæ–¹å¼å†è¯•ä¸€æ¬¡
            try:
                from langchain_core.messages import HumanMessage
                # æ£€æŸ¥thinker.memoryæœ€åä¸€æ¡æ˜¯å¦ä¸ºHumanMessageï¼Œå¦‚æœæ˜¯åˆ™åˆ é™¤
                if hasattr(self, "thinker") and hasattr(self.thinker, "memory") and self.thinker.memory:
                    last_msg = self.thinker.memory[-1]
                    if isinstance(last_msg, HumanMessage):
                        self.thinker.memory.pop()
                
                result = self.chat_sync(planning_prompt)
                plan_result = result.return_value if result.return_value else result.stdout
                
                # å°è¯•å¤šç§è§£ææ–¹å¼
                try:
                    # é¦–å…ˆåˆ¤æ–­plan_resultæ˜¯å¦ä»¥```jsonå¼€å¤´
                    if plan_result.startswith("```json"):
                        plan_result = plan_result[len("```json"):].strip()
                        # å»é™¤ç»“å°¾çš„```
                        if plan_result.endswith("```"):
                            plan_result = plan_result[:-len("```")]
                            
                    # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
                    plan_data = json.loads(plan_result)
                    if isinstance(plan_data, list):
                        plan = plan_data
                    else:
                        plan = plan_data.get("steps", [])
                except:
                    # å°è¯•æå–JSONéƒ¨åˆ†
                    import re
                    json_matches = re.findall(r'\[[\s\S]*?\]|\{[\s\S]*?\}', plan_result)
                    if json_matches:
                        for json_str in json_matches:
                            try:
                                plan_data = json.loads(json_str)
                                if isinstance(plan_data, list):
                                    plan = plan_data
                                    break
                                elif isinstance(plan_data, dict) and "steps" in plan_data:
                                    plan = plan_data["steps"]
                                    break
                            except:
                                continue
                    
                    if not locals().get('plan'):
                        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾ JSON æ•°ç»„æ ¼å¼
                        array_match = re.search(r'\[\s*\{.*?\}\s*\]', plan_result, re.DOTALL)
                        if array_match:
                            try:
                                plan = json.loads(array_match.group(0))
                            except:
                                plan = []
            except Exception as e2:
                logger.error(f"è§£æè®¡åˆ’å¤±è´¥: {e2}")
                plan = []
        
        # ç¡®ä¿ plan æ˜¯åˆ—è¡¨ä¸”æœ‰å†…å®¹
        if not isinstance(plan, list) or not plan:
            logger.warning("è®¡åˆ’ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å•æ­¥å›é€€è®¡åˆ’")
            plan = [{
                "id": "fallback_step",
                "name": "æ‰§è¡Œå®Œæ•´ä»»åŠ¡",
                "instruction": main_instruction,
                "agent_name": self.registered_agents[0].name if self.registered_agents else "general_agent",
                "phase": "execution",
                "instruction_type": "execution",
                "expected_output": "ä»»åŠ¡å®Œæˆç»“æœ",
                "prerequisites": "æ— "
            }]
        
        # ç¡®ä¿æ‰€æœ‰æ­¥éª¤éƒ½æœ‰å¿…è¦çš„å­—æ®µ
        for i, step in enumerate(plan):
            if not isinstance(step, dict):
                logger.warning(f"æ­¥éª¤ {i} ä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œå°†è¢«æ›¿æ¢ä¸ºé»˜è®¤æ­¥éª¤")
                plan[i] = {
                    "id": f"auto_{i}",
                    "name": f"è‡ªåŠ¨æ­¥éª¤{i}",
                    "instruction": f"æ‰§è¡Œä»»åŠ¡çš„ç¬¬{i+1}éƒ¨åˆ†",  # é¿å…ç›´æ¥ä½¿ç”¨åŸå§‹æŒ‡ä»¤
                    "agent_name": self.registered_agents[0].name if self.registered_agents else "general_agent",
                    "phase": "execution",
                    "instruction_type": "execution",
                    "expected_output": f"ç¬¬{i+1}éƒ¨åˆ†çš„æ‰§è¡Œç»“æœ",
                    "prerequisites": "æ— ",
                    "status": "pending"
                }
                continue
                
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            if "id" not in step:
                step["id"] = f"step_{i+1}"
            if "name" not in step:
                step["name"] = f"æ­¥éª¤{i+1}"
            if "instruction" not in step:
                step["instruction"] = f"æ‰§è¡Œä»»åŠ¡çš„ç¬¬{i+1}éƒ¨åˆ†"  # é¿å…ç›´æ¥ä½¿ç”¨åŸå§‹æŒ‡ä»¤
            if "agent_name" not in step:
                step["agent_name"] = self.registered_agents[0].name if self.registered_agents else "general_agent"
            if "phase" not in step:
                step["phase"] = "execution"
            if "instruction_type" not in step:
                step["instruction_type"] = "execution"
            # è®¾ç½®é»˜è®¤çŠ¶æ€
            if "status" not in step:
                step["status"] = "pending"
            if "expected_output" not in step:
                step["expected_output"] = f"ç¬¬{i+1}æ­¥çš„æ‰§è¡Œç»“æœ"
            # å‘åå…¼å®¹ï¼šå°†æ—§çš„dependenciesè½¬æ¢ä¸ºæ–°çš„prerequisites
            if "dependencies" in step and not step.get("prerequisites"):
                deps = step["dependencies"]
                if deps:
                    step["prerequisites"] = f"éœ€è¦å®Œæˆæ­¥éª¤: {', '.join(deps)}"
                else:
                    step["prerequisites"] = "æ— "
                del step["dependencies"]
            elif "prerequisites" not in step:
                step["prerequisites"] = "æ— "
        
        self.device.set_variable("current_plan", plan)
        logger.debug(f"ç”Ÿæˆè®¡åˆ’: {plan}")
        # æ·»åŠ ç›´æ¥æ‰“å°åˆ°æ§åˆ¶å°
        print(f"\nå½“å‰æ‰§è¡Œè®¡åˆ’:\n{json.dumps(plan, ensure_ascii=False, indent=2)}\n")
        return plan

    # ====== æ™ºèƒ½è°ƒåº¦ç›¸å…³æ–¹æ³• ======
    
    # æ³¨æ„ï¼šcan_execute_step æ–¹æ³•å·²ç§»é™¤
    # æ­¥éª¤å¯æ‰§è¡Œæ€§åˆ¤æ–­ç°åœ¨ç»Ÿä¸€ç”± make_decision æ–¹æ³•ä¸­çš„å†³ç­–æœºåˆ¶å¤„ç†
    # è¿™é¿å…äº†é‡å¤çš„LLMè°ƒç”¨å’Œå†³ç­–é€»è¾‘åˆ†æ•£çš„é—®é¢˜
    
    def select_next_executable_step(self, plan: List[Dict]) -> Optional[Tuple[int, Dict]]:
        """ç®€åŒ–çš„æ­¥éª¤é€‰æ‹© - ç»Ÿä¸€å†³ç­–æœºåˆ¶æ–¹æ¡ˆ2"""
        
        # è·å–æ‰€æœ‰å¾…æ‰§è¡Œæ­¥éª¤
        pending_steps = []
        for i, step in enumerate(plan):
            step_status = step.get('status')
            
            if step_status not in ('completed', 'skipped', 'running'):
                pending_steps.append((i, step))
        
        if not pending_steps:
            return None
        
        # ç®€åŒ–é€»è¾‘ï¼šæŒ‰é¡ºåºè¿”å›ç¬¬ä¸€ä¸ªå¾…æ‰§è¡Œæ­¥éª¤
        # å…·ä½“çš„å¯æ‰§è¡Œæ€§åˆ¤æ–­å’Œæ™ºèƒ½é€‰æ‹©äº¤ç”±ç»Ÿä¸€çš„å†³ç­–æœºåˆ¶å¤„ç†
        return pending_steps[0]
    
    def _add_new_tasks(self, new_tasks: List[Dict]):
        """æ·»åŠ æ–°ä»»åŠ¡åˆ°è®¡åˆ’ä¸­"""
        if not new_tasks:
            return
            
        plan = self.get_plan()
        for new_task in new_tasks:
            # ç¡®ä¿æ–°ä»»åŠ¡æœ‰å¿…è¦çš„å­—æ®µ
            new_task_id = new_task.get('id', f"dynamic_{len(plan)}")
            new_task['id'] = new_task_id
            if 'status' not in new_task:
                new_task['status'] = 'pending'
            if 'prerequisites' not in new_task:
                new_task['prerequisites'] = 'æ— '
            
            plan.append(new_task)
        
        # æ›´æ–°è®¡åˆ’
        self.device.set_variable("current_plan", plan)
        logger.debug(f"æ·»åŠ äº† {len(new_tasks)} ä¸ªæ–°ä»»åŠ¡")

    def get_plan(self) -> List[Dict[str, Any]]:
        """ä» StatefulExecutor è·å–å½“å‰è®¡åˆ’ã€‚"""
        return self.device.get_variable("current_plan") or []

    def update_step_status(self, step_idx: int, status: str, result: Any = None):
        """æ›´æ–° current_plan ä¸­æŸä¸€æ­¥éª¤çš„çŠ¶æ€å’Œç»“æœã€‚"""
        # æ›´æ–°åŸºæœ¬çŠ¶æ€å’Œç»“æŸæ—¶é—´
        code_base = f'''
current_plan[{step_idx}]["status"] = "{status}"
current_plan[{step_idx}]["end_time"] = "{dt.now().isoformat()}"
'''
        self.device.execute_code(code_base)

        if result is not None:
            # åˆ›å»ºç»“æœå­—å…¸ (ä½¿ç”¨ Python å¸ƒå°”å€¼)
            result_dict = {
                "success": bool(getattr(result, "success", False)), # ç¡®ä¿æ˜¯ Python bool
                "stdout": getattr(result, "stdout", None),
                "stderr": getattr(result, "stderr", None),
                "return_value": getattr(result, "return_value", None),
            }
            # å°†ç»“æœå­—å…¸å­˜å…¥ Executor ä¸´æ—¶å˜é‡
            temp_var_name = f"_temp_result_{step_idx}"
            self.device.set_variable(temp_var_name, result_dict)

            # æ›´æ–° plan ä¸­çš„ result å­—æ®µï¼Œå¼•ç”¨ä¸´æ—¶å˜é‡
            code_result_update = f'current_plan[{step_idx}]["result"] = {temp_var_name}'
            self.device.execute_code(code_result_update)

            # å¯é€‰ï¼šæ¸…ç†ä¸´æ—¶å˜é‡ï¼ˆå¦‚æœæ‹…å¿ƒå‘½åç©ºé—´æ±¡æŸ“ï¼‰
            # self.device.execute_code(f'del {temp_var_name}')

    # ====== æ–¹æ¡ˆ2: æ§åˆ¶æµå¤„ç†æ–¹æ³• ======
    
    def find_step_index_by_id(self, step_id: str) -> int:
        """æ ¹æ®æ­¥éª¤IDæŸ¥æ‰¾ç´¢å¼•"""
        plan = self.get_plan()
        for i, step in enumerate(plan):
            if step.get("id") == step_id:
                return i
        return -1
    
    def jump_to_step(self, target_step_id: str):
        """è·³è½¬åˆ°æŒ‡å®šæ­¥éª¤"""
        target_index = self.find_step_index_by_id(target_step_id)
        if target_index >= 0:
            # è·å–å½“å‰è®¡åˆ’
            plan = self.get_plan()
            
            # å°†å½“å‰æ­¥éª¤åˆ°ç›®æ ‡æ­¥éª¤ä¹‹é—´çš„æ‰€æœ‰æ­¥éª¤æ ‡è®°ä¸ºå·²è·³è¿‡(è·³è¿‡ä¾èµ–å…³ç³»é—®é¢˜)
            current_index = self.workflow_state.current_step_index
            for i in range(current_index, target_index):
                if i < len(plan) and plan[i].get('status') not in ('completed', 'skipped'):
                    plan[i]['status'] = 'skipped'
                    logger.debug(f"è·³è¿‡æ­¥éª¤ {i}: {plan[i].get('name', plan[i].get('id'))}")
            
            # æ›´æ–°è®¡åˆ’
            self.device.set_variable("current_plan", plan)
            
            # è®¾ç½®å½“å‰æ­¥éª¤ç´¢å¼•
            self.workflow_state.current_step_index = target_index
            logger.debug(f"è·³è½¬åˆ°æ­¥éª¤: {target_step_id} (ç´¢å¼•: {target_index})")
        else:
            logger.warning(f"æ‰¾ä¸åˆ°æ­¥éª¤ID: {target_step_id}")
    
    def loop_back_to_step(self, target_step_id: str):
        """å¾ªç¯å›åˆ°æŒ‡å®šæ­¥éª¤"""
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡ºå¾ªç¯
        if self.workflow_state.should_break_loop(target_step_id):
            logger.warning(f"è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œåœæ­¢å¾ªç¯åˆ°æ­¥éª¤: {target_step_id}")
            return False
        
        target_index = self.find_step_index_by_id(target_step_id)
        if target_index >= 0:
            # é‡ç½®ä»ç›®æ ‡æ­¥éª¤å¼€å§‹çš„æ‰€æœ‰æ­¥éª¤çŠ¶æ€
            plan = self.get_plan()
            self.workflow_state.reset_step_status_from(target_index, plan)
            self.device.set_variable("current_plan", plan)
            
            # è·³è½¬åˆ°ç›®æ ‡æ­¥éª¤
            self.workflow_state.current_step_index = target_index
            
            # å¢åŠ å¾ªç¯è®¡æ•°å™¨
            self.workflow_state.increment_loop_counter(target_step_id)
            
            logger.debug(f"å¾ªç¯å›åˆ°æ­¥éª¤: {target_step_id} (ç¬¬{self.workflow_state.loop_counters.get(f'loop_to_{target_step_id}', 0)}æ¬¡)")
            return True
        else:
            logger.warning(f"æ‰¾ä¸åˆ°æ­¥éª¤ID: {target_step_id}")
            return False
    
    def handle_generate_fix_task_and_loop(self, decision: Dict[str, Any]) -> bool:
        """å¤„ç†ç”Ÿæˆä¿®å¤ä»»åŠ¡å¹¶å¾ªç¯çš„å¤åˆå†³ç­–"""
        target_step_id = decision.get('loop_target')
        
        # æ£€æŸ¥å¾ªç¯æ¬¡æ•°
        if self.workflow_state.should_break_loop(target_step_id):
            logger.warning(f"å·²å°è¯•ä¿®å¤{self.workflow_state.max_loops}æ¬¡ï¼Œåœæ­¢å¾ªç¯")
            return False
        
        # 1. ç”Ÿæˆä¿®å¤ä»»åŠ¡
        fix_task = {
            "id": f"fix_{self.workflow_state.fix_counter}",
            "name": "ä»£ç ä¿®å¤",
            "instruction": decision.get('fix_instruction', 'ä¿®å¤ä»£ç ä¸­çš„é—®é¢˜'),
            "agent_name": decision.get('fix_agent', 'coder'),
            "instruction_type": "execution",
            "phase": "execution",
            "expected_output": "ä¿®å¤åçš„ä»£ç ",
            "prerequisites": "æ£€æµ‹åˆ°éœ€è¦ä¿®å¤çš„é—®é¢˜",
            "status": "pending"
        }
        
        # å¦‚æœæœ‰é”™è¯¯è¯¦æƒ…ï¼Œæ·»åŠ åˆ°æŒ‡ä»¤ä¸­
        if decision.get('error_details'):
            fix_task['instruction'] += f"\n\né”™è¯¯è¯¦æƒ…:\n{decision['error_details']}"
        
        # 2. å°†ä¿®å¤ä»»åŠ¡æ’å…¥åˆ°å½“å‰ä½ç½®ä¹‹å
        plan = self.get_plan()
        current_index = self.workflow_state.current_step_index
        plan.insert(current_index + 1, fix_task)
        self.device.set_variable("current_plan", plan)
        
        # 3. æ›´æ–°çŠ¶æ€
        self.workflow_state.fix_counter += 1
        
        logger.debug(f"ç”Ÿæˆä¿®å¤ä»»åŠ¡: {fix_task['id']}")
        print(f"\nç”Ÿæˆä¿®å¤ä»»åŠ¡: {fix_task['name']}")
        print(f"ä¿®å¤æŒ‡ä»¤: {fix_task['instruction'][:100]}...")
        
        return True

    #TODO: æ˜¯å¦åŒºåˆ†æ‰§è¡Œæ€§å’Œä¿¡æ¯æ€§ä»»åŠ¡?
    def execute_single_step(self, step: Dict[str, Any], task_history=None, global_state: Optional['WorkflowState'] = None) -> Optional[Result]:
        """
        æ‰§è¡Œè®¡åˆ’ä¸­çš„å•ä¸ªæ­¥éª¤ã€‚
        
        Args:
            step: æ­¥éª¤å®šä¹‰
            task_history: ä»»åŠ¡å†å²è®°å½•
            global_state: å…¨å±€å·¥ä½œæµçŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        
        agent_name = step.get("agent_name")
        instruction = step.get("instruction")
        instruction_type = step.get("instruction_type", "execution")  # é»˜è®¤ä¸ºexecutionç±»å‹
        if not agent_name or not instruction:
            return Result(False, instruction, "", "æ­¥éª¤ç¼ºå°‘ agent_name æˆ– instruction")

        try:
            # æŸ¥æ‰¾æŒ‡å®šçš„æ™ºèƒ½ä½“
            target_agent = None
            for spec in self.registered_agents:
                if spec.name == agent_name:
                    target_agent = spec.instance
                    break
            
            # å¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šçš„æ™ºèƒ½ä½“ï¼Œè¿”å›é”™è¯¯
            if target_agent is None:
                return Result(False, instruction, "", f"æ‰¾ä¸åˆ°åä¸º '{agent_name}' çš„æ™ºèƒ½ä½“")

            # è·å–å‰åºæ­¥éª¤çš„ç»“æœ
            previous_results = []
            if task_history is None:
                task_history = []
            for task in task_history:
                if task.get('result') and getattr(task.get('result'), 'success', False):
                    task_name = task.get('task', {}).get('name', '')
                    return_value = getattr(task.get('result'), 'return_value', '')
                    previous_results.append(f"æ­¥éª¤ {task_name} çš„ç»“æœ:\n{return_value}")

            # æ„å»ºåŒ…å«å…¨å±€çŠ¶æ€çš„å¢å¼ºæŒ‡ä»¤
            prompt = self._generate_state_aware_instruction(
                step, instruction, previous_results, global_state or self.workflow_state
            )
            # ä½¿ç”¨ç›®æ ‡æ™ºèƒ½ä½“æ‰§è¡Œä»»åŠ¡
            if instruction_type == "information":
                response = target_agent.chat_stream(prompt)
            else:
                response = target_agent.execute_stream(prompt)
                
            # å¤„ç†å“åº”æµå¹¶æ”¶é›†ç»“æœ
            response_text = ""
            for chunk in response:
                result=chunk
                if isinstance(chunk, str):
                    print(chunk,end="",flush=True)
                    response_text += chunk
                    
            # æ ¹æ®æŒ‡ä»¤ç±»å‹è§£æç»“æœ
            if instruction_type == "information":
                result_obj = Result(True, instruction, response_text, "", response_text)
            else:
                if isinstance(result, Result):
                    result_obj = result
                elif hasattr(result, "return_value") and isinstance(result.return_value, Result):
                    result_obj = result.return_value
                else:
                    stdout = getattr(result, "stdout", str(result))
                    stderr = getattr(result, "stderr", None)
                    result_obj = Result(False, instruction, stdout, stderr, None)
            
            # è¿›è¡Œå“åº”åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            result_obj = self._analyze_step_response(result_obj, step, response_text)
            
            return result_obj
            
        except Exception as e:
            error_result = Result(False, instruction, "", str(e), None)
            # åˆ†æé”™è¯¯å“åº”
            error_result = self._analyze_step_response(error_result, step, str(e))
            return error_result

    #TODO: æ•´åˆåˆ°agentçš„executeæ–¹æ³•
    @reduce_memory_decorator_compress
    def execute_multi_step(self, main_instruction: str, interactive: bool = False) -> str:
        """
        ä¸»å…¥å£ï¼šè§„åˆ’å¹¶æ‰§è¡Œå¤šæ­¥éª¤ä»»åŠ¡ - é‡æ„åçš„ç®€åŒ–ç‰ˆæœ¬
        """
        # åˆå§‹åŒ–æ‰§è¡Œä¸Šä¸‹æ–‡
        context = self._initialize_execution_context(main_instruction)
        
        # ä¸»æ‰§è¡Œå¾ªç¯
        while self._should_continue_execution(context):
            try:
                # æ‰§è¡Œä¸€ä¸ªå·¥ä½œæµè¿­ä»£
                should_break = self._execute_workflow_iteration(context, interactive)
                if should_break:
                    break
            except Exception as e:
                logger.error(f"å·¥ä½œæµè¿­ä»£å¤±è´¥: {e}")
                self._handle_workflow_error(context, e)
                break
        
        return self._generate_execution_summary(context)
    
    def _initialize_execution_context(self, main_instruction: str) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰§è¡Œä¸Šä¸‹æ–‡"""
        # å­˜å‚¨åŸå§‹ç›®æ ‡
        self.original_goal = main_instruction
        
        # é‡ç½®å·¥ä½œæµçŠ¶æ€
        self.workflow_state = WorkflowState()
        
        # è§„åˆ’æ­¥éª¤
        self.device.set_variable("previous_plan", None)
        plan = self.plan_execution(main_instruction)
        
        return {
            'main_instruction': main_instruction,
            'plan': plan,
            'task_history': [],
            'summary': "",
            'retries': 0,
            'workflow_iterations': 0,
            'context': {"original_goal": main_instruction},
            'max_workflow_iterations': 50
        }
    
    def _should_continue_execution(self, context: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­æ‰§è¡Œ"""
        return (context['retries'] <= self.max_retries and 
                context['workflow_iterations'] < context['max_workflow_iterations'])
    
    def _execute_workflow_iteration(self, context: Dict[str, Any], interactive: bool) -> bool:
        """
        æ‰§è¡Œä¸€ä¸ªå·¥ä½œæµè¿­ä»£
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        context['workflow_iterations'] += 1
        
        context['plan'] = self.get_plan()
        
        # é€‰æ‹©ä¸‹ä¸€ä¸ªå¯æ‰§è¡Œæ­¥éª¤
        next_step_info = self.select_next_executable_step(context['plan'])
        
        if not next_step_info:
            # æ²¡æœ‰å¯æ‰§è¡Œæ­¥éª¤ï¼Œè¿›è¡Œå†³ç­–
            return self._handle_no_executable_steps(context)
        
        # æ‰§è¡Œé€‰å®šçš„æ­¥éª¤
        current_idx, current_step = next_step_info
        should_break = self._execute_single_workflow_step(current_idx, current_step, context)
        
        if should_break:
            return True
            
        # äº¤äº’æ¨¡å¼å¤„ç†
        if interactive and self._check_user_interrupt():
            context['summary'] += "\nç”¨æˆ·è¯·æ±‚é€€å‡ºã€‚"
            return True
            
        return False
    
    def _handle_no_executable_steps(self, context: Dict[str, Any]) -> bool:
        """
        å¤„ç†æ²¡æœ‰å¯æ‰§è¡Œæ­¥éª¤çš„æƒ…å†µ
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        # è·å–æœ€åä¸€ä¸ªæ‰§è¡Œç»“æœ
        last_result = None
        if context['task_history']:
            last_result = context['task_history'][-1].get('result', None)
        
        # è¿›è¡Œå†³ç­–
        decision = self.make_decision(
            current_result=last_result,
            task_history=context['task_history'],
            context=context['context']
        )
        
        print(f"\nå†³ç­–ç»“æœ: {decision['action']}")
        print(f"åŸå› : {decision['reason']}")
        
        # å¤„ç†å†³ç­–ç»“æœ
        return self._process_no_steps_decision(decision, context)
    
    def _process_no_steps_decision(self, decision: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """
        å¤„ç†æ²¡æœ‰å¯æ‰§è¡Œæ­¥éª¤æ—¶çš„å†³ç­–ç»“æœ
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        action = decision['action']
        
        if action == 'complete':
            context['summary'] += "\nå…¨éƒ¨æ­¥éª¤æ‰§è¡Œå®Œæˆã€‚"
            self._clear_failure_records()
            return True
            
        elif action == 'generate_new_task' and decision.get('new_tasks'):
            context['summary'] += "\næ·»åŠ æ–°ä»»åŠ¡å¹¶ç»§ç»­æ‰§è¡Œã€‚"
            self._add_new_tasks(decision.get('new_tasks', []))
            context['plan'] = self.get_plan()
            return False
            
        else:
            context['summary'] += f"\næ‰€æœ‰æ­¥éª¤å·²å¤„ç†ï¼Œå†³ç­–ä¸º: {action}ã€‚"
            return True
    
    def _execute_single_workflow_step(self, current_idx: int, current_step: Dict, 
                                     context: Dict[str, Any]) -> bool:
        """
        æ‰§è¡Œå•ä¸ªå·¥ä½œæµæ­¥éª¤
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
        plan = context['plan']
        print(f"\næ‰§è¡Œæ­¥éª¤ {current_idx+1}/{len(plan)}: {current_step.get('name')}")
        
        # æ ‡è®°ä¸ºè¿è¡Œä¸­
        self.update_step_status(current_idx, "running")
        
        # æ‰§è¡Œæ­¥éª¤
        exec_result = self.execute_single_step(current_step, context['task_history'], self.workflow_state)
        
        # è®°å½•ä»»åŠ¡å†å²
        context['task_history'].append({
            'task': current_step,
            'result': exec_result,
            'timestamp': dt.now().isoformat()
        })
        
        # === AIçŠ¶æ€æ›´æ–°å™¨é›†æˆ ===
        # åœ¨æ¯ä¸ªæ­¥éª¤æ‰§è¡Œåè§¦å‘AIçŠ¶æ€æ›´æ–°
        self._trigger_ai_state_update(current_step, exec_result, context)
        
        # æ ¹æ®æ‰§è¡Œç»“æœè¿›è¡Œåç»­å¤„ç†
        if exec_result and exec_result.success:
            return self._handle_step_success(current_idx, exec_result, context)
        else:
            return self._handle_step_failure(current_idx, current_step, exec_result, context)
    
    def _handle_step_success(self, current_idx: int, exec_result: Result, 
                           context: Dict[str, Any]) -> bool:
        """
        å¤„ç†æ­¥éª¤æ‰§è¡ŒæˆåŠŸçš„æƒ…å†µ
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        self.update_step_status(current_idx, "completed", exec_result)
        
        # æ‰§è¡ŒæˆåŠŸåè¿›è¡Œå†³ç­–
        decision = self.make_decision(
            current_result=exec_result,
            task_history=context['task_history'],
            context=context['context']
        )
        
        print(f"\nå†³ç­–ç»“æœ: {decision['action']}")
        print(f"åŸå› : {decision['reason']}")
        
        # å¤„ç†æˆåŠŸå†³ç­–ç»“æœ
        return self._process_success_decision(decision, context)
    
    def _handle_step_failure(self, current_idx: int, current_step: Dict, 
                           exec_result: Result, context: Dict[str, Any]) -> bool:
        """
        å¤„ç†æ­¥éª¤æ‰§è¡Œå¤±è´¥çš„æƒ…å†µ
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        # æ›´æ–°æ­¥éª¤çŠ¶æ€
        self.update_step_status(current_idx, "failed", exec_result)
        context['summary'] += f"\næ­¥éª¤å¤±è´¥: {current_step.get('name')}"
        
        # å¤±è´¥åè¿›è¡Œå†³ç­–
        decision = self.make_decision(
            current_result=exec_result,
            task_history=context['task_history'],
            context=context['context']
        )
        
        print(f"\nå¤±è´¥åå†³ç­–: {decision['action']}")
        print(f"åŸå› : {decision['reason']}")
        
        # å¤„ç†å¤±è´¥å†³ç­–
        return self._process_failure_decision(decision, context, current_idx)
    
    def _process_success_decision(self, decision: Dict[str, Any], 
                                context: Dict[str, Any]) -> bool:
        """
        å¤„ç†æˆåŠŸåçš„å†³ç­–
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        action = decision['action']
        
        if action == 'complete':
            context['summary'] += "\nå†³ç­–ä¸ºå®Œæˆæ‰§è¡Œã€‚"
            self._clear_failure_records()
            return True
            
        elif action == 'continue':
            context['summary'] += "\nç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªæ­¥éª¤ã€‚"
            return False
            
        elif action == 'generate_new_task':
            return self._handle_generate_new_task_decision(decision, context)
            
        elif action in ['jump_to', 'loop_back']:
            return self._handle_navigation_decision(decision, context)
            
        elif action == 'generate_fix_task_and_loop':
            return self._handle_fix_task_decision(decision, context)
            
        elif action == 'skip_step':
            return self._handle_skip_step_decision(decision, context)
            
        return False
    
    def _process_failure_decision(self, decision: Dict[str, Any], context: Dict[str, Any], 
                                current_idx: int) -> bool:
        """
        å¤„ç†å¤±è´¥åçš„å†³ç­–
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        action = decision['action']
        
        if action == 'retry':
            self.update_step_status(current_idx, "pending")
            context['summary'] += "\nå°†é‡è¯•å½“å‰æ­¥éª¤ã€‚"
            return False
            
        elif action == 'continue':
            context['summary'] += "\nç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªæ­¥éª¤ã€‚"
            return False
            
        elif action == 'generate_new_task':
            return self._handle_generate_new_task_decision(decision, context)
            
        elif action == 'skip_step':
            return self._handle_skip_step_decision(decision, context)
            
        else:
            # é»˜è®¤å¤„ç†ï¼šå¢åŠ é‡è¯•æ¬¡æ•°
            return self._handle_retry_logic(context)
    
    def _handle_generate_new_task_decision(self, decision: Dict[str, Any], 
                                         context: Dict[str, Any]) -> bool:
        """å¤„ç†ç”Ÿæˆæ–°ä»»åŠ¡çš„å†³ç­–"""
        new_tasks = decision.get('new_tasks', [])
        if new_tasks:
            self._add_new_tasks(new_tasks)
            context['plan'] = self.get_plan()
            context['summary'] += "\næ·»åŠ æ–°ä»»åŠ¡å¹¶ç»§ç»­æ‰§è¡Œã€‚"
        return False
    
    def _handle_navigation_decision(self, decision: Dict[str, Any], 
                                  context: Dict[str, Any]) -> bool:
        """å¤„ç†è·³è½¬å’Œå¾ªç¯å†³ç­–"""
        action = decision['action']
        target_step_id = decision.get('target_step_id')
        
        if not target_step_id:
            logger.warning(f"{action}å†³ç­–ç¼ºå°‘target_step_id")
            return False
        
        if action == 'jump_to':
            if self.jump_to_step(target_step_id):
                context['summary'] += f"\nè·³è½¬åˆ°æ­¥éª¤: {target_step_id}"
            
        elif action == 'loop_back':
            if self.loop_back_to_step(target_step_id):
                context['summary'] += f"\nå¾ªç¯å›åˆ°æ­¥éª¤: {target_step_id}"
            else:
                context['summary'] += "\nå¾ªç¯å¤±è´¥"
        
        return False
    
    def _handle_fix_task_decision(self, decision: Dict[str, Any], 
                                context: Dict[str, Any]) -> bool:
        """å¤„ç†ä¿®å¤ä»»åŠ¡å†³ç­–"""
        if self.handle_generate_fix_task_and_loop(decision):
            # æ‰§è¡Œä¿®å¤ä»»åŠ¡
            return self._execute_fix_task(decision, context)
        else:
            context['summary'] += "\nä¿®å¤ä»»åŠ¡ç”Ÿæˆå¤±è´¥æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°"
            return True
    
    def _handle_skip_step_decision(self, decision: Dict[str, Any], 
                                 context: Dict[str, Any]) -> bool:
        """å¤„ç†è·³è¿‡æ­¥éª¤çš„å†³ç­–"""
        target_step_id = decision.get('target_step_id')
        
        if not target_step_id:
            logger.warning("skip_stepå†³ç­–ç¼ºå°‘target_step_id")
            return False
        
        # æŸ¥æ‰¾ç›®æ ‡æ­¥éª¤
        target_index = self.find_step_index_by_id(target_step_id)
        if target_index >= 0:
            plan = self.get_plan()
            
            # å°†ç›®æ ‡æ­¥éª¤æ ‡è®°ä¸ºè·³è¿‡
            if target_index < len(plan):
                plan[target_index]['status'] = 'skipped'
                self.device.set_variable("current_plan", plan)
                
                context['summary'] += f"\nè·³è¿‡æ­¥éª¤: {target_step_id} - {decision.get('reason', 'æ— åŸå› ')}"
                logger.debug(f"è·³è¿‡æ­¥éª¤: {target_step_id}")
                print(f"\nè·³è¿‡æ­¥éª¤: {plan[target_index].get('name', target_step_id)}")
                
                return False  # ç»§ç»­æ‰§è¡Œå·¥ä½œæµ
            else:
                logger.warning(f"æ­¥éª¤ç´¢å¼•è¶Šç•Œ: {target_index}")
                return False
        else:
            logger.warning(f"æ‰¾ä¸åˆ°è¦è·³è¿‡çš„æ­¥éª¤ID: {target_step_id}")
            return False
    
    def _execute_fix_task(self, decision: Dict[str, Any], 
                         context: Dict[str, Any]) -> bool:
        """æ‰§è¡Œä¿®å¤ä»»åŠ¡"""
        # è·å–æ›´æ–°åçš„è®¡åˆ’
        plan = self.get_plan()
        current_idx = self.workflow_state.current_step_index + 1
        
        if current_idx < len(plan):
            fix_task = plan[current_idx]
            print(f"\næ‰§è¡Œä¿®å¤ä»»åŠ¡: {fix_task.get('name')}")
            
            # æ‰§è¡Œä¿®å¤ä»»åŠ¡
            self.update_step_status(current_idx, "running")
            fix_result = self.execute_single_step(fix_task, context.get('task_history', []), self.workflow_state)
            
            # è®°å½•ä¿®å¤ä»»åŠ¡å†å²
            context['task_history'].append({
                'task': fix_task,
                'result': fix_result,
                'timestamp': dt.now().isoformat()
            })
            
            # æ›´æ–°ä¿®å¤ä»»åŠ¡çŠ¶æ€
            if fix_result and fix_result.success:
                self.update_step_status(current_idx, "completed", fix_result)
                print(f"ä¿®å¤ä»»åŠ¡å®Œæˆ: {fix_task.get('name')}")
            else:
                self.update_step_status(current_idx, "failed", fix_result)
                print(f"ä¿®å¤ä»»åŠ¡å¤±è´¥: {fix_task.get('name')}")
        
        # å¾ªç¯å›åˆ°æµ‹è¯•æ­¥éª¤
        loop_target = decision.get('loop_target')
        if loop_target and self.loop_back_to_step(loop_target):
            context['summary'] += f"\nç”Ÿæˆä¿®å¤ä»»åŠ¡å¹¶å¾ªç¯å›åˆ°: {loop_target}"
        
        return False
    
    def _handle_retry_logic(self, context: Dict[str, Any]) -> bool:
        """
        å¤„ç†é‡è¯•é€»è¾‘
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥è·³å‡ºä¸»å¾ªç¯
        """
        # è®°å½•å¤±è´¥ä¿¡æ¯
        self._record_failure_information(context)
        
        # å¢åŠ é‡è¯•è®¡æ•°
        context['retries'] += 1
        if context['retries'] <= self.max_retries:
            context['summary'] += f"\nç¬¬{context['retries']}æ¬¡é‡è¯•ã€‚"
            return False
        else:
            context['summary'] += "\nå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚"
            return True
    
    def _record_failure_information(self, context: Dict[str, Any]) -> None:
        """è®°å½•å¤±è´¥ä¿¡æ¯ä»¥ä¾›ä¸‹æ¬¡é‡è¯•å‚è€ƒ"""
        plan = context['plan']
        failures = [
            {
                "id": step.get("id"), 
                "name": step.get("name"), 
                "error": step.get("result", {}).get("stderr", "")
            }
            for step in plan if step.get("status") == "failed"
        ]
        
        failure_verification = f"æ‰§è¡Œå¤±è´¥çš„æ­¥éª¤: {json.dumps(failures, ensure_ascii=False, indent=2)}"
        
        try:
            self.device.set_variable("previous_attempt_failed", True)
            self.device.set_variable("previous_verification", failure_verification)
            self.device.set_variable("previous_plan", {"steps": plan})
        except Exception as e:
            logger.warning(f"è®¾ç½®å¤±è´¥è®°å½•æ—¶å‡ºé”™: {e}")
    
    def _check_user_interrupt(self) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¦æ±‚ä¸­æ–­"""
        user_input = input("\næŒ‰Enterç»§ç»­ï¼Œè¾“å…¥'q'é€€å‡º: ")
        return user_input.lower() == 'q'
    
    def _clear_failure_records(self) -> None:
        """æ¸…é™¤å¤±è´¥è®°å½•"""
        try:
            self.device.set_variable("previous_attempt_failed", False)
            self.device.set_variable("previous_verification", None)
        except Exception as e:
            logger.warning(f"æ¸…é™¤å¤±è´¥è®°å½•æ—¶å‡ºé”™: {e}")
    
    
    def _trigger_ai_state_update(self, step: Dict[str, Any], exec_result: Optional[Result], 
                                context: Dict[str, Any]) -> None:
        """
        è§¦å‘AIçŠ¶æ€æ›´æ–°å™¨
        
        Args:
            step: æ‰§è¡Œçš„æ­¥éª¤ä¿¡æ¯
            exec_result: æ­¥éª¤æ‰§è¡Œç»“æœ
            context: å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨çŠ¶æ€æ›´æ–°
            if not self.workflow_state.is_state_update_enabled():
                logger.debug("AIçŠ¶æ€æ›´æ–°å·²ç¦ç”¨ï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°")
                return
            
            # æ„å»ºçŠ¶æ€æ›´æ–°ä¸Šä¸‹æ–‡
            update_context = self._build_state_update_context(step, exec_result, context)
            
            # è°ƒç”¨WorkflowStateçš„AIæ›´æ–°æ¥å£
            success = self.workflow_state.update_state_with_ai(update_context)
            
            if success:
                logger.info(f"AIçŠ¶æ€æ›´æ–°æˆåŠŸ - æ­¥éª¤: {step.get('name', 'unknown')}")
                # å¯é€‰ï¼šè¾“å‡ºçŠ¶æ€æ‘˜è¦åˆ°æ§åˆ¶å°
                if logger.isEnabledFor(logging.DEBUG):
                    state_summary = self.workflow_state.get_state_summary()
                    logger.debug(f"å½“å‰çŠ¶æ€æ‘˜è¦: {state_summary}")
            else:
                logger.warning(f"AIçŠ¶æ€æ›´æ–°å¤±è´¥ - æ­¥éª¤: {step.get('name', 'unknown')}")
                
        except Exception as e:
            # é‡è¦ï¼šçŠ¶æ€æ›´æ–°å¤±è´¥ä¸åº”å½±å“å·¥ä½œæµç»§ç»­æ‰§è¡Œ
            logger.error(f"AIçŠ¶æ€æ›´æ–°è¿‡ç¨‹å¼‚å¸¸ - æ­¥éª¤: {step.get('name', 'unknown')}, é”™è¯¯: {e}")
            # å¯é€‰ï¼šè®°å½•åˆ°æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­
            context.setdefault('state_update_errors', []).append({
                'step': step.get('id', 'unknown'),
                'step_name': step.get('name', 'unknown'),
                'error': str(e),
                'timestamp': dt.now().isoformat()
            })
    
    def _generate_state_aware_instruction(self, step: Dict[str, Any], instruction: str, 
                                         previous_results: List[str], global_state: 'WorkflowState') -> str:
        """
        ç”ŸæˆåŒ…å«å…¨å±€çŠ¶æ€ä¿¡æ¯çš„çŠ¶æ€æ„ŸçŸ¥æŒ‡ä»¤ï¼Œé›†æˆæŒ‡ä»¤ä¼˜åŒ–ç³»ç»Ÿ
        
        Args:
            step: å½“å‰æ­¥éª¤ä¿¡æ¯
            instruction: åŸå§‹æŒ‡ä»¤
            previous_results: å‰åºæ­¥éª¤ç»“æœ
            global_state: å…¨å±€å·¥ä½œæµçŠ¶æ€
            
        Returns:
            å¢å¼ºå’Œä¼˜åŒ–çš„çŠ¶æ€æ„ŸçŸ¥æŒ‡ä»¤
        """
        # é¦–å…ˆåº”ç”¨æŒ‡ä»¤ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        optimized_instruction = instruction
        optimization_result = None
        
        if self.optimization_enabled and hasattr(self, 'instruction_optimizer'):
            try:
                # æ„å»ºä¼˜åŒ–ä¸Šä¸‹æ–‡
                optimization_context = {
                    'previous_results': previous_results,
                    'workflow_state': global_state,
                    'agent_instance': self
                }
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä¼˜åŒ–
                if self.instruction_optimizer.can_optimize(instruction, step, global_state, optimization_context):
                    optimization_result = self.instruction_optimizer.optimize_instruction(
                        instruction, step, global_state, optimization_context
                    )
                    
                    # æ ¹æ®é£é™©è¯„ä¼°å†³å®šæ˜¯å¦ä½¿ç”¨ä¼˜åŒ–ç»“æœ
                    risk_assessment = optimization_result.risk_assessment
                    if risk_assessment.get('recommendation') != 'avoid':
                        optimized_instruction = optimization_result.optimized_instruction
                        
                        logger.info(f"æŒ‡ä»¤ä¼˜åŒ–åº”ç”¨æˆåŠŸ - ç½®ä¿¡åº¦: {optimization_result.confidence_score:.2f}, "
                                  f"åº”ç”¨çš„ä¼˜åŒ–: {', '.join(optimization_result.applied_enhancements)}")
                    else:
                        logger.warning(f"æŒ‡ä»¤ä¼˜åŒ–è¢«è·³è¿‡ï¼Œé£é™©è¯„ä¼°å»ºè®®é¿å…: {risk_assessment.get('risk_factors', [])}")
                        
            except Exception as e:
                logger.error(f"æŒ‡ä»¤ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
                # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŒ‡ä»¤ç»§ç»­
                optimized_instruction = instruction
        # åˆ›å»ºçŠ¶æ€ä¸Šä¸‹æ–‡æå–å™¨
        if not hasattr(self, '_state_extractor'):
            self._state_extractor = StateContextExtractor()
        
        # æå–ç›¸å…³çŠ¶æ€ä¸Šä¸‹æ–‡
        state_context = self._state_extractor.extract_relevant_context(step, global_state)
        
        # æ„å»ºåŸºæœ¬æŒ‡ä»¤ä¿¡æ¯
        enhanced_instruction = f"""# çŠ¶æ€æ„ŸçŸ¥ä»»åŠ¡æ‰§è¡Œ

## å½“å‰æ­¥éª¤ä¿¡æ¯
- æ­¥éª¤ID: {step.get('id', 'unknown')}
- æ­¥éª¤åç§°: {step.get('name', 'Unknown Step')}
- æ‰§è¡Œè€…: {step.get('agent_name', 'unknown')}
- æŒ‡ä»¤ç±»å‹: {step.get('instruction_type', 'execution')}"""
        
        # æ·»åŠ é¢„æœŸè¾“å‡ºï¼ˆå¦‚æœæœ‰ï¼‰
        if step.get('expected_output'):
            enhanced_instruction += f"\n- é¢„æœŸè¾“å‡º: {step.get('expected_output')}"
        
        # æ·»åŠ ä»»åŠ¡æŒ‡ä»¤ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„æŒ‡ä»¤ï¼‰
        enhanced_instruction += f"""

## ä»»åŠ¡æŒ‡ä»¤
{optimized_instruction}
"""
        
        # å¦‚æœä½¿ç”¨äº†æŒ‡ä»¤ä¼˜åŒ–ï¼Œæ·»åŠ ä¼˜åŒ–ä¿¡æ¯
        if optimization_result and optimization_result.optimization_types:
            enhanced_instruction += f"""

## ğŸ”§ æŒ‡ä»¤ä¼˜åŒ–ä¿¡æ¯
**åº”ç”¨çš„ä¼˜åŒ–**: {', '.join(optimization_result.applied_enhancements)}
**ä¼˜åŒ–ç†ç”±**: {optimization_result.optimization_reasoning}
**ç½®ä¿¡åº¦**: {optimization_result.confidence_score:.2f}
"""
        
        # æ™ºèƒ½æ·»åŠ ç›¸å…³çŠ¶æ€ä¿¡æ¯
        current_state = global_state.get_global_state()
        if current_state and current_state.strip():
            # ä½¿ç”¨æ™ºèƒ½æå–çš„ä¸Šä¸‹æ–‡
            if state_context['state_summary']:
                enhanced_instruction += f"""
## ğŸ¯ ç›¸å…³çŠ¶æ€ä¸Šä¸‹æ–‡
{state_context['state_summary']}
"""
            
            # æ·»åŠ é«˜ç›¸å…³æ€§çŠ¶æ€ä¿¡æ¯
            if state_context['high_relevance']:
                enhanced_instruction += f"""
## â­ é‡ç‚¹å…³æ³¨çŠ¶æ€
ä»¥ä¸‹çŠ¶æ€ä¿¡æ¯ä¸å½“å‰ä»»åŠ¡é«˜åº¦ç›¸å…³ï¼š
"""
                for item in state_context['high_relevance'][:5]:  # æœ€å¤šæ˜¾ç¤º5é¡¹
                    enhanced_instruction += f"â€¢ {item}\n"
            
            # æ·»åŠ ä¸­ç­‰ç›¸å…³æ€§çŠ¶æ€ä¿¡æ¯ï¼ˆå¦‚æœé«˜ç›¸å…³æ€§ä¿¡æ¯ä¸è¶³ï¼‰
            if len(state_context['high_relevance']) < 3 and state_context['medium_relevance']:
                enhanced_instruction += f"""
## ğŸ“‹ è¡¥å……çŠ¶æ€ä¿¡æ¯
"""
                for item in state_context['medium_relevance'][:3]:  # æœ€å¤šæ˜¾ç¤º3é¡¹
                    enhanced_instruction += f"â€¢ {item}\n"
            
            # æ·»åŠ æå–çš„å®ä½“ä¿¡æ¯
            if state_context['extracted_entities']:
                enhanced_instruction += f"""
## ğŸ” æå–çš„å…³é”®ä¿¡æ¯
"""
                for entity_type, entities in state_context['extracted_entities'].items():
                    if isinstance(entities, list) and entities:
                        enhanced_instruction += f"**{entity_type.replace('_', ' ').title()}**: {', '.join(str(e) for e in entities[:3])}\n"
                    elif isinstance(entities, dict) and entities:
                        pairs = [f"{k}={v}" for k, v in list(entities.items())[:3]]
                        enhanced_instruction += f"**{entity_type.replace('_', ' ').title()}**: {', '.join(pairs)}\n"
            
            # å¦‚æœæ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜¾ç¤ºå®Œæ•´çŠ¶æ€ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            if not any([state_context['high_relevance'], state_context['medium_relevance'], state_context['extracted_entities']]):
                enhanced_instruction += f"""
## å·¥ä½œæµå½“å‰çŠ¶æ€
ä»¥ä¸‹æ˜¯å·¥ä½œæµçš„å½“å‰æ•´ä½“çŠ¶æ€ï¼š

{current_state[:800] + '...' if len(current_state) > 800 else current_state}
"""
        else:
            enhanced_instruction += f"""
## å·¥ä½œæµçŠ¶æ€
å·¥ä½œæµåˆšå¼€å§‹æ‰§è¡Œï¼Œè¿™æ˜¯æ—©æœŸæ­¥éª¤ã€‚å½“å‰æ²¡æœ‰è®°å½•çš„å…¨å±€çŠ¶æ€ä¿¡æ¯ã€‚
"""
        
        # æ·»åŠ å‰åºæ­¥éª¤ç»“æœï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        if previous_results:
            enhanced_instruction += f"""
## å‰åºæ­¥éª¤ç»“æœ
{chr(10).join(previous_results[:3])}"""  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
            if len(previous_results) > 3:
                enhanced_instruction += f"\n... (è¿˜æœ‰{len(previous_results)-3}ä¸ªå‰åºç»“æœ)"
        else:
            enhanced_instruction += f"""
## å‰åºæ­¥éª¤ç»“æœ
æ— å‰åºæ­¥éª¤ç»“æœ
"""
        
        # æ™ºèƒ½æ·»åŠ çŠ¶æ€å†å²æ‘˜è¦
        history_count = global_state.get_state_history_count()
        if history_count > 0:
            recent_history = global_state.get_state_history(limit=2)  # å‡å°‘åˆ°2ä¸ªï¼Œé¿å…ä¿¡æ¯è¿‡è½½
            if recent_history:
                enhanced_instruction += f"""
## ğŸ“œ è¿‘æœŸçŠ¶æ€å˜åŒ– ({history_count}æ¬¡æ›´æ–°)
"""
                for i, entry in enumerate(reversed(recent_history)):  # å€’åºæ˜¾ç¤ºï¼Œæœ€æ–°çš„åœ¨å‰
                    enhanced_instruction += f"**{i+1}. {entry.timestamp.strftime('%H:%M:%S')}** ({entry.source or 'AI'}): "
                    # æ›´ä¸¥æ ¼çš„é•¿åº¦é™åˆ¶
                    snapshot = entry.state_snapshot[:200] + "..." if len(entry.state_snapshot) > 200 else entry.state_snapshot
                    enhanced_instruction += f"{snapshot}\n"
        
        # æ·»åŠ åŸºäºæ­¥éª¤ç±»å‹çš„å®šåˆ¶åŒ–æ‰§è¡Œæç¤º
        step_types = []
        if hasattr(self, '_state_extractor'):
            step_analysis = self._state_extractor._analyze_step_requirements(step)
            step_types = step_analysis.get('step_types', [])
        
        enhanced_instruction += f"""
## ğŸ’¡ æ™ºèƒ½æ‰§è¡Œæç¤º
- ğŸ¯ **åŸºäºçŠ¶æ€æ‰§è¡Œ**: ç‰¹åˆ«å…³æ³¨ä¸Šè¿°æ ‡è®°çš„é‡ç‚¹çŠ¶æ€ä¿¡æ¯
- ğŸ”„ **é¿å…é‡å¤å·¥ä½œ**: æ£€æŸ¥å·²æå–çš„å…³é”®ä¿¡æ¯ï¼Œé¿å…é‡å¤ä¹‹å‰å·²å®Œæˆçš„å·¥ä½œ
- ğŸ¨ **ä¿æŒä¸€è‡´æ€§**: ç¡®ä¿ä¸æå–çš„å®ä½“ä¿¡æ¯å’Œé…ç½®ä¿æŒä¸€è‡´"""
        
        # æ ¹æ®æ­¥éª¤ç±»å‹æ·»åŠ ç‰¹å®šæç¤º
        if 'file_operations' in step_types:
            enhanced_instruction += f"\n- ğŸ“ **æ–‡ä»¶æ“ä½œ**: æ³¨æ„å·²å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„å’Œç›®å½•ç»“æ„"
        if 'database' in step_types:
            enhanced_instruction += f"\n- ğŸ—„ï¸ **æ•°æ®åº“æ“ä½œ**: ä½¿ç”¨å·²é…ç½®çš„è¿æ¥ä¿¡æ¯å’Œå‚æ•°"
        if 'api' in step_types:
            enhanced_instruction += f"\n- ğŸŒ **APIæ“ä½œ**: å‚è€ƒå·²æœ‰çš„ç«¯ç‚¹å’ŒæœåŠ¡é…ç½®"
        if 'error_handling' in step_types:
            enhanced_instruction += f"\n- ğŸš¨ **é”™è¯¯å¤„ç†**: åŸºäºä¸Šè¿°é”™è¯¯ä¿¡æ¯è¿›è¡Œé’ˆå¯¹æ€§ä¿®å¤"
        if 'configuration' in step_types:
            enhanced_instruction += f"\n- âš™ï¸ **é…ç½®ä»»åŠ¡**: ä¿æŒä¸ç°æœ‰é…ç½®çš„å…¼å®¹æ€§"
        
        enhanced_instruction += f"""
- ğŸ“ **è´¨é‡ä¿è¯**: å¦‚æœæ˜¯ä»£ç ç›¸å…³ä»»åŠ¡ï¼Œè¯·ç¡®ä¿ä»£ç çš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§
- ğŸ”— **å¼•ç”¨ä¿¡æ¯**: ä¼˜å…ˆä½¿ç”¨ä¸Šè¿°æå–çš„å…³é”®ä¿¡æ¯å’Œå®ä½“æ•°æ®
- ğŸ’¡ **çŠ¶æ€æ›´æ–°**: æ‰§è¡Œå®Œæˆåï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ›´æ–°å…¨å±€çŠ¶æ€
"""
        
        return enhanced_instruction
    
    def _build_state_update_context(self, step: Dict[str, Any], exec_result: Optional[Result], 
                                   workflow_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ„å»ºAIçŠ¶æ€æ›´æ–°å™¨æ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            step: æ‰§è¡Œçš„æ­¥éª¤ä¿¡æ¯
            exec_result: æ­¥éª¤æ‰§è¡Œç»“æœ
            workflow_context: å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            çŠ¶æ€æ›´æ–°ä¸Šä¸‹æ–‡å­—å…¸
        """
        # åŸºç¡€æ­¥éª¤ä¿¡æ¯
        step_info = {
            'step_id': step.get('id', 'unknown'),
            'step_name': step.get('name', 'unknown'),
            'step_type': step.get('type', 'unknown'),
            'step_description': step.get('description', ''),
            'step_expected_output': step.get('expected_output', ''),
        }
        
        # æ‰§è¡Œç»“æœä¿¡æ¯
        result_info = {}
        if exec_result:
            result_info = {
                'success': getattr(exec_result, 'success', False),
                'stdout': getattr(exec_result, 'stdout', ''),
                'stderr': getattr(exec_result, 'stderr', ''),
                'return_value': getattr(exec_result, 'return_value', None),
                'execution_time': getattr(exec_result, 'execution_time', None),
            }
        
        # å·¥ä½œæµæ‰§è¡Œç»Ÿè®¡
        plan = workflow_context.get('plan', [])
        completed_steps = [s for s in plan if s.get('status') == 'completed']
        failed_steps = [s for s in plan if s.get('status') == 'failed']
        
        workflow_stats = {
            'total_steps': len(plan),
            'completed_steps': len(completed_steps),
            'failed_steps': len(failed_steps),
            'current_iteration': workflow_context.get('workflow_iterations', 0),
            'max_iterations': workflow_context.get('max_workflow_iterations', 50),
        }
        
        # å†å²ä»»åŠ¡ä¿¡æ¯ï¼ˆæœ€è¿‘çš„å‡ ä¸ªä»»åŠ¡ï¼‰
        task_history = workflow_context.get('task_history', [])
        recent_history = []
        if task_history:
            # è·å–æœ€è¿‘5ä¸ªä»»åŠ¡çš„ç®€åŒ–ä¿¡æ¯
            for task_item in task_history[-5:]:
                if isinstance(task_item, dict):
                    task = task_item.get('task', {})
                    result = task_item.get('result', {})
                    recent_history.append({
                        'name': task.get('name', 'unknown'),
                        'success': getattr(result, 'success', False),
                        'timestamp': task_item.get('timestamp', '')
                    })
        
        # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        error_info = {}
        if hasattr(exec_result, 'stderr') and exec_result.stderr:
            error_info['error_message'] = exec_result.stderr
        if 'state_update_errors' in workflow_context:
            error_info['previous_update_errors'] = workflow_context['state_update_errors']
        
        # ç»„åˆå®Œæ•´ä¸Šä¸‹æ–‡
        update_context = {
            'step_info': step_info,
            'execution_result': result_info,
            'workflow_stats': workflow_stats,
            'recent_history': recent_history,
            'error_info': error_info,
            'timestamp': dt.now().isoformat(),
            'original_goal': getattr(self, 'original_goal', ''),
            'workflow_summary': workflow_context.get('summary', ''),
        }
        
        return update_context
    
    def _handle_workflow_error(self, context: Dict[str, Any], error: Exception) -> None:
        """å¤„ç†å·¥ä½œæµæ‰§è¡Œé”™è¯¯ï¼Œä½¿ç”¨çŠ¶æ€æ„ŸçŸ¥çš„é”™è¯¯å¤„ç†æœºåˆ¶"""
        try:
            # æ›´æ–°é”™è¯¯ç»Ÿè®¡
            self.error_statistics['total_errors'] += 1
            
            # è·å–å½“å‰æ‰§è¡Œçš„æ­¥éª¤
            current_step = context.get('current_step', {})
            if not current_step:
                # å¦‚æœæ²¡æœ‰å½“å‰æ­¥éª¤ï¼Œä½¿ç”¨é»˜è®¤æ­¥éª¤ä¿¡æ¯
                current_step = {
                    'id': 'unknown',
                    'name': 'unknown_step',
                    'instruction': 'Unknown step',
                    'agent_name': 'unknown'
                }
            
            # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            execution_context = {
                'plan': context.get('plan', []),
                'completed_steps': context.get('completed_steps', 0),
                'failed_steps': context.get('failed_steps', 0),
                'summary': context.get('summary', ''),
                'start_time': context.get('start_time'),
                'retry_count': context.get('retry_count', 0),
                'workflow_state': self.workflow_state
            }
            
            # ä½¿ç”¨é”™è¯¯åˆ†å‘å™¨å¤„ç†é”™è¯¯
            error_result = self.error_dispatcher.dispatch_error(
                error=error,
                step=current_step,
                global_state=self.workflow_state,
                execution_context=execution_context
            )
            
            # å¤„ç†é”™è¯¯å¤„ç†ç»“æœ
            if error_result.get('handled', False):
                self.error_statistics['handled_errors'] += 1
                
                # åº”ç”¨æ¢å¤åŠ¨ä½œ
                recovery_action = error_result.get('recovery_action')
                if recovery_action:
                    self._apply_recovery_action(recovery_action, context)
                
                # æ·»åŠ å¤„ç†ç»“æœåˆ°æ‘˜è¦
                context['summary'] += f"\né”™è¯¯å·²å¤„ç†: {error_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                
                # æ—¥å¿—è®°å½•
                logger.info(f"é”™è¯¯å·²æˆåŠŸå¤„ç†: {error_result.get('message')}")
                
            else:
                self.error_statistics['unhandled_errors'] += 1
                context['summary'] += f"\nå·¥ä½œæµæ‰§è¡Œå‡ºé”™: {str(error)}"
                logger.error(f"å·¥ä½œæµæ‰§è¡Œå‡ºé”™ï¼ˆæœªå¤„ç†ï¼‰: {error}")
            
            # æ›´æ–°é”™è¯¯ç±»å‹ç»Ÿè®¡
            error_type = error_result.get('error_type', 'unknown')
            self.error_statistics['error_types'][error_type] = \
                self.error_statistics['error_types'].get(error_type, 0) + 1
            
            # è®¡ç®—æ¢å¤æˆåŠŸç‡
            if self.error_statistics['total_errors'] > 0:
                self.error_statistics['recovery_success_rate'] = \
                    self.error_statistics['handled_errors'] / self.error_statistics['total_errors']
            
        except Exception as handler_error:
            # é”™è¯¯å¤„ç†å™¨æœ¬èº«å‡ºé”™çš„æƒ…å†µ
            self.error_statistics['unhandled_errors'] += 1
            context['summary'] += f"\né”™è¯¯å¤„ç†å¤±è´¥: {str(handler_error)}"
            logger.error(f"é”™è¯¯å¤„ç†å™¨å¤±è´¥: {handler_error}")
            logger.error(f"åŸå§‹é”™è¯¯: {error}")
    
    def _apply_recovery_action(self, action: str, context: Dict[str, Any]) -> None:
        """åº”ç”¨æ¢å¤åŠ¨ä½œ"""
        try:
            if action == "retry_step":
                # é‡è¯•å½“å‰æ­¥éª¤
                context['should_retry'] = True
                logger.info("å·²æ ‡è®°é‡è¯•å½“å‰æ­¥éª¤")
                
            elif action == "skip_step":
                # è·³è¿‡å½“å‰æ­¥éª¤
                context['should_skip'] = True
                logger.info("å·²æ ‡è®°è·³è¿‡å½“å‰æ­¥éª¤")
                
            elif action == "pause_workflow":
                # æš‚åœå·¥ä½œæµ
                context['should_pause'] = True
                logger.info("å·²æ ‡è®°æš‚åœå·¥ä½œæµ")
                
            elif action == "continue_workflow":
                # ç»§ç»­å·¥ä½œæµ
                context['should_continue'] = True
                logger.info("å·²æ ‡è®°ç»§ç»­å·¥ä½œæµ")
                
            elif action.startswith("delay_"):
                # å»¶è¿Ÿæ‰§è¡Œ
                delay_seconds = int(action.split("_")[1])
                context['delay_seconds'] = delay_seconds
                logger.info(f"å·²è®¾ç½®å»¶è¿Ÿ {delay_seconds} ç§’")
                
            elif action == "generate_fix_task":
                # ç”Ÿæˆä¿®å¤ä»»åŠ¡
                context['generate_fix_task'] = True
                logger.info("å·²æ ‡è®°ç”Ÿæˆä¿®å¤ä»»åŠ¡")
                
            else:
                logger.warning(f"æœªçŸ¥çš„æ¢å¤åŠ¨ä½œ: {action}")
                
        except Exception as e:
            logger.error(f"åº”ç”¨æ¢å¤åŠ¨ä½œå¤±è´¥ [{action}]: {e}")
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """è·å–é”™è¯¯å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        return self.error_statistics.copy()
    
    def reset_error_statistics(self) -> None:
        """é‡ç½®é”™è¯¯å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        self.error_statistics = {
            'total_errors': 0,
            'handled_errors': 0,
            'unhandled_errors': 0,
            'error_types': {},
            'recovery_success_rate': 0.0
        }
        logger.info("é”™è¯¯å¤„ç†ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def enable_instruction_optimization(self) -> None:
        """å¯ç”¨æŒ‡ä»¤ä¼˜åŒ–"""
        self.optimization_enabled = True
        logger.info("æŒ‡ä»¤ä¼˜åŒ–ç³»ç»Ÿå·²å¯ç”¨")
    
    def disable_instruction_optimization(self) -> None:
        """ç¦ç”¨æŒ‡ä»¤ä¼˜åŒ–"""
        self.optimization_enabled = False
        logger.info("æŒ‡ä»¤ä¼˜åŒ–ç³»ç»Ÿå·²ç¦ç”¨")
    
    def set_optimization_strategy(self, strategy: OptimizationStrategy) -> None:
        """è®¾ç½®ä¼˜åŒ–ç­–ç•¥"""
        if hasattr(self, 'instruction_optimizer'):
            self.instruction_optimizer.strategy = strategy
            logger.info(f"æŒ‡ä»¤ä¼˜åŒ–ç­–ç•¥å·²è®¾ç½®ä¸º: {strategy.value}")
        else:
            logger.warning("æŒ‡ä»¤ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–")
    
    def get_optimization_statistics(self) -> Dict[str, Any]:
        """è·å–æŒ‡ä»¤ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        if hasattr(self, 'instruction_optimizer'):
            stats = self.instruction_optimizer.get_optimization_statistics()
            stats['optimization_enabled'] = self.optimization_enabled
            stats['strategy'] = self.instruction_optimizer.strategy.value
            return stats
        else:
            return {
                'optimization_enabled': False,
                'message': 'æŒ‡ä»¤ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–'
            }
    
    def reset_optimization_statistics(self) -> None:
        """é‡ç½®æŒ‡ä»¤ä¼˜åŒ–ç»Ÿè®¡"""
        if hasattr(self, 'instruction_optimizer'):
            self.instruction_optimizer.reset_optimization_statistics()
            logger.info("æŒ‡ä»¤ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
        else:
            logger.warning("æŒ‡ä»¤ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–")
    
    def create_decision_node(self, node_id: str, node_type: DecisionNodeType, 
                           description: str = "") -> DecisionNode:
        """åˆ›å»ºå†³ç­–èŠ‚ç‚¹"""
        node = DecisionNode(node_id, node_type, description)
        self.decision_manager.register_decision_node(node)
        return node
    
    def add_conditional_decision(self, node_id: str, condition: StateCondition, 
                               true_step: str, false_step: str, description: str = "") -> DecisionNode:
        """æ·»åŠ æ¡ä»¶å†³ç­–èŠ‚ç‚¹çš„å¿«æ·æ–¹æ³•"""
        return self.decision_manager.create_conditional_node(node_id, condition, true_step, false_step, description)
    
    def add_validation_decision(self, node_id: str, condition: StateCondition,
                              valid_step: str, invalid_step: str, description: str = "") -> DecisionNode:
        """æ·»åŠ éªŒè¯å†³ç­–èŠ‚ç‚¹çš„å¿«æ·æ–¹æ³•"""
        return self.decision_manager.create_validation_node(node_id, condition, valid_step, invalid_step, description)
    
    def evaluate_workflow_decision(self, node_id: str) -> DecisionResult:
        """è¯„ä¼°å·¥ä½œæµå†³ç­–èŠ‚ç‚¹"""
        return self.decision_manager.evaluate_decision(node_id, self.workflow_state)
    
    def list_decision_nodes(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å†³ç­–èŠ‚ç‚¹"""
        return self.decision_manager.list_decision_nodes()
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """è·å–å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        return self.decision_manager.get_decision_statistics()
    
    def reset_decision_statistics(self) -> None:
        """é‡ç½®å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        self.decision_manager.reset_decision_statistics()
        logger.info("å†³ç­–ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def _generate_execution_summary(self, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆæœ€ç»ˆæ‰§è¡Œæ‘˜è¦ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å“åº”åˆ†æï¼‰"""
        all_steps = context['plan']
        completed_steps = [s for s in all_steps if s.get("status") == "completed"]
        failed_steps = [s for s in all_steps if s.get("status") == "failed"]
        pending_steps = [s for s in all_steps if s.get("status") not in ("completed", "failed", "skipped")]
        
        # åŸºç¡€æ‘˜è¦
        summary = f"""
## æ‰§è¡Œæ‘˜è¦
- æ€»æ­¥éª¤æ•°: {len(all_steps)}
- å·²å®Œæˆ: {len(completed_steps)}
- å¤±è´¥: {len(failed_steps)}
- æœªæ‰§è¡Œ: {len(pending_steps)}

{context['summary']}
"""
        
        # æ·»åŠ å“åº”åˆ†ææ‘˜è¦
        if self.enable_response_analysis and self.response_parser and self.parsed_responses_history:
            analysis_summary = self._generate_response_analysis_summary()
            summary += f"\n## ğŸ¤– æ™ºèƒ½åˆ†ææ‘˜è¦\n{analysis_summary}"
        
        return summary
    

    def make_decision(self, current_result, task_history=None, context=None):
        """
        åˆ†æå½“å‰æ‰§è¡Œç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥æ“ä½œï¼ˆæ”¯æŒçŠ¶æ€æ„ŸçŸ¥å†³ç­–ï¼‰
        
        Args:
            current_result: å½“å‰æ‰§è¡Œç»“æœï¼ˆResultå¯¹è±¡æˆ–å…¶ä»–ç»“æœï¼‰
            task_history: ä»»åŠ¡æ‰§è¡Œå†å²è®°å½•ï¼ˆå¯é€‰ï¼‰
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å†³ç­–ç»“æœå­—å…¸ï¼ŒåŒ…å«actionã€reasonå’Œnew_tasks
        """
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨çŠ¶æ€æ„ŸçŸ¥å†³ç­–ç³»ç»Ÿ
            state_decision = self._try_state_aware_decision(current_result, task_history, context)
            if state_decision:
                logger.info(f"ä½¿ç”¨çŠ¶æ€æ„ŸçŸ¥å†³ç­–: {state_decision['action']}")
                return state_decision
            
            # å›é€€åˆ°ä¼ ç»Ÿçš„LLMå†³ç­–
            logger.debug("å›é€€åˆ°ä¼ ç»ŸLLMå†³ç­–æœºåˆ¶")
            return self._make_traditional_decision(current_result, task_history, context)
            
        except Exception as e:
            logger.error(f"å†³ç­–è¿‡ç¨‹å¼‚å¸¸: {e}")
            return self._get_fallback_decision(str(e))
    
    def _try_state_aware_decision(self, current_result, task_history=None, context=None) -> Optional[Dict[str, Any]]:
        """
        å°è¯•ä½¿ç”¨çŠ¶æ€æ„ŸçŸ¥å†³ç­–ç³»ç»Ÿ
        
        Returns:
            å†³ç­–ç»“æœå­—å…¸æˆ–Noneï¼ˆå¦‚æœæ— æ³•ä½¿ç”¨çŠ¶æ€æ„ŸçŸ¥å†³ç­–ï¼‰
        """
        try:
            # è·å–ä¸‹ä¸€ä¸ªå¯æ‰§è¡Œæ­¥éª¤ä»¥ç¡®å®šå†³ç­–åœºæ™¯
            plan = self.get_plan()
            next_step_info = self.select_next_executable_step(plan)
            
            if next_step_info:
                current_idx, current_step = next_step_info
                step_id = current_step.get('id', f'step_{current_idx}')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é’ˆå¯¹è¯¥æ­¥éª¤çš„å†³ç­–èŠ‚ç‚¹
                decision_node_id = f"decision_{step_id}"
                decision_nodes = self.decision_manager.list_decision_nodes()
                
                # å¦‚æœå­˜åœ¨ç›¸å…³çš„å†³ç­–èŠ‚ç‚¹ï¼Œä½¿ç”¨çŠ¶æ€æ„ŸçŸ¥å†³ç­–
                for node_info in decision_nodes:
                    if node_info['node_id'] == decision_node_id:
                        decision_result = self.decision_manager.evaluate_decision(
                            decision_node_id, self.workflow_state
                        )
                        
                        if decision_result.decision_made:
                            return self._convert_decision_result(decision_result, current_step)
                
                # åŠ¨æ€åˆ›å»ºå†³ç­–èŠ‚ç‚¹ï¼ˆåŸºäºæ­¥éª¤ç±»å‹å’Œå½“å‰çŠ¶æ€ï¼‰
                dynamic_decision = self._create_dynamic_decision(current_step, current_result, context)
                if dynamic_decision:
                    return dynamic_decision
            
            # æ£€æŸ¥å·¥ä½œæµçº§åˆ«çš„å†³ç­–
            workflow_decision = self._evaluate_workflow_level_decisions(current_result, task_history, context)
            if workflow_decision:
                return workflow_decision
                
            return None
            
        except Exception as e:
            logger.warning(f"çŠ¶æ€æ„ŸçŸ¥å†³ç­–å°è¯•å¤±è´¥: {e}")
            return None
    
    def _create_dynamic_decision(self, current_step: Dict[str, Any], current_result, context=None) -> Optional[Dict[str, Any]]:
        """
        åŸºäºæ­¥éª¤ç±»å‹å’Œå…¨å±€çŠ¶æ€åŠ¨æ€åˆ›å»ºå†³ç­–
        
        Args:
            current_step: å½“å‰æ­¥éª¤ä¿¡æ¯
            current_result: æ‰§è¡Œç»“æœ
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å†³ç­–ç»“æœæˆ–None
        """
        try:
            step_name = current_step.get('name', '').lower()
            step_instruction = current_step.get('instruction', '').lower()
            global_state_content = self.workflow_state.get_global_state().lower()
            
            # æ£€æµ‹æµ‹è¯•æ­¥éª¤çš„æˆåŠŸ/å¤±è´¥åˆ†æ”¯
            if any(keyword in step_name or keyword in step_instruction 
                   for keyword in ['test', 'æµ‹è¯•', 'verify', 'éªŒè¯', 'check', 'æ£€æŸ¥']):
                return self._create_test_decision(current_step, current_result)
            
            # æ£€æµ‹æ•°æ®éªŒè¯æ­¥éª¤
            if any(keyword in step_name or keyword in step_instruction 
                   for keyword in ['validate', 'éªŒè¯', 'confirm', 'ç¡®è®¤']):
                return self._create_validation_decision(current_step, current_result)
            
            # æ£€æµ‹å®¡æ‰¹æˆ–äººå·¥ç¡®è®¤æ­¥éª¤
            if any(keyword in step_name or keyword in step_instruction 
                   for keyword in ['approve', 'å®¡æ‰¹', 'review', 'å®¡æŸ¥', 'confirm', 'ç¡®è®¤']):
                return self._create_approval_decision(current_step, current_result)
            
            # åŸºäºå…¨å±€çŠ¶æ€çš„æ¡ä»¶å†³ç­–
            if any(keyword in global_state_content 
                   for keyword in ['é”™è¯¯', 'error', 'å¤±è´¥', 'fail', 'å¼‚å¸¸', 'exception']):
                return self._create_error_recovery_decision(current_step, current_result)
            
            return None
            
        except Exception as e:
            logger.error(f"åŠ¨æ€å†³ç­–åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def _create_test_decision(self, current_step: Dict[str, Any], current_result) -> Dict[str, Any]:
        """åˆ›å»ºæµ‹è¯•æ­¥éª¤çš„å†³ç­–"""
        # åˆ¤æ–­æµ‹è¯•æ˜¯å¦æˆåŠŸ
        test_success = False
        if isinstance(current_result, Result):
            test_success = current_result.success
            # è¿›ä¸€æ­¥æ£€æŸ¥è¾“å‡ºå†…å®¹
            if current_result.stdout:
                output_lower = current_result.stdout.lower()
                if any(keyword in output_lower for keyword in ['pass', 'passed', 'é€šè¿‡', 'æˆåŠŸ']):
                    test_success = True
                elif any(keyword in output_lower for keyword in ['fail', 'failed', 'error', 'å¤±è´¥', 'é”™è¯¯']):
                    test_success = False
        
        if test_success:
            return {
                'action': 'complete',
                'reason': 'æµ‹è¯•é€šè¿‡ï¼Œå·¥ä½œæµæ‰§è¡ŒæˆåŠŸå®Œæˆ',
                'new_tasks': [],
                'decision_source': 'state_aware_test'
            }
        else:
            return {
                'action': 'generate_fix_task_and_loop',
                'reason': 'æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ç”Ÿæˆä¿®å¤ä»»åŠ¡å¹¶é‡æ–°æµ‹è¯•',
                'new_tasks': [],
                'loop_target': current_step.get('id'),
                'fix_instruction': 'åˆ†ææµ‹è¯•å¤±è´¥åŸå› å¹¶ä¿®å¤ä»£ç ',
                'fix_agent': 'coder',
                'decision_source': 'state_aware_test'
            }
    
    def _create_validation_decision(self, current_step: Dict[str, Any], current_result) -> Dict[str, Any]:
        """åˆ›å»ºéªŒè¯æ­¥éª¤çš„å†³ç­–"""
        # ç®€å•çš„éªŒè¯é€»è¾‘ï¼šæ£€æŸ¥æ‰§è¡Œç»“æœ
        validation_success = isinstance(current_result, Result) and current_result.success
        
        if validation_success:
            return {
                'action': 'continue',
                'reason': 'éªŒè¯æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥',
                'new_tasks': [],
                'decision_source': 'state_aware_validation'
            }
        else:
            return {
                'action': 'retry',
                'reason': 'éªŒè¯å¤±è´¥ï¼Œé‡è¯•å½“å‰æ­¥éª¤',
                'new_tasks': [],
                'decision_source': 'state_aware_validation'
            }
    
    def _create_approval_decision(self, current_step: Dict[str, Any], current_result) -> Dict[str, Any]:
        """åˆ›å»ºå®¡æ‰¹æ­¥éª¤çš„å†³ç­–"""
        # åŸºäºæ‰§è¡Œç»“æœåˆ¤æ–­å®¡æ‰¹çŠ¶æ€
        approval_granted = isinstance(current_result, Result) and current_result.success
        
        if approval_granted:
            return {
                'action': 'continue',
                'reason': 'å®¡æ‰¹é€šè¿‡ï¼Œç»§ç»­æ‰§è¡Œ',
                'new_tasks': [],
                'decision_source': 'state_aware_approval'
            }
        else:
            return {
                'action': 'complete',
                'reason': 'å®¡æ‰¹æœªé€šè¿‡ï¼Œç»ˆæ­¢å·¥ä½œæµ',
                'new_tasks': [],
                'decision_source': 'state_aware_approval'
            }
    
    def _create_error_recovery_decision(self, current_step: Dict[str, Any], current_result) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯æ¢å¤å†³ç­–"""
        return {
            'action': 'generate_new_task',
            'reason': 'æ£€æµ‹åˆ°é”™è¯¯çŠ¶æ€ï¼Œç”Ÿæˆé”™è¯¯æ¢å¤ä»»åŠ¡',
            'new_tasks': [{
                'id': f'error_recovery_{len(self.get_plan()) + 1}',
                'name': 'é”™è¯¯æ¢å¤å¤„ç†',
                'instruction': 'åˆ†æå’Œå¤„ç†å½“å‰å·¥ä½œæµä¸­çš„é”™è¯¯çŠ¶æ€',
                'agent_name': 'coder',
                'instruction_type': 'execution',
                'phase': 'verification',
                'expected_output': 'é”™è¯¯ä¿®å¤ç»“æœ',
                'prerequisites': 'æ— '
            }],
            'decision_source': 'state_aware_error_recovery'
        }
    
    def _evaluate_workflow_level_decisions(self, current_result, task_history=None, context=None) -> Optional[Dict[str, Any]]:
        """
        è¯„ä¼°å·¥ä½œæµçº§åˆ«çš„å†³ç­–ï¼ˆå¦‚å®Œæˆæ¡ä»¶ã€å¾ªç¯æ§åˆ¶ç­‰ï¼‰
        
        Returns:
            å·¥ä½œæµçº§åˆ«çš„å†³ç­–ç»“æœæˆ–None
        """
        try:
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å®Œæˆæ¡ä»¶
            completion_decision = self._check_completion_conditions()
            if completion_decision:
                return completion_decision
            
            # æ£€æŸ¥å¾ªç¯æ§åˆ¶
            loop_decision = self._check_loop_conditions(current_result, task_history)
            if loop_decision:
                return loop_decision
            
            return None
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµçº§åˆ«å†³ç­–è¯„ä¼°å¤±è´¥: {e}")
            return None
    
    def _check_completion_conditions(self) -> Optional[Dict[str, Any]]:
        """æ£€æŸ¥å·¥ä½œæµå®Œæˆæ¡ä»¶"""
        try:
            plan = self.get_plan()
            global_state = self.workflow_state.get_global_state().lower()
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ ¸å¿ƒæ­¥éª¤éƒ½å·²å®Œæˆ
            completed_steps = [step for step in plan if step.get('status') == 'completed']
            total_steps = len(plan)
            completion_rate = len(completed_steps) / total_steps if total_steps > 0 else 0
            
            # å¦‚æœå®Œæˆç‡å¾ˆé«˜ä¸”å…¨å±€çŠ¶æ€æ˜¾ç¤ºæˆåŠŸ
            if completion_rate >= 0.8 and any(keyword in global_state 
                                            for keyword in ['æˆåŠŸ', 'success', 'complete', 'å®Œæˆ', 'pass', 'é€šè¿‡']):
                return {
                    'action': 'complete',
                    'reason': f'å·¥ä½œæµå®Œæˆç‡{completion_rate:.1%}ï¼Œå…¨å±€çŠ¶æ€æ˜¾ç¤ºæˆåŠŸ',
                    'new_tasks': [],
                    'decision_source': 'state_aware_completion'
                }
            
            return None
            
        except Exception as e:
            logger.error(f"å®Œæˆæ¡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
            return None
    
    def _check_loop_conditions(self, current_result, task_history=None) -> Optional[Dict[str, Any]]:
        """æ£€æŸ¥å¾ªç¯æ§åˆ¶æ¡ä»¶"""
        try:
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°
            for loop_key, count in self.workflow_state.loop_counters.items():
                if count >= self.workflow_state.max_loops:
                    return {
                        'action': 'complete',
                        'reason': f'è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°é™åˆ¶({self.workflow_state.max_loops})ï¼Œç»ˆæ­¢æ‰§è¡Œ',
                        'new_tasks': [],
                        'decision_source': 'state_aware_loop_limit'
                    }
            
            return None
            
        except Exception as e:
            logger.error(f"å¾ªç¯æ¡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
            return None
    
    def _convert_decision_result(self, decision_result: DecisionResult, current_step: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†StateAwareDecisionManagerçš„DecisionResultè½¬æ¢ä¸ºæ ‡å‡†å†³ç­–æ ¼å¼
        
        Args:
            decision_result: StateAwareDecisionManagerçš„å†³ç­–ç»“æœ
            current_step: å½“å‰æ­¥éª¤ä¿¡æ¯
            
        Returns:
            æ ‡å‡†æ ¼å¼çš„å†³ç­–å­—å…¸
        """
        try:
            # åŸºç¡€å†³ç­–ä¿¡æ¯
            decision = {
                'reason': decision_result.decision_reason,
                'new_tasks': [],
                'decision_source': 'state_aware_manager',
                'confidence': decision_result.confidence,
                'state_variables_used': decision_result.state_variables_used
            }
            
            # æ ¹æ®next_step_idç¡®å®šaction
            if decision_result.next_step_id:
                if decision_result.next_step_id == current_step.get('id'):
                    decision['action'] = 'retry'
                else:
                    decision['action'] = 'jump_to'
                    decision['target_step_id'] = decision_result.next_step_id
            else:
                decision['action'] = 'complete'
            
            # æ·»åŠ é¢å¤–çš„å»ºè®®è¡ŒåŠ¨
            if decision_result.additional_actions:
                decision['additional_actions'] = decision_result.additional_actions
            
            return decision
            
        except Exception as e:
            logger.error(f"å†³ç­–ç»“æœè½¬æ¢å¤±è´¥: {e}")
            return self._get_fallback_decision("å†³ç­–ç»“æœè½¬æ¢å¤±è´¥")
    
    def _make_traditional_decision(self, current_result, task_history=None, context=None) -> Dict[str, Any]:
        """
        ä¼ ç»Ÿçš„åŸºäºLLMçš„å†³ç­–æ–¹æ³•
        
        Returns:
            å†³ç­–ç»“æœå­—å…¸
        """
        # ç”Ÿæˆå†³ç­–æç¤º
        decision_prompt = self._generate_decision_prompt(current_result, task_history, context)
        
        # è°ƒç”¨LLMè¿›è¡Œå†³ç­–
        try:
            result = self.chat_sync(decision_prompt)
            if result.success:
                decision_text = result.return_value if result.return_value else result.stdout
                decision = self._parse_decision(decision_text)
                decision['decision_source'] = 'traditional_llm'
                return decision
            else:
                logger.warning(f"LLMå†³ç­–å¤±è´¥: {result.stderr}")
                return self._get_fallback_decision("LLMå†³ç­–è¿‡ç¨‹å‡ºé”™")
        except Exception as e:
            logger.error(f"ä¼ ç»Ÿå†³ç­–è¿‡ç¨‹å¼‚å¸¸: {e}")
            return self._get_fallback_decision(f"ä¼ ç»Ÿå†³ç­–è¿‡ç¨‹å¼‚å¸¸: {e}")
    
    def _get_fallback_decision(self, reason: str) -> Dict[str, Any]:
        """
        è·å–å›é€€å†³ç­–
        
        Args:
            reason: éœ€è¦å›é€€çš„åŸå› 
            
        Returns:
            å›é€€å†³ç­–ç»“æœ
        """
        return {
            'action': 'continue',
            'reason': f'å†³ç­–ç³»ç»Ÿå¼‚å¸¸({reason})ï¼Œé»˜è®¤ç»§ç»­æ‰§è¡Œ',
            'new_tasks': [],
            'decision_source': 'fallback'
        }

    def _generate_decision_prompt(self, current_result, task_history=None, context=None):
        """
        ç”Ÿæˆç”¨äºå†³ç­–çš„æç¤º (æ–¹æ¡ˆ2: æ”¯æŒå¾ªç¯å’Œæ¡ä»¶åˆ†æ”¯æ§åˆ¶)
        
        Args:
            current_result: å½“å‰æ‰§è¡Œç»“æœ
            task_history: ä»»åŠ¡æ‰§è¡Œå†å²
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å†³ç­–æç¤ºå­—ç¬¦ä¸²
        """
        # è·å–å½“å‰è®¡åˆ’å’ŒçŠ¶æ€
        plan = self.get_plan()
        # ä¸å†ä½¿ç”¨å›ºå®šçš„current_step_indexï¼Œè€Œæ˜¯åŸºäºä»»åŠ¡å†å²ç¡®å®šå½“å‰çŠ¶æ€
        
        # è·å–å¯ç”¨æ™ºèƒ½ä½“åˆ—è¡¨
        available_agents = "\n".join([
            f"- {spec.name}: {spec.description}" for spec in self.registered_agents
        ]) if self.registered_agents else "æ— å¯ç”¨æ™ºèƒ½ä½“"
        
        # æ ¼å¼åŒ–å½“å‰ç»“æœ
        if isinstance(current_result, Result):
            result_str = f"æˆåŠŸ: {current_result.success}\n"
            if current_result.stdout:
                result_str += f"è¾“å‡º: {current_result.stdout[:500]}{'...' if len(current_result.stdout) > 500 else ''}\n"
            if current_result.stderr:
                result_str += f"é”™è¯¯: {current_result.stderr}\n"
            if current_result.return_value:
                result_str += f"è¿”å›å€¼: {current_result.return_value}\n"
        else:
            result_str = str(current_result)
        
        # æ ¼å¼åŒ–ä»»åŠ¡å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        history_str = ""
        if task_history:
            try:
                history_items = []
                for item in task_history:
                    if isinstance(item, dict):
                        task = item.get('task', {})
                        task_id = task.get('id', 'unknown')
                        task_name = task.get('name', 'unnamed')
                        task_result = item.get('result', {})
                        task_success = getattr(task_result, 'success', False)
                        history_items.append(f"ä»»åŠ¡ {task_id} ({task_name}): {'æˆåŠŸ' if task_success else 'å¤±è´¥'}")
                history_str = "\n".join(history_items)
            except Exception as e:
                history_str = f"æ— æ³•æ ¼å¼åŒ–ä»»åŠ¡å†å²: {e}"
        
        # æ£€æŸ¥å‰©ä½™ä»»åŠ¡
        completed_steps = [step for step in plan if step.get('status') == 'completed']
        pending_steps = [step for step in plan if step.get('status') not in ['completed', 'skipped']]
        remaining_steps_str = "\n".join([
            f"- {step.get('id')}: {step.get('name')}" for step in pending_steps
        ]) if pending_steps else "æ— å‰©ä½™æ­¥éª¤"
        
        # å·¥ä½œæµçŠ¶æ€ä¿¡æ¯  
        last_executed_step = None
        if task_history:
            last_executed_step = task_history[-1].get('task', {}).get('name', 'æ— ')
        
        workflow_state_str = f"""
æœ€åæ‰§è¡Œæ­¥éª¤: {last_executed_step or 'æ— '}
å¾ªç¯è®¡æ•°å™¨: {self.workflow_state.loop_counters}
ä¿®å¤ä»»åŠ¡è®¡æ•°: {self.workflow_state.fix_counter}
"""
        
        # æ ¼å¼åŒ–é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰ï¼‰
        context_str = ""
        if context:
            if isinstance(context, dict):
                context_str = "\n".join([f"{k}: {v}" for k, v in context.items()])
            else:
                context_str = str(context)
        
        # ç”Ÿæˆå†³ç­–æç¤º
        prompt = f"""
# æ‰§è¡Œå†³ç­–åˆ†æ (æ–¹æ¡ˆ2: åŠ¨æ€æ§åˆ¶æµ)

## å½“å‰æ‰§è¡ŒçŠ¶æ€
å·²å®Œæˆæ­¥éª¤æ•°: {len(completed_steps)}
å‰©ä½™æ­¥éª¤æ•°: {len(pending_steps)}

## å·¥ä½œæµçŠ¶æ€
{workflow_state_str}

## å½“å‰ç»“æœ
{result_str}

## ä»»åŠ¡å†å²
{history_str}

## å¯ç”¨æ™ºèƒ½ä½“
{available_agents}

## å‰©ä½™æ­¥éª¤
{remaining_steps_str}

## åŸå§‹ç›®æ ‡
{getattr(self, 'original_goal', 'æœªè®¾ç½®')}

## é¢å¤–ä¸Šä¸‹æ–‡
{context_str}

## å†³ç­–ä»»åŠ¡
è¯·åˆ†æå½“å‰æ‰§è¡ŒçŠ¶æ€å’Œç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥æ“ä½œã€‚å¯é€‰çš„æ“ä½œæœ‰ï¼š

### åŸºæœ¬å†³ç­–ç±»å‹ï¼š
1. **continue**: ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªè®¡åˆ’æ­¥éª¤
2. **complete**: å®Œæˆæ•´ä¸ªå·¥ä½œæµï¼ˆç›®æ ‡å·²è¾¾æˆï¼‰
3. **retry**: é‡è¯•å½“å‰æ­¥éª¤
4. **generate_new_task**: ç”Ÿæˆæ–°çš„ä»»åŠ¡

### æ§åˆ¶æµå†³ç­–ç±»å‹ï¼ˆæ–¹æ¡ˆ2æ–°å¢ï¼‰ï¼š
5. **jump_to**: è·³è½¬åˆ°æŒ‡å®šæ­¥éª¤ID
6. **loop_back**: å¾ªç¯å›åˆ°æŒ‡å®šæ­¥éª¤ID
7. **generate_fix_task_and_loop**: ç”Ÿæˆä¿®å¤ä»»åŠ¡å¹¶å¾ªç¯å›åˆ°æµ‹è¯•æ­¥éª¤

## å†³ç­–ç­–ç•¥

### æµ‹è¯•ç»“æœåˆ†æï¼ˆé’ˆå¯¹æµ‹è¯•æ­¥éª¤ï¼‰
å¦‚æœå½“å‰æ­¥éª¤æ˜¯æµ‹è¯•æ­¥éª¤ï¼Œè¯·æ ¹æ®æµ‹è¯•ç»“æœå†³ç­–ï¼š
- **æµ‹è¯•æˆåŠŸ**: é€‰æ‹© `complete`
- **æµ‹è¯•å¤±è´¥**: é€‰æ‹© `generate_fix_task_and_loop`ï¼Œç”Ÿæˆä¿®å¤ä»»åŠ¡å¹¶å¾ªç¯å›åˆ°æµ‹è¯•æ­¥éª¤

### å¾ªç¯æ§åˆ¶ç­–ç•¥
- æ£€æŸ¥å¾ªç¯æ¬¡æ•°æ˜¯å¦è¶…è¿‡é™åˆ¶ï¼ˆå½“å‰é™åˆ¶: {self.workflow_state.max_loops}æ¬¡ï¼‰
- å¦‚æœè¶…è¿‡é™åˆ¶ï¼Œé€‰æ‹© `complete` å¹¶è¯´æ˜åŸå› 
- å¦‚æœéœ€è¦ä¿®å¤é”™è¯¯ï¼Œä½¿ç”¨ `generate_fix_task_and_loop`

### å…¶ä»–ç­–ç•¥
- ä¿¡æ¯ä¸è¶³: ç”Ÿæˆä¿¡æ¯æ”¶é›†ä»»åŠ¡
- é”™è¯¯å¤„ç†: ç”Ÿæˆè¯Šæ–­å’Œä¿®å¤ä»»åŠ¡
- æ›¿ä»£æ–¹æ¡ˆ: å°è¯•å…¶ä»–æ–¹æ³•

## è¾“å‡ºæ ¼å¼
è¯·ä»¥JSONæ ¼å¼è¿”å›ä½ çš„å†³ç­–ï¼š

```json
{{
  "action": "continue|complete|retry|generate_new_task|jump_to|loop_back|generate_fix_task_and_loop",
  "reason": "è¯¦ç»†è¯´æ˜ä½ çš„å†³ç­–ç†ç”±",
  "target_step_id": "ç›®æ ‡æ­¥éª¤IDï¼ˆä»…ç”¨äºjump_toå’Œloop_backï¼‰",
  "loop_target": "å¾ªç¯ç›®æ ‡æ­¥éª¤IDï¼ˆä»…ç”¨äºgenerate_fix_task_and_loopï¼‰",
  "fix_instruction": "ä¿®å¤æŒ‡ä»¤ï¼ˆä»…ç”¨äºgenerate_fix_task_and_loopï¼‰",
  "fix_agent": "ä¿®å¤æ™ºèƒ½ä½“ï¼ˆä»…ç”¨äºgenerate_fix_task_and_loopï¼‰",
  "error_details": "é”™è¯¯è¯¦æƒ…ï¼ˆä»…ç”¨äºgenerate_fix_task_and_loopï¼‰",
  "new_tasks": [
    {{
      "id": "task_id",
      "name": "ä»»åŠ¡åç§°",
      "instruction": "è¯¦ç»†æŒ‡ä»¤",
      "agent_name": "æ‰§è¡Œæ™ºèƒ½ä½“åç§°",
      "phase": "information|execution|verification",
      "prerequisites": "å…ˆå†³æ¡ä»¶æè¿°"
    }}
  ]
}}
```

é‡è¦æç¤ºï¼š
1. å¦‚æœå‰©ä½™æ­¥éª¤ä¸ä¸ºç©ºä¸”æœªè¾¾åˆ°ç›®æ ‡ï¼Œä¸è¦é€‰æ‹©complete
2. å¦‚æœé€‰æ‹©generate_new_taskï¼Œå¿…é¡»æä¾›å®Œæ•´çš„new_tasksæ•°ç»„
3. å¦‚æœé€‰æ‹©æ§åˆ¶æµæ“ä½œï¼Œå¿…é¡»æä¾›ç›¸åº”çš„ç›®æ ‡æ­¥éª¤ID
4. æ–°ä»»åŠ¡çš„agent_nameå¿…é¡»ä»å¯ç”¨æ™ºèƒ½ä½“åˆ—è¡¨ä¸­é€‰æ‹©
5. ä¼˜å…ˆä½¿ç”¨ä¸“é—¨çš„æ§åˆ¶æµå†³ç­–ç±»å‹æ¥å¤„ç†å¾ªç¯å’Œæ¡ä»¶åˆ†æ”¯
"""
        return prompt
    
    def _parse_decision(self, decision_text):
        """
        è§£æå†³ç­–æ–‡æœ¬ä¸ºç»“æ„åŒ–å†³ç­–
        
        Args:
            decision_text: å†³ç­–æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«JSONï¼‰
            
        Returns:
            è§£æåçš„å†³ç­–å­—å…¸
        """
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            try:
                from autogen.code_utils import extract_code
                
                # å…ˆå°è¯•æå–ä»£ç å—
                extracted_json = extract_code(decision_text)
                if extracted_json:
                    # æ‰¾åˆ°äº†ä»£ç å—
                    for lang, code in extracted_json:
                        if lang == "" or lang.lower() == "json":
                            try:
                                return json.loads(code)
                            except:
                                continue
            except ImportError:
                # autogenä¸å¯ç”¨ï¼Œè·³è¿‡è¿™ä¸ªæ–¹æ³•
                pass
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°ä»£ç å—æˆ–è§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥è§£æ
            try:
                return json.loads(decision_text)
            except:
                # å°è¯•æŸ¥æ‰¾JSONæ ¼å¼éƒ¨åˆ†
                import re
                json_pattern = r'\{{[\s\S]*\}}'
                match = re.search(json_pattern, decision_text)
                if match:
                    try:
                        return json.loads(match.group(0))
                    except:
                        pass
            
            # æ‰€æœ‰JSONè§£ææ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„æ–‡æœ¬åˆ†æ
            decision = {}
            if 'generate_new_task' in decision_text.lower():
                decision['action'] = 'generate_new_task'
            elif 'retry' in decision_text.lower():
                decision['action'] = 'retry'
            elif 'complete' in decision_text.lower():
                decision['action'] = 'complete'
            else:
                decision['action'] = 'continue'
            
            decision['reason'] = "åŸºäºæ–‡æœ¬åˆ†æçš„å†³ç­–ï¼ˆJSONè§£æå¤±è´¥ï¼‰"
            decision['new_tasks'] = []
            
            return decision
            
        except Exception as e:
            logger.error(f"å†³ç­–è§£æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤å†³ç­–
            return {
                'action': 'continue',
                'reason': f'å†³ç­–è§£æå¤±è´¥: {e}',
                'new_tasks': []
            }

    # ===== å¤šæ–¹æ¡ˆå“åº”è§£æå™¨ç›¸å…³æ–¹æ³• =====
    
    def _analyze_step_response(self, result: Result, step: Dict[str, Any], response_text: str) -> Result:
        """
        åˆ†ææ­¥éª¤å“åº”å¹¶å¢å¼ºç»“æœ
        
        Args:
            result: åŸå§‹æ‰§è¡Œç»“æœ
            step: æ­¥éª¤ä¿¡æ¯
            response_text: å“åº”æ–‡æœ¬
            
        Returns:
            å¢å¼ºåçš„ç»“æœå¯¹è±¡
        """
        if not self.enable_response_analysis or not self.response_parser:
            return result
        
        try:
            # å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
            context = {
                'step_name': step.get('name', ''),
                'step_type': step.get('instruction_type', ''),
                'agent_name': step.get('agent_name', ''),
                'instruction': step.get('instruction', ''),
                'execution_success': result.success
            }
            
            # è§£æå“åº”
            parsed_info = self.response_parser.parse_response(response_text, context)
            
            # è®°å½•è§£æå†å²
            self.parsed_responses_history.append({
                'timestamp': dt.now().isoformat(),
                'step_name': step.get('name', ''),
                'instruction': step.get('instruction', ''),
                'response_text': response_text,
                'parsed_info': parsed_info,
                'original_success': result.success
            })
            
            # å¢å¼ºç»“æœå¯¹è±¡
            if hasattr(result, 'details') and isinstance(result.details, dict):
                result.details['response_analysis'] = {
                    'main_content': parsed_info.main_content,
                    'confidence_score': parsed_info.confidence_score,
                    'extracted_entities': parsed_info.extracted_entities,
                    'sentiment': parsed_info.sentiment,
                    'intent': parsed_info.intent,
                    'quality_metrics': parsed_info.quality_metrics
                }
            else:
                # å¦‚æœ result.details ä¸å­˜åœ¨æˆ–ä¸æ˜¯å­—å…¸ï¼Œåˆ›å»ºæ–°çš„
                result.details = {
                    'response_analysis': {
                        'main_content': parsed_info.main_content,
                        'confidence_score': parsed_info.confidence_score,
                        'extracted_entities': parsed_info.extracted_entities,
                        'sentiment': parsed_info.sentiment,
                        'intent': parsed_info.intent,
                        'quality_metrics': parsed_info.quality_metrics
                    }
                }
            
            # æ£€æŸ¥ç½®ä¿¡åº¦å¹¶è®°å½•è­¦å‘Š
            if parsed_info.confidence_score < self.confidence_threshold:
                logger.warning(f"æ­¥éª¤ '{step.get('name', '')}' å“åº”ç½®ä¿¡åº¦è¾ƒä½: {parsed_info.confidence_score:.2f}")
            
            return result
            
        except Exception as e:
            logger.error(f"å“åº”åˆ†æå¤±è´¥: {e}")
            return result
    
    def _generate_response_analysis_summary(self) -> str:
        """ç”Ÿæˆå“åº”åˆ†ææ‘˜è¦"""
        if not self.parsed_responses_history:
            return "æš‚æ— å“åº”åˆ†ææ•°æ®"
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_responses = len(self.parsed_responses_history)
        confidence_scores = [entry['parsed_info'].confidence_score for entry in self.parsed_responses_history]
        avg_confidence = sum(confidence_scores) / len(confidence_scores)
        
        # ç»Ÿè®¡çŠ¶æ€ç±»å‹
        status_types = [entry['parsed_info'].extracted_entities.get('status_type', 'unknown') 
                       for entry in self.parsed_responses_history]
        status_counts = {}
        for status in status_types:
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # ç»Ÿè®¡æƒ…æ„Ÿå€¾å‘
        sentiments = [entry['parsed_info'].sentiment for entry in self.parsed_responses_history 
                     if entry['parsed_info'].sentiment]
        sentiment_counts = {}
        for sentiment in sentiments:
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
        
        # è·å–è§£æå™¨ç»Ÿè®¡
        parser_stats = self.response_parser.get_stats() if self.response_parser else {}
        
        # ç”Ÿæˆæ‘˜è¦
        summary = f"ğŸ“Š **å“åº”åˆ†æç»Ÿè®¡**\n"
        summary += f"- æ€»å“åº”æ•°: {total_responses}\n"
        summary += f"- å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.1%}\n"
        summary += f"- è§£ææˆåŠŸç‡: {parser_stats.get('success_rate', 0):.1%}\n"
        
        if status_counts:
            summary += f"- çŠ¶æ€åˆ†å¸ƒ: "
            status_desc = {"success": "æˆåŠŸ", "error": "é”™è¯¯", "progress": "è¿›è¡Œä¸­", "neutral": "ä¸­æ€§"}
            status_parts = [f"{status_desc.get(k, k)}({v})" for k, v in status_counts.items()]
            summary += ", ".join(status_parts) + "\n"
        
        if sentiment_counts:
            summary += f"- æƒ…æ„Ÿåˆ†å¸ƒ: "
            sentiment_desc = {"positive": "ç§¯æ", "negative": "æ¶ˆæ", "neutral": "ä¸­æ€§"}
            sentiment_parts = [f"{sentiment_desc.get(k, k)}({v})" for k, v in sentiment_counts.items()]
            summary += ", ".join(sentiment_parts) + "\n"
        
        # æœ€è¿‘ä¸€æ¬¡åˆ†æç»“æœ
        if self.parsed_responses_history:
            last_entry = self.parsed_responses_history[-1]
            last_info = last_entry['parsed_info']
            summary += f"- æœ€è¿‘åˆ†æ: {last_info.extracted_entities.get('status_type', 'æœªçŸ¥')}çŠ¶æ€ï¼Œ"
            summary += f"ç½®ä¿¡åº¦{last_info.confidence_score:.1%}\n"
        
        return summary
    
    def get_response_analysis_stats(self) -> Dict[str, Any]:
        """è·å–å“åº”åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        if not self.response_parser:
            return {"error": "å“åº”è§£æå™¨æœªåˆå§‹åŒ–"}
        
        base_stats = self.response_parser.get_stats()
        
        if self.parsed_responses_history:
            # è®¡ç®—é¢å¤–ç»Ÿè®¡ä¿¡æ¯
            confidence_scores = [entry['parsed_info'].confidence_score for entry in self.parsed_responses_history]
            base_stats.update({
                'total_analyzed_responses': len(self.parsed_responses_history),
                'average_confidence': sum(confidence_scores) / len(confidence_scores),
                'min_confidence': min(confidence_scores),
                'max_confidence': max(confidence_scores),
                'low_confidence_count': sum(1 for score in confidence_scores if score < self.confidence_threshold)
            })
        
        return base_stats
    
    def configure_response_parser(self, 
                                 parser_method: Union[str, ParserMethod] = None,
                                 parser_config: Dict[str, Any] = None,
                                 enable_response_analysis: bool = None,
                                 enable_execution_monitoring: bool = None):
        """
        é‡æ–°é…ç½®å“åº”è§£æå™¨
        
        Args:
            parser_method: æ–°çš„è§£æå™¨æ–¹æ³•
            parser_config: æ–°çš„è§£æå™¨é…ç½®
            enable_response_analysis: æ˜¯å¦å¯ç”¨å“åº”åˆ†æ
            enable_execution_monitoring: æ˜¯å¦å¯ç”¨æ‰§è¡Œç›‘æ§
        """
        if enable_response_analysis is not None:
            self.enable_response_analysis = enable_response_analysis
        
        if enable_execution_monitoring is not None:
            self.enable_execution_monitoring = enable_execution_monitoring
        
        if parser_method is not None or parser_config is not None:
            # é‡æ–°åˆå§‹åŒ–è§£æå™¨
            self._init_response_parser(
                parser_method=parser_method or "rule",
                parser_config=parser_config or {},
                enable_response_analysis=self.enable_response_analysis,
                enable_execution_monitoring=self.enable_execution_monitoring
            )
            
            # åŒæ­¥æ›´æ–°AIçŠ¶æ€æ›´æ–°å™¨çš„è§£æå™¨
            if (hasattr(self, '_ai_updater') and self._ai_updater is not None and
                hasattr(self, 'response_parser') and self.response_parser is not None):
                self._ai_updater.response_parser = self.response_parser
                logger.info("AIçŠ¶æ€æ›´æ–°å™¨çš„å“åº”è§£æå™¨å·²åŒæ­¥æ›´æ–°")
        
        logger.info(f"å“åº”è§£æå™¨é…ç½®å·²æ›´æ–°")
    
    def clear_response_analysis_history(self):
        """æ¸…ç©ºå“åº”åˆ†æå†å²"""
        self.parsed_responses_history = []
        logger.info("å“åº”åˆ†æå†å²å·²æ¸…ç©º")
    
    def get_natural_language_analysis_summary(self) -> str:
        """è·å–è‡ªç„¶è¯­è¨€å½¢å¼çš„åˆ†ææ‘˜è¦"""
        if not self.parsed_responses_history:
            return "æ™ºèƒ½ä½“å°šæœªæ‰§è¡Œä»»ä½•ä»»åŠ¡ï¼Œæš‚æ— åˆ†ææ•°æ®ã€‚"
        
        total_responses = len(self.parsed_responses_history)
        confidence_scores = [entry['parsed_info'].confidence_score for entry in self.parsed_responses_history]
        avg_confidence = sum(confidence_scores) / len(confidence_scores)
        
        # åˆ†ææœ€è¿‘çš„è¶‹åŠ¿
        if len(self.parsed_responses_history) >= 3:
            recent_confidences = confidence_scores[-3:]
            if recent_confidences[-1] > recent_confidences[0]:
                trend = "å‘ˆä¸Šå‡è¶‹åŠ¿"
            elif recent_confidences[-1] < recent_confidences[0]:
                trend = "å‘ˆä¸‹é™è¶‹åŠ¿"
            else:
                trend = "ä¿æŒç¨³å®š"
        else:
            trend = "æ•°æ®ä¸è¶³"
        
        # è·å–ä¸»è¦çŠ¶æ€ç±»å‹
        status_types = [entry['parsed_info'].extracted_entities.get('status_type', 'unknown') 
                       for entry in self.parsed_responses_history]
        if status_types:
            most_common_status = max(set(status_types), key=status_types.count)
            status_desc = {"success": "æˆåŠŸ", "error": "é”™è¯¯", "progress": "è¿›è¡Œä¸­", "neutral": "ä¸­æ€§"}.get(most_common_status, most_common_status)
        else:
            status_desc = "æœªçŸ¥"
        
        summary = f"æ™ºèƒ½ä½“å·²å®Œæˆ {total_responses} ä¸ªä»»åŠ¡çš„å“åº”åˆ†æï¼Œ"
        summary += f"å¹³å‡è§£æç½®ä¿¡åº¦ä¸º {avg_confidence:.1%}ï¼Œç½®ä¿¡åº¦{trend}ã€‚"
        summary += f"ä¸»è¦ä»»åŠ¡çŠ¶æ€ç±»å‹ä¸º{status_desc}ã€‚"
        
        # è·å–è§£æå™¨æ€§èƒ½
        if self.response_parser:
            parser_stats = self.response_parser.get_stats()
            success_rate = parser_stats.get('success_rate', 0)
            summary += f"è§£æå™¨æ•´ä½“æˆåŠŸç‡ä¸º {success_rate:.1%}ã€‚"
        
        return summary

