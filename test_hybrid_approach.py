#!/usr/bin/env python3
"""
æµ‹è¯•æ··åˆæ–¹æ¡ˆAIè¯„ä¼°åŠŸèƒ½
=================

æµ‹è¯•AIå¸ƒå°”å­—æ®µå’Œä¼ ç»Ÿå­—ç¬¦ä¸²æ¡ä»¶çš„æ··åˆé…ç½®æ–¹æ¡ˆã€‚
"""

import os
import sys
import json
import logging
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from static_workflow.workflow_definitions import (
    WorkflowDefinition, WorkflowStep, ControlFlow, ControlFlowType,
    WorkflowMetadata, WorkflowLoader
)
from static_workflow.control_flow_evaluator import ControlFlowEvaluator
from static_workflow.result_evaluator import MockTestResultEvaluator
from agent_base import Result

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_test_workflow_with_ai_fields() -> WorkflowDefinition:
    """åˆ›å»ºå¸¦æœ‰AIè¯„ä¼°å­—æ®µçš„æµ‹è¯•å·¥ä½œæµ"""
    
    # åˆ›å»ºå·¥ä½œæµæ­¥éª¤
    steps = [
        WorkflowStep(
            id="step1",
            name="è¿è¡Œæµ‹è¯•",
            agent_name="test_agent",
            instruction="è¿è¡Œå•å…ƒæµ‹è¯•",
            control_flow=ControlFlow(
                type=ControlFlowType.CONDITIONAL,
                success_next="step2",
                failure_next="step3",
                # ä½¿ç”¨AIå¸ƒå°”å­—æ®µè¯„ä¼°
                ai_evaluate_test_result=True,
                ai_confidence_threshold=0.7,
                ai_fallback_condition="last_result.success == True"
            )
        ),
        WorkflowStep(
            id="step2",
            name="æµ‹è¯•é€šè¿‡",
            agent_name="report_agent",
            instruction="ç”Ÿæˆæµ‹è¯•é€šè¿‡æŠ¥å‘Š"
        ),
        WorkflowStep(
            id="step3",
            name="æµ‹è¯•å¤±è´¥",
            agent_name="report_agent", 
            instruction="ç”Ÿæˆæµ‹è¯•å¤±è´¥æŠ¥å‘Š"
        )
    ]
    
    return WorkflowDefinition(
        workflow_metadata=WorkflowMetadata(
            name="AIæ··åˆè¯„ä¼°æµ‹è¯•å·¥ä½œæµ",
            version="1.0",
            description="æµ‹è¯•AIå¸ƒå°”å­—æ®µå’Œä¼ ç»Ÿæ¡ä»¶çš„æ··åˆæ–¹æ¡ˆ"
        ),
        steps=steps
    )


def create_test_workflow_with_string_condition() -> WorkflowDefinition:
    """åˆ›å»ºå¸¦æœ‰ä¼ ç»Ÿå­—ç¬¦ä¸²æ¡ä»¶çš„æµ‹è¯•å·¥ä½œæµ"""
    
    steps = [
        WorkflowStep(
            id="step1",
            name="è¿è¡Œæµ‹è¯•",
            agent_name="test_agent",
            instruction="è¿è¡Œå•å…ƒæµ‹è¯•",
            control_flow=ControlFlow(
                type=ControlFlowType.CONDITIONAL,
                success_next="step2",
                failure_next="step3",
                # ä½¿ç”¨ä¼ ç»Ÿæ¡ä»¶è¡¨è¾¾å¼
                condition="ai_evaluate_test_result"
            )
        ),
        WorkflowStep(
            id="step2", 
            name="æµ‹è¯•é€šè¿‡",
            agent_name="report_agent",
            instruction="ç”Ÿæˆæµ‹è¯•é€šè¿‡æŠ¥å‘Š"
        ),
        WorkflowStep(
            id="step3",
            name="æµ‹è¯•å¤±è´¥",
            agent_name="report_agent",
            instruction="ç”Ÿæˆæµ‹è¯•å¤±è´¥æŠ¥å‘Š"
        )
    ]
    
    return WorkflowDefinition(
        workflow_metadata=WorkflowMetadata(
            name="ä¼ ç»Ÿæ¡ä»¶è¯„ä¼°æµ‹è¯•å·¥ä½œæµ",
            version="1.0", 
            description="æµ‹è¯•ä¼ ç»Ÿå­—ç¬¦ä¸²æ¡ä»¶æ–¹å¼çš„AIè¯„ä¼°"
        ),
        steps=steps
    )


def test_workflow_validation():
    """æµ‹è¯•å·¥ä½œæµéªŒè¯åŠŸèƒ½"""
    logger.info("=== æµ‹è¯•å·¥ä½œæµéªŒè¯åŠŸèƒ½ ===")
    
    # æµ‹è¯•æœ‰æ•ˆçš„AIé…ç½®
    workflow1 = create_test_workflow_with_ai_fields()
    errors1 = workflow1.validate()
    logger.info(f"AIå­—æ®µé…ç½®éªŒè¯ç»“æœ: {len(errors1)} ä¸ªé”™è¯¯")
    for error in errors1:
        logger.warning(f"  - {error}")
    
    # æµ‹è¯•ä¼ ç»Ÿæ¡ä»¶é…ç½®
    workflow2 = create_test_workflow_with_string_condition()
    errors2 = workflow2.validate()
    logger.info(f"ä¼ ç»Ÿæ¡ä»¶é…ç½®éªŒè¯ç»“æœ: {len(errors2)} ä¸ªé”™è¯¯")
    for error in errors2:
        logger.warning(f"  - {error}")
    
    # æµ‹è¯•æ— æ•ˆçš„ç½®ä¿¡åº¦é˜ˆå€¼
    workflow3 = create_test_workflow_with_ai_fields()
    workflow3.steps[0].control_flow.ai_confidence_threshold = 1.5  # æ— æ•ˆå€¼
    errors3 = workflow3.validate()
    logger.info(f"æ— æ•ˆç½®ä¿¡åº¦é˜ˆå€¼éªŒè¯ç»“æœ: {len(errors3)} ä¸ªé”™è¯¯")
    for error in errors3:
        logger.warning(f"  - {error}")
    
    # æµ‹è¯•åŒæ—¶ä½¿ç”¨AIå­—æ®µå’Œæ¡ä»¶è¡¨è¾¾å¼çš„è­¦å‘Š
    workflow4 = create_test_workflow_with_ai_fields()
    workflow4.steps[0].control_flow.condition = "last_result.success == True"  # åŒæ—¶è®¾ç½®
    errors4 = workflow4.validate()
    logger.info(f"æ··åˆé…ç½®å†²çªéªŒè¯ç»“æœ: {len(errors4)} ä¸ªé”™è¯¯")
    for error in errors4:
        logger.warning(f"  - {error}")
    
    return len(errors1) == 0 and len(errors2) == 0 and len(errors3) > 0 and len(errors4) > 0


def test_ai_field_evaluation():
    """æµ‹è¯•AIå¸ƒå°”å­—æ®µè¯„ä¼°"""
    logger.info("=== æµ‹è¯•AIå¸ƒå°”å­—æ®µè¯„ä¼° ===")
    
    # åˆ›å»ºAIè¯„ä¼°å™¨
    ai_evaluator = MockTestResultEvaluator()
    
    # åˆ›å»ºæ§åˆ¶æµè¯„ä¼°å™¨
    evaluator = ControlFlowEvaluator(ai_evaluator=ai_evaluator)
    
    # åˆ›å»ºæµ‹è¯•ç»“æœï¼ˆæ¨¡æ‹Ÿunittestè¾“å‡ºåˆ°stderrçš„æƒ…å†µï¼‰
    test_result = Result(
        success=True,
        code="python -m unittest test_calculator.py",
        stdout="",  # unittesté€šå¸¸ä¸å‘stdoutè¾“å‡º
        stderr="Ran 5 tests in 0.123s\n\nOK",  # unittestè¾“å‡ºåˆ°stderr
        return_value="0 failed, 5 passed"
    )
    
    # è®¾ç½®è¯„ä¼°ä¸Šä¸‹æ–‡
    evaluator.set_context(step_result=test_result)
    
    # åˆ›å»ºæ§åˆ¶æµé…ç½®
    control_flow = ControlFlow(
        type=ControlFlowType.CONDITIONAL,
        ai_evaluate_test_result=True,
        ai_confidence_threshold=0.7,
        ai_fallback_condition="last_result.success == True"
    )
    
    # æµ‹è¯•AIè¯„ä¼°
    result = evaluator.evaluate_control_flow_condition(control_flow)
    logger.info(f"AIå­—æ®µè¯„ä¼°ç»“æœ: {result}")
    
    # æµ‹è¯•ä½ç½®ä¿¡åº¦å›é€€
    control_flow.ai_confidence_threshold = 0.9  # è®¾ç½®é«˜é˜ˆå€¼
    result_fallback = evaluator.evaluate_control_flow_condition(control_flow)  
    logger.info(f"é«˜é˜ˆå€¼å›é€€è¯„ä¼°ç»“æœ: {result_fallback}")
    
    # æµ‹è¯•unittestå¤±è´¥çš„æƒ…å†µ
    failed_test_result = Result(
        success=True,  # å‘½ä»¤æ‰§è¡ŒæˆåŠŸ
        code="python -m unittest test_calculator.py",
        stdout="",
        stderr="Ran 5 tests in 0.123s\n\nFAILED (failures=2)",  # unittestå¤±è´¥è¾“å‡º
        return_value="2 failed, 3 passed"
    )
    
    evaluator.set_context(step_result=failed_test_result)
    control_flow.ai_confidence_threshold = 0.7  # é‡ç½®é˜ˆå€¼
    failed_result = evaluator.evaluate_control_flow_condition(control_flow)
    logger.info(f"å¤±è´¥æµ‹è¯•è¯„ä¼°ç»“æœ: {failed_result}")
    
    return result is True and failed_result is False


def test_string_condition_evaluation():
    """æµ‹è¯•ä¼ ç»Ÿå­—ç¬¦ä¸²æ¡ä»¶è¯„ä¼°"""
    logger.info("=== æµ‹è¯•ä¼ ç»Ÿå­—ç¬¦ä¸²æ¡ä»¶è¯„ä¼° ===")
    
    # åˆ›å»ºAIè¯„ä¼°å™¨
    ai_evaluator = MockTestResultEvaluator()
    
    # åˆ›å»ºæ§åˆ¶æµè¯„ä¼°å™¨
    evaluator = ControlFlowEvaluator(ai_evaluator=ai_evaluator)
    
    # åˆ›å»ºæµ‹è¯•ç»“æœï¼ˆæ¨¡æ‹Ÿunittestè¾“å‡ºåˆ°stderrçš„æƒ…å†µï¼‰
    test_result = Result(
        success=True,
        code="python -m unittest test_calculator.py",
        stdout="", 
        stderr="Ran 5 tests in 0.123s\n\nOK",
        return_value="0 failed, 5 passed"
    )
    
    # è®¾ç½®è¯„ä¼°ä¸Šä¸‹æ–‡
    evaluator.set_context(step_result=test_result)
    
    # æµ‹è¯•ä¼ ç»Ÿæ¡ä»¶è¯„ä¼°
    result1 = evaluator.evaluate_condition("last_result.success == True")
    logger.info(f"ä¼ ç»Ÿæ¡ä»¶è¯„ä¼°ç»“æœ: {result1}")
    
    # æµ‹è¯•AIå­—ç¬¦ä¸²æ¡ä»¶è¯„ä¼°
    result2 = evaluator.evaluate_condition("ai_evaluate_test_result")
    logger.info(f"AIå­—ç¬¦ä¸²æ¡ä»¶è¯„ä¼°ç»“æœ: {result2}")
    
    return result1 is True and result2 is True


def test_workflow_serialization():
    """æµ‹è¯•å·¥ä½œæµåºåˆ—åŒ–å’Œååºåˆ—åŒ–"""
    logger.info("=== æµ‹è¯•å·¥ä½œæµåºåˆ—åŒ– ===")
    
    # åˆ›å»ºæµ‹è¯•å·¥ä½œæµ
    workflow = create_test_workflow_with_ai_fields()
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = "temp_workflow_test.json"
    
    try:
        WorkflowLoader.save_to_file(workflow, temp_file)
        logger.info(f"å·¥ä½œæµå·²ä¿å­˜åˆ°: {temp_file}")
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        with open(temp_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥AIå­—æ®µæ˜¯å¦æ­£ç¡®ä¿å­˜
        step1_cf = data['steps'][0]['control_flow']
        ai_fields_present = (
            'ai_evaluate_test_result' in step1_cf and
            'ai_confidence_threshold' in step1_cf and 
            'ai_fallback_condition' in step1_cf
        )
        logger.info(f"AIå­—æ®µä¿å­˜æ£€æŸ¥: {ai_fields_present}")
        
        # é‡æ–°åŠ è½½å·¥ä½œæµ
        loaded_workflow = WorkflowLoader.load_from_file(temp_file)
        logger.info(f"å·¥ä½œæµé‡æ–°åŠ è½½æˆåŠŸ: {loaded_workflow.workflow_metadata.name}")
        
        # æ£€æŸ¥åŠ è½½çš„AIå­—æ®µ
        loaded_cf = loaded_workflow.steps[0].control_flow
        ai_fields_loaded = (
            loaded_cf.ai_evaluate_test_result == True and
            loaded_cf.ai_confidence_threshold == 0.7 and
            loaded_cf.ai_fallback_condition == "last_result.success == True"
        )
        logger.info(f"AIå­—æ®µåŠ è½½æ£€æŸ¥: {ai_fields_loaded}")
        
        return ai_fields_present and ai_fields_loaded
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_file):
            os.remove(temp_file)


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("å¼€å§‹æ··åˆæ–¹æ¡ˆåŠŸèƒ½æµ‹è¯•")
    
    tests = [
        ("å·¥ä½œæµéªŒè¯", test_workflow_validation),
        ("AIå­—æ®µè¯„ä¼°", test_ai_field_evaluation), 
        ("å­—ç¬¦ä¸²æ¡ä»¶è¯„ä¼°", test_string_condition_evaluation),
        ("å·¥ä½œæµåºåˆ—åŒ–", test_workflow_serialization)
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            result = test_func()
            results[test_name] = result
            status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
            logger.info(f"{test_name}: {status}")
        except Exception as e:
            results[test_name] = False
            logger.error(f"{test_name}: âœ— å¼‚å¸¸ - {e}")
        
        logger.info("-" * 50)
    
    # æ±‡æ€»ç»“æœ
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    
    logger.info(f"æµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ··åˆæ–¹æ¡ˆå®ç°æˆåŠŸã€‚")
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)