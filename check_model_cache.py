#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥æ¨¡å‹ç¼“å­˜ç›®å½•å’Œä¸‹è½½ä½ç½®
"""

import os
from pathlib import Path

def check_model_cache_directories():
    """æ£€æŸ¥æ¨¡å‹ç¼“å­˜ç›®å½•"""
    print("=== æ¨¡å‹ç¼“å­˜ç›®å½•æ£€æŸ¥ ===\n")
    
    # 1. HuggingFace é»˜è®¤ç¼“å­˜ç›®å½•
    try:
        import transformers
        default_cache = transformers.utils.TRANSFORMERS_CACHE
        print(f"1. HuggingFace é»˜è®¤ç¼“å­˜ç›®å½•:")
        print(f"   {default_cache}")
        print(f"   æ˜¯å¦å­˜åœ¨: {os.path.exists(default_cache)}")
        
        if os.path.exists(default_cache):
            # æ£€æŸ¥ç›®å½•å¤§å°
            total_size = 0
            file_count = 0
            for root, dirs, files in os.walk(default_cache):
                for file in files:
                    file_path = os.path.join(root, file)
                    try:
                        total_size += os.path.getsize(file_path)
                        file_count += 1
                    except:
                        pass
            
            print(f"   ç›®å½•å¤§å°: {total_size / (1024**3):.2f} GB")
            print(f"   æ–‡ä»¶æ•°é‡: {file_count}")
            
            # åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹
            print(f"   å·²ä¸‹è½½çš„æ¨¡å‹:")
            models_dir = os.path.join(default_cache, "models")
            if os.path.exists(models_dir):
                for item in os.listdir(models_dir):
                    if os.path.isdir(os.path.join(models_dir, item)):
                        print(f"     - {item}")
            else:
                print(f"     æ— å·²ä¸‹è½½æ¨¡å‹")
        
    except ImportError:
        print("   transformersåº“æœªå®‰è£…")
    
    # 2. ç¯å¢ƒå˜é‡ç¼“å­˜ç›®å½•
    print(f"\n2. ç¯å¢ƒå˜é‡ TRANSFORMERS_CACHE:")
    env_cache = os.environ.get('TRANSFORMERS_CACHE')
    if env_cache:
        print(f"   {env_cache}")
        print(f"   æ˜¯å¦å­˜åœ¨: {os.path.exists(env_cache)}")
    else:
        print("   æœªè®¾ç½®")
    
    # 3. ç¯å¢ƒå˜é‡ HF_HOME
    print(f"\n3. ç¯å¢ƒå˜é‡ HF_HOME:")
    hf_home = os.environ.get('HF_HOME')
    if hf_home:
        print(f"   {hf_home}")
        print(f"   æ˜¯å¦å­˜åœ¨: {os.path.exists(hf_home)}")
    else:
        print("   æœªè®¾ç½®")
    
    # 4. é¡¹ç›®æœ¬åœ°ç¼“å­˜ç›®å½•
    print(f"\n4. é¡¹ç›®æœ¬åœ°ç›®å½•:")
    local_dirs = ['./models', './cache', './.cache']
    for dir_path in local_dirs:
        abs_path = os.path.abspath(dir_path)
        exists = os.path.exists(dir_path)
        print(f"   {dir_path} -> {abs_path}")
        print(f"   æ˜¯å¦å­˜åœ¨: {exists}")
        if exists:
            try:
                size = sum(os.path.getsize(os.path.join(root, file))
                          for root, dirs, files in os.walk(dir_path)
                          for file in files)
                print(f"   ç›®å½•å¤§å°: {size / (1024**2):.1f} MB")
            except:
                print(f"   æ— æ³•è®¡ç®—å¤§å°")

def show_cache_configuration_examples():
    """æ˜¾ç¤ºç¼“å­˜é…ç½®ç¤ºä¾‹"""
    print("\n=== ç¼“å­˜é…ç½®æ–¹æ³• ===\n")
    
    print("æ–¹æ³•1: ä½¿ç”¨é»˜è®¤ç¼“å­˜ç›®å½•ï¼ˆæ¨èï¼‰")
    print("```python")
    print("# æ¨¡å‹ä¼šä¸‹è½½åˆ° ~/.cache/huggingface/hub/")
    print("agent.configure_response_parser(")
    print("    parser_method='transformer',")
    print("    parser_config={")
    print("        'model_name': 'hfl/chinese-bert-wwm-ext'")
    print("    }")
    print(")")
    print("```")
    
    print("\næ–¹æ³•2: æŒ‡å®šé¡¹ç›®æœ¬åœ°ç¼“å­˜ç›®å½•")
    print("```python")
    print("# æ¨¡å‹ä¼šä¸‹è½½åˆ° ./models/ ç›®å½•")
    print("agent.configure_response_parser(")
    print("    parser_method='transformer',")
    print("    parser_config={")
    print("        'model_name': 'hfl/chinese-bert-wwm-ext',")
    print("        'cache_dir': './models'")
    print("    }")
    print(")")
    print("```")
    
    print("\næ–¹æ³•3: é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®å…¨å±€ç¼“å­˜")
    print("```bash")
    print("export TRANSFORMERS_CACHE=/path/to/your/cache")
    print("export HF_HOME=/path/to/your/huggingface")
    print("```")
    
    print("\næ–¹æ³•4: åœ¨ä»£ç ä¸­åŠ¨æ€è®¾ç½®")
    print("```python")
    print("import os")
    print("os.environ['TRANSFORMERS_CACHE'] = '/path/to/cache'")
    print("# ç„¶åé…ç½®è§£æå™¨")
    print("```")

def show_model_size_info():
    """æ˜¾ç¤ºæ¨¡å‹å¤§å°ä¿¡æ¯"""
    print("\n=== å¸¸ç”¨æ¨¡å‹å¤§å°å‚è€ƒ ===\n")
    
    models_info = [
        ("hfl/chinese-bert-wwm-ext", "~400MB", "ä¸­æ–‡BERTæ¨¡å‹ï¼Œæ¨è"),
        ("bert-base-chinese", "~400MB", "æ ‡å‡†ä¸­æ–‡BERT"),
        ("hfl/chinese-roberta-wwm-ext", "~400MB", "ä¸­æ–‡RoBERTaæ¨¡å‹"),
        ("paraphrase-multilingual-MiniLM-L12-v2", "~120MB", "å¤šè¯­è¨€è½»é‡çº§æ¨¡å‹"),
        ("sentence-transformers/paraphrase-MiniLM-L6-v2", "~80MB", "è‹±æ–‡è½»é‡çº§æ¨¡å‹")
    ]
    
    for model_name, size, description in models_info:
        print(f"æ¨¡å‹: {model_name}")
        print(f"å¤§å°: {size}")
        print(f"è¯´æ˜: {description}")
        print()

if __name__ == "__main__":
    check_model_cache_directories()
    show_cache_configuration_examples()
    show_model_size_info()
    
    print("ğŸ’¡ å»ºè®®:")
    print("1. å¦‚æœç£ç›˜ç©ºé—´å……è¶³ï¼Œä½¿ç”¨é»˜è®¤ç¼“å­˜ç›®å½•ï¼ˆ~/.cache/huggingface/ï¼‰")
    print("2. å¦‚æœéœ€è¦é¡¹ç›®éš”ç¦»ï¼Œä½¿ç”¨ cache_dir='./models' å‚æ•°")
    print("3. é¦–æ¬¡ä¸‹è½½éœ€è¦è‰¯å¥½çš„ç½‘ç»œè¿æ¥å’Œä»£ç†é…ç½®")
    print("4. æ¨¡å‹æ–‡ä»¶è¾ƒå¤§ï¼Œå»ºè®®åœ¨WiFiç¯å¢ƒä¸‹è½½è½½")