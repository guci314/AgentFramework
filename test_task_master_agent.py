"""
TaskMasterAgent åŸºæœ¬æµ‹è¯•

æµ‹è¯• TaskMasterAgent çš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬åˆå§‹åŒ–ã€é…ç½®ã€æ•°æ®è½¬æ¢ç­‰ã€‚
"""

import unittest
import tempfile
import shutil
from pathlib import Path
import json
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from task_master_agent import TaskMasterAgent, AgentSpecification, TaskMasterWorkflowState
from task_master.client import TaskMasterClient, TaskMasterClientError
from task_master.data_mapper import TaskMasterDataMapper
from task_master.config import TaskMasterConfig
from python_core import Agent
from agent_base import Result


class MockLLM:
    """æ¨¡æ‹Ÿ LLM ç±»ç”¨äºæµ‹è¯•"""
    def __init__(self):
        self.model = "mock-model"
    
    def invoke(self, messages, **kwargs):
        class MockResponse:
            content = '{"action": "continue", "reason": "æµ‹è¯•å†³ç­–"}'
        return MockResponse()


class TestTaskMasterConfig(unittest.TestCase):
    """æµ‹è¯• TaskMasterConfig ç±»"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.config = TaskMasterConfig(self.temp_dir)
    
    def tearDown(self):
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_default_config(self):
        """æµ‹è¯•é»˜è®¤é…ç½®"""
        # åˆ›å»ºæ–°çš„é…ç½®å®ä¾‹é¿å…æµ‹è¯•é—´æ±¡æŸ“
        fresh_config = TaskMasterConfig(self.temp_dir + "_fresh")
        self.assertEqual(fresh_config.get("project.auto_init"), True)
        self.assertEqual(fresh_config.get_complexity_threshold(), 5)
        self.assertEqual(fresh_config.is_research_enabled(), True)
    
    def test_config_modification(self):
        """æµ‹è¯•é…ç½®ä¿®æ”¹"""
        self.config.set("task_management.complexity_threshold", 7)
        self.assertEqual(self.config.get_complexity_threshold(), 7)
        
        self.config.set("ai_models.use_research", False)
        self.assertEqual(self.config.is_research_enabled(), False)
    
    def test_config_validation(self):
        """æµ‹è¯•é…ç½®éªŒè¯"""
        self.assertTrue(self.config.validate_config())
        
        # è®¾ç½®æ— æ•ˆçš„å¤æ‚åº¦é˜ˆå€¼
        self.config.set("task_management.complexity_threshold", 15)
        self.assertFalse(self.config.validate_config())
        
        # æ¢å¤æœ‰æ•ˆå€¼ï¼Œé¿å…å½±å“å…¶ä»–æµ‹è¯•
        self.config.set("task_management.complexity_threshold", 5)
    
    def test_config_save_load(self):
        """æµ‹è¯•é…ç½®ä¿å­˜å’ŒåŠ è½½"""
        self.config.set("test_key", "test_value")
        self.assertTrue(self.config.save_config())
        
        new_config = TaskMasterConfig(self.temp_dir)
        self.assertEqual(new_config.get("test_key"), "test_value")


class TestTaskMasterDataMapper(unittest.TestCase):
    """æµ‹è¯• TaskMasterDataMapper ç±»"""
    
    def setUp(self):
        self.mapper = TaskMasterDataMapper()
        self.llm = MockLLM()
    
    def test_status_mapping(self):
        """æµ‹è¯•çŠ¶æ€æ˜ å°„"""
        # MultiStepAgent -> Task Master AI
        self.assertEqual(self.mapper._map_status_to_tm("running"), "in-progress")
        self.assertEqual(self.mapper._map_status_to_tm("completed"), "done")
        
        # Task Master AI -> MultiStepAgent
        self.assertEqual(self.mapper._map_status_to_multistep("in-progress"), "running")
        self.assertEqual(self.mapper._map_status_to_multistep("done"), "completed")
    
    def test_tm_task_to_step_format(self):
        """æµ‹è¯• Task Master AI ä»»åŠ¡è½¬æ¢ä¸ºæ­¥éª¤æ ¼å¼"""
        tm_task = {
            "id": 1,
            "title": "æµ‹è¯•ä»»åŠ¡",
            "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä»»åŠ¡",
            "status": "pending",
            "priority": "high",
            "agent_name": "test_agent",
            "dependencies": ["2"],
            "subtasks": []
        }
        
        step = self.mapper.tm_task_to_step_format(tm_task)
        
        self.assertEqual(step["id"], "1")
        self.assertEqual(step["name"], "æµ‹è¯•ä»»åŠ¡")
        self.assertEqual(step["instruction"], "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä»»åŠ¡")
        self.assertEqual(step["status"], "pending")
        self.assertEqual(step["dependencies"], ["2"])
    
    def test_step_to_tm_task_format(self):
        """æµ‹è¯•æ­¥éª¤æ ¼å¼è½¬æ¢ä¸º Task Master AI ä»»åŠ¡"""
        step = {
            "id": "step1",
            "name": "æµ‹è¯•æ­¥éª¤",
            "instruction": "æ‰§è¡Œæµ‹è¯•",
            "agent_name": "test_agent",
            "status": "pending",
            "dependencies": ["step2"],
            "instruction_type": "execution",
            "phase": "execution"
        }
        
        tm_task = self.mapper.step_to_tm_task_format(step, task_id=1)
        
        self.assertEqual(tm_task["id"], 1)
        self.assertEqual(tm_task["title"], "æµ‹è¯•æ­¥éª¤")
        self.assertEqual(tm_task["description"], "æ‰§è¡Œæµ‹è¯•")
        self.assertEqual(tm_task["status"], "pending")
        self.assertEqual(tm_task["dependencies"], ["step2"])
    
    def test_agent_specs_formatting(self):
        """æµ‹è¯•æ™ºèƒ½ä½“è§„æ ¼æ ¼å¼åŒ–"""
        mock_agent = Agent(self.llm)
        specs = [
            AgentSpecification("coder", mock_agent, "ç¼–ç¨‹æ™ºèƒ½ä½“"),
            AgentSpecification("tester", mock_agent, "æµ‹è¯•æ™ºèƒ½ä½“")
        ]
        
        formatted = self.mapper.agent_specs_to_tm_format(specs)
        self.assertIn("coder: ç¼–ç¨‹æ™ºèƒ½ä½“", formatted)
        self.assertIn("tester: æµ‹è¯•æ™ºèƒ½ä½“", formatted)
        
        names = self.mapper.agent_specs_to_name_list(specs)
        self.assertEqual(names, ["coder", "tester"])
    
    def test_format_validation(self):
        """æµ‹è¯•æ ¼å¼éªŒè¯"""
        valid_step = {
            "id": "1",
            "name": "æµ‹è¯•",
            "instruction": "æ‰§è¡Œ",
            "agent_name": "test"
        }
        self.assertTrue(self.mapper.validate_step_format(valid_step))
        
        invalid_step = {"id": "1"}
        self.assertFalse(self.mapper.validate_step_format(invalid_step))


class TestTaskMasterClient(unittest.TestCase):
    """æµ‹è¯• TaskMasterClient ç±»"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.client = TaskMasterClient(self.temp_dir, auto_create=True)
    
    def tearDown(self):
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_initialization(self):
        """æµ‹è¯•å®¢æˆ·ç«¯åˆå§‹åŒ–"""
        self.assertTrue(self.client.is_initialized())
        self.assertTrue(Path(self.temp_dir, ".taskmaster").exists())
        self.assertTrue(Path(self.temp_dir, ".taskmaster", "tasks", "tasks.json").exists())
    
    def test_add_task(self):
        """æµ‹è¯•æ·»åŠ ä»»åŠ¡"""
        task = self.client.add_task(
            prompt="æµ‹è¯•ä»»åŠ¡",
            priority="high"
        )
        
        self.assertIsNotNone(task)
        self.assertEqual(task.get("priority"), "high")
    
    def test_get_tasks(self):
        """æµ‹è¯•è·å–ä»»åŠ¡åˆ—è¡¨"""
        # æ·»åŠ ä¸€ä¸ªä»»åŠ¡
        self.client.add_task(prompt="æµ‹è¯•ä»»åŠ¡1")
        
        tasks = self.client.get_tasks()
        self.assertIsInstance(tasks, list)
    
    def test_next_task(self):
        """æµ‹è¯•è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        # æ·»åŠ ä¸€ä¸ªä»»åŠ¡
        self.client.add_task(prompt="æµ‹è¯•ä»»åŠ¡")
        
        next_task = self.client.next_task()
        # åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹å¯èƒ½è¿”å› None æˆ–ä»»åŠ¡
        self.assertIsInstance(next_task, (dict, type(None)))
    
    def test_research_function(self):
        """æµ‹è¯•ç ”ç©¶åŠŸèƒ½"""
        result = self.client.research("æµ‹è¯•æŸ¥è¯¢")
        self.assertIsInstance(result, str)
        self.assertIn("æµ‹è¯•æŸ¥è¯¢", result)


class TestTaskMasterAgent(unittest.TestCase):
    """æµ‹è¯• TaskMasterAgent ç±»"""
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.llm = MockLLM()
        
        # åˆ›å»ºæµ‹è¯•æ™ºèƒ½ä½“
        self.test_agent = Agent(self.llm)
        self.agent_specs = [
            AgentSpecification("test_agent", self.test_agent, "æµ‹è¯•æ™ºèƒ½ä½“")
        ]
        
        self.tm_agent = TaskMasterAgent(
            project_root=self.temp_dir,
            llm=self.llm,
            agent_specs=self.agent_specs,
            auto_init=True
        )
    
    def tearDown(self):
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_initialization(self):
        """æµ‹è¯• TaskMasterAgent åˆå§‹åŒ–"""
        self.assertEqual(len(self.tm_agent.agent_specs), 1)
        self.assertTrue(self.tm_agent.tm_client.is_initialized())
        self.assertIsInstance(self.tm_agent.config, TaskMasterConfig)
        self.assertIsInstance(self.tm_agent.workflow_state, TaskMasterWorkflowState)
    
    def test_register_agent(self):
        """æµ‹è¯•æ™ºèƒ½ä½“æ³¨å†Œ"""
        new_agent = Agent(self.llm)
        success = self.tm_agent.register_agent("new_agent", new_agent, "æ–°æ™ºèƒ½ä½“")
        
        self.assertTrue(success)
        self.assertEqual(len(self.tm_agent.agent_specs), 2)
    
    def test_project_status(self):
        """æµ‹è¯•é¡¹ç›®çŠ¶æ€è·å–"""
        status = self.tm_agent.get_project_status()
        
        self.assertIsInstance(status, dict)
        self.assertIn("total_tasks", status)
        self.assertIn("agents_registered", status)
        self.assertEqual(status["agents_registered"], 1)
    
    def test_research_function(self):
        """æµ‹è¯•ç ”ç©¶åŠŸèƒ½"""
        result = self.tm_agent.research("Python æœ€ä½³å®è·µ")
        self.assertIsInstance(result, str)
    
    def test_complexity_analysis(self):
        """æµ‹è¯•å¤æ‚åº¦åˆ†æ"""
        analysis = self.tm_agent.get_complexity_analysis()
        self.assertIsInstance(analysis, dict)
    
    def test_enhanced_decision_making(self):
        """æµ‹è¯•å¢å¼ºå†³ç­–åˆ¶å®š"""
        mock_result = Result(True, "test", "success", "", "test_result")
        task_context = {
            "task_id": "1",
            "task_name": "æµ‹è¯•ä»»åŠ¡",
            "agent_name": "test_agent"
        }
        
        decision = self.tm_agent.enhanced_decision_making(mock_result, task_context)
        
        self.assertIsInstance(decision, dict)
        self.assertIn("action", decision)
        self.assertIn("reason", decision)
    
    def test_sync_with_tm(self):
        """æµ‹è¯•ä¸ Task Master AI åŒæ­¥"""
        success = self.tm_agent.sync_with_tm()
        self.assertTrue(success)
        self.assertEqual(self.tm_agent.workflow_state.sync_status, "synced")
    
    def test_execution_modes(self):
        """æµ‹è¯•ä¸åŒæ‰§è¡Œæ¨¡å¼"""
        instruction = "åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•"
        
        # æµ‹è¯•æ¨¡å¼å‚æ•°ï¼ˆä¸å®é™…æ‰§è¡Œï¼Œé¿å… API è°ƒç”¨ï¼‰
        self.assertEqual(self.tm_agent.execution_mode, "tm_native")
        
        # æµ‹è¯•æ¨¡å¼åˆ‡æ¢
        try:
            # è¿™é‡Œåªæµ‹è¯•æ¨¡å¼å‚æ•°ï¼Œä¸å®é™…æ‰§è¡Œ
            result = self.tm_agent.execute_multi_step(
                instruction, 
                mode="legacy"
            )
            # åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸‹ï¼Œlegacy æ¨¡å¼å¯èƒ½ä¼šå¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        except Exception:
            pass  # é¢„æœŸåœ¨æµ‹è¯•ç¯å¢ƒä¸­ä¼šå¤±è´¥


class TestWorkflowState(unittest.TestCase):
    """æµ‹è¯•å·¥ä½œæµçŠ¶æ€ç®¡ç†"""
    
    def test_workflow_state_initialization(self):
        """æµ‹è¯•å·¥ä½œæµçŠ¶æ€åˆå§‹åŒ–"""
        state = TaskMasterWorkflowState()
        
        self.assertIsNone(state.current_task_id)
        self.assertEqual(state.sync_status, "synced")
        self.assertIsInstance(state.execution_context, dict)
        self.assertIsInstance(state.performance_metrics, dict)
    
    def test_performance_metrics(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
        state = TaskMasterWorkflowState()
        
        metrics = state.performance_metrics
        self.assertEqual(metrics["tasks_completed"], 0)
        self.assertEqual(metrics["tasks_failed"], 0)
        self.assertEqual(metrics["average_execution_time"], 0)


def run_basic_tests():
    """è¿è¡ŒåŸºæœ¬æµ‹è¯•"""
    print("è¿è¡Œ TaskMasterAgent åŸºæœ¬æµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    test_classes = [
        TestTaskMasterConfig,
        TestTaskMasterDataMapper,
        TestTaskMasterClient,
        TestTaskMasterAgent,
        TestWorkflowState
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è¾“å‡ºç»“æœ
    print(f"\næµ‹è¯•ç»“æœ:")
    print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    print(f"æˆåŠŸç‡: {((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100):.1f}%")
    
    if result.failures:
        print("\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print("\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    print("TaskMasterAgent æµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    try:
        success = run_basic_tests()
        
        if success:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)